{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Add a relevant banner image here](path_to_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Short project description. Your bottom line up front (BLUF) insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customer of this project is FutureProduct Advisors, a consultancy that helps their customers develop innovative and new consumer products. FutureProduct’s customers are increasingly seeking help from their consultants in go-to-market activities. \n",
    "\n",
    "FutureProduct’s consultants can support these go-to-market activities, but the business does not have all the infrastructure needed to support it. Their biggest ask is for a tool to help them find interesting, up-and-coming music to accompany social posts and online ads for go-to-market promotions. \n",
    "\n",
    "**Stakeholders**\n",
    "\n",
    "- FutureProduct Managing Director: oversees their consulting practice and is sponsoring this project.\n",
    "- FutureProduct Senior Consultants: the actual users of the prospective tool. A small subset of the consultants will pilot the prototype tool.\n",
    "- My consulting leadership: sponsors of this effort; will provide oversight and technical input of the project as needed.\n",
    "\n",
    "**Primary Goals**\n",
    "\n",
    "1.\tBuild a data tool that can evaluate any song in the Billboard Hot 100 list and make predictions about:\n",
    "    -\tThe song’s position on the Hot 100 list 4 weeks in the future\n",
    "    -\tThe song’s highest position on the list in the next 6 months\n",
    "2.\tCreate a rubric that lists the 3 most important factors for songs’ placement on the Hot 100 list for each hear from 2000 to 2021.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Billboard Hot 100 weekly charts (Kaggle): https://www.kaggle.com/datasets/thedevastator/billboard-hot-100-audio-features\n",
    "\n",
    "I’ve chosen this dataset because it has a direct measurement of song popularity (the Hot 100 list) and because its long history gives significant context to a song’s positioning in a given week.\n",
    "The features list gives a wide range of song attributes to explore and enables me to determine what features most significantly contribute to a song’s popularity and how that changes over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import math\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotlist_all = pd.read_csv('Data/Hot Stuff.csv')\n",
    "df_features_all = pd.read_csv('Data/Hot 100 Audio Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327895 entries, 0 to 327894\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   index                   327895 non-null  int64  \n",
      " 1   url                     327895 non-null  object \n",
      " 2   WeekID                  327895 non-null  object \n",
      " 3   Week Position           327895 non-null  int64  \n",
      " 4   Song                    327895 non-null  object \n",
      " 5   Performer               327895 non-null  object \n",
      " 6   SongID                  327895 non-null  object \n",
      " 7   Instance                327895 non-null  int64  \n",
      " 8   Previous Week Position  295941 non-null  float64\n",
      " 9   Peak Position           327895 non-null  int64  \n",
      " 10  Weeks on Chart          327895 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(5)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# exploring hotlist data\n",
    "df_hotlist_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29503 entries, 0 to 29502\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   index                      29503 non-null  int64  \n",
      " 1   SongID                     29503 non-null  object \n",
      " 2   Performer                  29503 non-null  object \n",
      " 3   Song                       29503 non-null  object \n",
      " 4   spotify_genre              27903 non-null  object \n",
      " 5   spotify_track_id           24397 non-null  object \n",
      " 6   spotify_track_preview_url  14491 non-null  object \n",
      " 7   spotify_track_duration_ms  24397 non-null  float64\n",
      " 8   spotify_track_explicit     24397 non-null  object \n",
      " 9   spotify_track_album        24391 non-null  object \n",
      " 10  danceability               24334 non-null  float64\n",
      " 11  energy                     24334 non-null  float64\n",
      " 12  key                        24334 non-null  float64\n",
      " 13  loudness                   24334 non-null  float64\n",
      " 14  mode                       24334 non-null  float64\n",
      " 15  speechiness                24334 non-null  float64\n",
      " 16  acousticness               24334 non-null  float64\n",
      " 17  instrumentalness           24334 non-null  float64\n",
      " 18  liveness                   24334 non-null  float64\n",
      " 19  valence                    24334 non-null  float64\n",
      " 20  tempo                      24334 non-null  float64\n",
      " 21  time_signature             24334 non-null  float64\n",
      " 22  spotify_track_popularity   24397 non-null  float64\n",
      "dtypes: float64(14), int64(1), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# exploring features df\n",
    "df_features_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327895 entries, 0 to 327894\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   WeekID                  327895 non-null  object \n",
      " 1   Week Position           327895 non-null  int64  \n",
      " 2   SongID                  327895 non-null  object \n",
      " 3   Instance                327895 non-null  int64  \n",
      " 4   Previous Week Position  295941 non-null  float64\n",
      " 5   Peak Position           327895 non-null  int64  \n",
      " 6   Weeks on Chart          327895 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# removing attributes that will not be used in cleaning or analysis\n",
    "df_hotlist_all = df_hotlist_all.drop(['index', 'url', 'Song', 'Performer'], axis=1)\n",
    "df_hotlist_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29503 entries, 0 to 29502\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   SongID                     29503 non-null  object \n",
      " 1   spotify_genre              27903 non-null  object \n",
      " 2   spotify_track_id           24397 non-null  object \n",
      " 3   spotify_track_duration_ms  24397 non-null  float64\n",
      " 4   danceability               24334 non-null  float64\n",
      " 5   energy                     24334 non-null  float64\n",
      " 6   key                        24334 non-null  float64\n",
      " 7   loudness                   24334 non-null  float64\n",
      " 8   mode                       24334 non-null  float64\n",
      " 9   speechiness                24334 non-null  float64\n",
      " 10  acousticness               24334 non-null  float64\n",
      " 11  instrumentalness           24334 non-null  float64\n",
      " 12  liveness                   24334 non-null  float64\n",
      " 13  valence                    24334 non-null  float64\n",
      " 14  tempo                      24334 non-null  float64\n",
      " 15  time_signature             24334 non-null  float64\n",
      "dtypes: float64(13), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# removing attributes that will not be used in cleaning or analysis\n",
    "df_features_all = df_features_all.drop(['index', 'Performer', 'Song', 'spotify_track_album', 'spotify_track_preview_url', 'spotify_track_explicit', 'spotify_track_popularity'], axis=1)\n",
    "df_features_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekID</th>\n",
       "      <th>Week Position</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Instance</th>\n",
       "      <th>Previous Week Position</th>\n",
       "      <th>Peak Position</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>63</td>\n",
       "      <td>High School ConfidentialJerry Lee Lewis And Hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103337</th>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>98</td>\n",
       "      <td>Little SerenadeThe Ames Brothers</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146293</th>\n",
       "      <td>1958-08-02</td>\n",
       "      <td>68</td>\n",
       "      <td>Volare (Nel Blu Dipinto Di Blu)Dean Martin</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           WeekID  Week Position  \\\n",
       "18553  1958-08-02             63   \n",
       "103337 1958-08-02             98   \n",
       "146293 1958-08-02             68   \n",
       "\n",
       "                                                   SongID  Instance  \\\n",
       "18553   High School ConfidentialJerry Lee Lewis And Hi...         1   \n",
       "103337                   Little SerenadeThe Ames Brothers         1   \n",
       "146293         Volare (Nel Blu Dipinto Di Blu)Dean Martin         1   \n",
       "\n",
       "        Previous Week Position  Peak Position  Weeks on Chart  \n",
       "18553                      NaN             63               1  \n",
       "103337                     NaN             98               1  \n",
       "146293                     NaN             68               1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting WeekID to datetime\n",
    "df_hotlist_all['WeekID'] = pd.to_datetime(df_hotlist_all['WeekID'], errors='coerce')\n",
    "df_hotlist_all = df_hotlist_all.sort_values(by='WeekID')\n",
    "df_hotlist_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           WeekID  Week Position                                    SongID  \\\n",
       " 270579 2010-01-02             37  Run This TownJay-Z, Rihanna & Kanye West   \n",
       " 145895 2010-01-02            100    Video PhoneBeyonce Featuring Lady Gaga   \n",
       " \n",
       "         Instance  Previous Week Position  Peak Position  Weeks on Chart  \n",
       " 270579         1                    32.0              2              21  \n",
       " 145895         1                    97.0             65               4  ,\n",
       "            WeekID  Week Position                    SongID  Instance  \\\n",
       " 7909   2020-12-26             40     Gold RushTaylor Swift         1   \n",
       " 320975 2020-12-26             65  HawaiMaluma & The Weeknd         1   \n",
       " \n",
       "         Previous Week Position  Peak Position  Weeks on Chart  \n",
       " 7909                       NaN             40               1  \n",
       " 320975                    55.0             12              17  )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new df with only complete year data from 2009 - 2020, the time period being studied\n",
    "df_hotlist_2000s = df_hotlist_all.loc[(df_hotlist_all['WeekID'] > '2009-12-31') & (df_hotlist_all['WeekID'] < '2021-01-01')]\n",
    "df_hotlist_2000s.head(2), df_hotlist_2000s.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57400 entries, 270579 to 320975\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   WeekID                  57400 non-null  datetime64[ns]\n",
      " 1   Week Position           57400 non-null  int64         \n",
      " 2   SongID                  57400 non-null  object        \n",
      " 3   Instance                57400 non-null  int64         \n",
      " 4   Previous Week Position  50939 non-null  float64       \n",
      " 5   Peak Position           57400 non-null  int64         \n",
      " 6   Weeks on Chart          57400 non-null  int64         \n",
      " 7   Rank_Change             57400 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(1)\n",
      "memory usage: 3.9+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1582887564.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s.apply(lambda x: diff(x['Week Position'], x['Previous Week Position']), axis=1)\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1582887564.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s['Rank_Change'].fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           WeekID  Week Position                                    SongID  \\\n",
       " 270579 2010-01-02             37  Run This TownJay-Z, Rihanna & Kanye West   \n",
       " 145895 2010-01-02            100    Video PhoneBeyonce Featuring Lady Gaga   \n",
       " 279649 2010-01-02             96    Kings And QueensThirty Seconds To Mars   \n",
       " \n",
       "         Instance  Previous Week Position  Peak Position  Weeks on Chart  \\\n",
       " 270579         1                    32.0              2              21   \n",
       " 145895         1                    97.0             65               4   \n",
       " 279649         2                    82.0             82               4   \n",
       " \n",
       "         Rank_Change  \n",
       " 270579          5.0  \n",
       " 145895          3.0  \n",
       " 279649         14.0  ,\n",
       "            WeekID  Week Position                            SongID  Instance  \\\n",
       " 265214 2020-12-26             93  Ain't Always The CowboyJon Pardi         1   \n",
       " 7909   2020-12-26             40             Gold RushTaylor Swift         1   \n",
       " 320975 2020-12-26             65          HawaiMaluma & The Weeknd         1   \n",
       " \n",
       "         Previous Week Position  Peak Position  Weeks on Chart  Rank_Change  \n",
       " 265214                    56.0             55              16         37.0  \n",
       " 7909                       NaN             40               1          0.0  \n",
       " 320975                    55.0             12              17         10.0  ,\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a column to calculate the week over week change in rank\n",
    "def diff(a, b):\n",
    "    return a - b\n",
    "\n",
    "df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s.apply(lambda x: diff(x['Week Position'], x['Previous Week Position']), axis=1)\n",
    "df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s['Rank_Change'].fillna(0)\n",
    "df_hotlist_2000s.head(3), df_hotlist_2000s.tail(3), df_hotlist_2000s.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5277 entries, #BeautifulMariah Carey Featuring Miguel to whoa (mind in awe)XXXTENTACION\n",
      "Data columns (total 1 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Max_Rank_Change  5277 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 82.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                             Max_Rank_Change\n",
       " SongID                                                      \n",
       " #BeautifulMariah Carey Featuring Miguel                 17.0\n",
       " #SELFIEThe Chainsmokers                                 18.0\n",
       " #thatPOWERwill.i.am Featuring Justin Bieber             21.0,\n",
       " None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new df with the max weekly rank change for each song in df_hotlist_2000s\n",
    "df_max_rank_change = df_hotlist_2000s.groupby('SongID', as_index=False)['Rank_Change'].max()\n",
    "df_max_rank_change.rename(columns={'Rank_Change': 'Max_Rank_Change'}, inplace=True)\n",
    "df_max_rank_change.set_index('SongID', inplace=True)\n",
    "df_max_rank_change.head(3), df_max_rank_change.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5277 entries, #BeautifulMariah Carey Featuring Miguel to whoa (mind in awe)XXXTENTACION\n",
      "Data columns (total 1 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   Max_Peak_Position  5277 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 82.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                             Max_Peak_Position\n",
       " SongID                                                        \n",
       " #BeautifulMariah Carey Featuring Miguel                     24\n",
       " #SELFIEThe Chainsmokers                                     55\n",
       " #thatPOWERwill.i.am Featuring Justin Bieber                 42,\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new df with the max peak position for each song in df_hotlist_2000s\n",
    "df_max_peak_pos = df_hotlist_2000s.groupby('SongID', as_index=False)['Peak Position'].max()\n",
    "df_max_peak_pos.rename(columns={'Peak Position': 'Max_Peak_Position'}, inplace=True)\n",
    "df_max_peak_pos.set_index('SongID', inplace=True)\n",
    "df_max_peak_pos.head(3), df_max_peak_pos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_peak_pos['Max_Peak_Position'].isna().sum(), df_max_rank_change['Max_Rank_Change'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting full list of songs in the time period being studied\n",
    "songid_list = df_hotlist_2000s['SongID'].unique()\n",
    "\n",
    "# creating a features df with only songs in df_hotlist_2000s\n",
    "df_features_2000s = df_features_all[df_features_all['SongID'].isin(songid_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5389\n",
      "5272\n"
     ]
    }
   ],
   "source": [
    "# checking for duplicates\n",
    "print(len(df_features_2000s))\n",
    "print(len(pd.unique(df_features_2000s['SongID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5272\n",
      "5272\n"
     ]
    }
   ],
   "source": [
    "# removing duplicates and rechecking\n",
    "df_features_2000s = df_features_2000s.drop_duplicates(subset='SongID')\n",
    "\n",
    "print(len(df_features_2000s))\n",
    "print(len(pd.unique(df_features_2000s['SongID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5272 entries, 5 to 29499\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   SongID                     5272 non-null   object \n",
      " 1   spotify_genre              4924 non-null   object \n",
      " 2   spotify_track_id           4773 non-null   object \n",
      " 3   spotify_track_duration_ms  4773 non-null   float64\n",
      " 4   danceability               4753 non-null   float64\n",
      " 5   energy                     4753 non-null   float64\n",
      " 6   key                        4753 non-null   float64\n",
      " 7   loudness                   4753 non-null   float64\n",
      " 8   mode                       4753 non-null   float64\n",
      " 9   speechiness                4753 non-null   float64\n",
      " 10  acousticness               4753 non-null   float64\n",
      " 11  instrumentalness           4753 non-null   float64\n",
      " 12  liveness                   4753 non-null   float64\n",
      " 13  valence                    4753 non-null   float64\n",
      " 14  tempo                      4753 non-null   float64\n",
      " 15  time_signature             4753 non-null   float64\n",
      " 16  Max_Peak_Position          5272 non-null   int64  \n",
      " 17  Max_Rank_Change            5272 non-null   float64\n",
      "dtypes: float64(14), int64(1), object(3)\n",
      "memory usage: 782.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# adding max peak position to main df\n",
    "df_2000s_data = df_features_2000s.join(df_max_peak_pos, on='SongID')\n",
    "# adding max rank change to main df\n",
    "df_2000s_data = df_2000s_data.join(df_max_rank_change, on='SongID')\n",
    "\n",
    "df_2000s_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4713 entries, 5 to 29499\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   SongID                     4713 non-null   object \n",
      " 1   spotify_genre              4713 non-null   object \n",
      " 2   spotify_track_id           4713 non-null   object \n",
      " 3   spotify_track_duration_ms  4713 non-null   float64\n",
      " 4   danceability               4713 non-null   float64\n",
      " 5   energy                     4713 non-null   float64\n",
      " 6   key                        4713 non-null   float64\n",
      " 7   loudness                   4713 non-null   float64\n",
      " 8   mode                       4713 non-null   float64\n",
      " 9   speechiness                4713 non-null   float64\n",
      " 10  acousticness               4713 non-null   float64\n",
      " 11  instrumentalness           4713 non-null   float64\n",
      " 12  liveness                   4713 non-null   float64\n",
      " 13  valence                    4713 non-null   float64\n",
      " 14  tempo                      4713 non-null   float64\n",
      " 15  time_signature             4713 non-null   float64\n",
      " 16  Max_Peak_Position          4713 non-null   int64  \n",
      " 17  Max_Rank_Change            4713 non-null   float64\n",
      "dtypes: float64(14), int64(1), object(3)\n",
      "memory usage: 699.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# removing entries with missing values\n",
    "df_cleaned = df_2000s_data[df_2000s_data.notna().all(axis=1)]\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a df with unique genre names\n",
    "unique_genres = list(set(\n",
    "    genre \n",
    "    for genre_string in df_cleaned['spotify_genre'] \n",
    "    if pd.notna(genre_string)\n",
    "    for genre in ast.literal_eval(genre_string)\n",
    "))\n",
    "\n",
    "df_unique_genres = pd.DataFrame(unique_genres, columns=['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding counts of each unique genre name\n",
    "# Extract all genres (with duplicates) and count them\n",
    "all_genres_list = []\n",
    "for genre_string in df_cleaned['spotify_genre']:\n",
    "    if pd.notna(genre_string):\n",
    "        genre_list = ast.literal_eval(genre_string)\n",
    "        all_genres_list.extend(genre_list)\n",
    "\n",
    "# Count occurrences\n",
    "genre_counts = Counter(all_genres_list)\n",
    "\n",
    "# Map counts to genres dataframe\n",
    "df_unique_genres['count'] = df_unique_genres['genre'].map(genre_counts)\n",
    "df_unique_genres = df_unique_genres.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to csv for easier review of the data\n",
    "df_unique_genres.to_csv('genre_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading list of genres with 50 or more instances in df_cleaned\n",
    "df_genres_50_up = pd.read_csv('genre_counts_50+inst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[genre] = 0\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n",
      "C:\\Users\\markh\\AppData\\Local\\Temp\\ipykernel_1640\\1772023242.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cleaned.at[idx, genre] = 1\n"
     ]
    }
   ],
   "source": [
    "# converting df to list\n",
    "final_genres_list = df_genres_50_up['genre'].tolist()\n",
    "\n",
    "# manually one-hot encoding each genre\n",
    "\n",
    "# creating each new genre column and initializing to 0\n",
    "for genre in final_genres_list:\n",
    "    df_cleaned[genre] = 0\n",
    "\n",
    "# iterating through rows to set values to 1 when genre column appears in original spotify_genre column\n",
    "for idx, genre_string in enumerate(df_cleaned['spotify_genre']):\n",
    "    if pd.notna(genre_string):\n",
    "        genre_list = ast.literal_eval(genre_string)\n",
    "        for genre in genre_list:\n",
    "            df_cleaned.at[idx, genre] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongID</th>\n",
       "      <th>spotify_genre</th>\n",
       "      <th>spotify_track_id</th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>Max_Peak_Position</th>\n",
       "      <th>Max_Rank_Change</th>\n",
       "      <th>pop</th>\n",
       "      <th>rap</th>\n",
       "      <th>pop rap</th>\n",
       "      <th>dance pop</th>\n",
       "      <th>post-teen pop</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>trap</th>\n",
       "      <th>contemporary country</th>\n",
       "      <th>country road</th>\n",
       "      <th>country</th>\n",
       "      <th>southern hip hop</th>\n",
       "      <th>modern country rock</th>\n",
       "      <th>atl hip hop</th>\n",
       "      <th>r&amp;b</th>\n",
       "      <th>canadian pop</th>\n",
       "      <th>melodic rap</th>\n",
       "      <th>urban contemporary</th>\n",
       "      <th>pop rock</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>glee club</th>\n",
       "      <th>neo mellow</th>\n",
       "      <th>canadian hip hop</th>\n",
       "      <th>toronto rap</th>\n",
       "      <th>edm</th>\n",
       "      <th>gangster rap</th>\n",
       "      <th>country pop</th>\n",
       "      <th>tropical house</th>\n",
       "      <th>hip pop</th>\n",
       "      <th>modern rock</th>\n",
       "      <th>miami hip hop</th>\n",
       "      <th>latin</th>\n",
       "      <th>electropop</th>\n",
       "      <th>chicago rap</th>\n",
       "      <th>conscious hip hop</th>\n",
       "      <th>viral pop</th>\n",
       "      <th>country dawn</th>\n",
       "      <th>uk pop</th>\n",
       "      <th>dirty south rap</th>\n",
       "      <th>philly rap</th>\n",
       "      <th>detroit hip hop</th>\n",
       "      <th>alternative r&amp;b</th>\n",
       "      <th>post-grunge</th>\n",
       "      <th>oklahoma country</th>\n",
       "      <th>talent show</th>\n",
       "      <th>canadian contemporary r&amp;b</th>\n",
       "      <th>neo soul</th>\n",
       "      <th>boy band</th>\n",
       "      <th>reggaeton</th>\n",
       "      <th>electro house</th>\n",
       "      <th>rock</th>\n",
       "      <th>atl trap</th>\n",
       "      <th>nc hip hop</th>\n",
       "      <th>new orleans rap</th>\n",
       "      <th>emo rap</th>\n",
       "      <th>australian country</th>\n",
       "      <th>alternative rock</th>\n",
       "      <th>permanent wave</th>\n",
       "      <th>adult standards</th>\n",
       "      <th>brill building pop</th>\n",
       "      <th>easy listening</th>\n",
       "      <th>vocal jazz</th>\n",
       "      <th>plugg</th>\n",
       "      <th>underground hip hop</th>\n",
       "      <th>pittsburgh rap</th>\n",
       "      <th>cali rap</th>\n",
       "      <th>slow game</th>\n",
       "      <th>alternative dance</th>\n",
       "      <th>dance-punk</th>\n",
       "      <th>indie pop</th>\n",
       "      <th>indie rock</th>\n",
       "      <th>indietronica</th>\n",
       "      <th>new rave</th>\n",
       "      <th>indie pop rap</th>\n",
       "      <th>bachata</th>\n",
       "      <th>latin pop</th>\n",
       "      <th>tropical</th>\n",
       "      <th>deep pop r&amp;b</th>\n",
       "      <th>metropopolis</th>\n",
       "      <th>baton rouge rap</th>\n",
       "      <th>brooklyn drill</th>\n",
       "      <th>nyc rap</th>\n",
       "      <th>australian pop</th>\n",
       "      <th>west coast trap</th>\n",
       "      <th>g funk</th>\n",
       "      <th>complextro</th>\n",
       "      <th>german techno</th>\n",
       "      <th>dmv rap</th>\n",
       "      <th>new jersey rap</th>\n",
       "      <th>danish pop</th>\n",
       "      <th>scandipop</th>\n",
       "      <th>texas country</th>\n",
       "      <th>dfw rap</th>\n",
       "      <th>acoustic pop</th>\n",
       "      <th>deep talent show</th>\n",
       "      <th>redneck</th>\n",
       "      <th>american folk revival</th>\n",
       "      <th>country gospel</th>\n",
       "      <th>folk-pop</th>\n",
       "      <th>ny roots</th>\n",
       "      <th>east coast hip hop</th>\n",
       "      <th>candy pop</th>\n",
       "      <th>memphis hip hop</th>\n",
       "      <th>trap queen</th>\n",
       "      <th>pop reggaeton</th>\n",
       "      <th>downtempo</th>\n",
       "      <th>electronic trap</th>\n",
       "      <th>shiver pop</th>\n",
       "      <th>latin hip hop</th>\n",
       "      <th>reggaeton flow</th>\n",
       "      <th>pop punk</th>\n",
       "      <th>punk</th>\n",
       "      <th>socal pop punk</th>\n",
       "      <th>sertanejo</th>\n",
       "      <th>sertanejo pop</th>\n",
       "      <th>sertanejo universitario</th>\n",
       "      <th>emo</th>\n",
       "      <th>pixie</th>\n",
       "      <th>pop emo</th>\n",
       "      <th>new jack swing</th>\n",
       "      <th>quiet storm</th>\n",
       "      <th>swedish electropop</th>\n",
       "      <th>swedish pop</th>\n",
       "      <th>big room</th>\n",
       "      <th>brostep</th>\n",
       "      <th>catstep</th>\n",
       "      <th>electra</th>\n",
       "      <th>australian dance</th>\n",
       "      <th>british soul</th>\n",
       "      <th>lounge</th>\n",
       "      <th>girl group</th>\n",
       "      <th>alternative metal</th>\n",
       "      <th>canadian metal</th>\n",
       "      <th>canadian rock</th>\n",
       "      <th>nu metal</th>\n",
       "      <th>wrestling</th>\n",
       "      <th>piano rock</th>\n",
       "      <th>west coast rap</th>\n",
       "      <th>bronx hip hop</th>\n",
       "      <th>hardcore hip hop</th>\n",
       "      <th>show tunes</th>\n",
       "      <th>etherpop</th>\n",
       "      <th>indie poptimism</th>\n",
       "      <th>progressive electro house</th>\n",
       "      <th>modern uplift</th>\n",
       "      <th>australian hip hop</th>\n",
       "      <th>kentucky hip hop</th>\n",
       "      <th>art pop</th>\n",
       "      <th>art rock</th>\n",
       "      <th>experimental</th>\n",
       "      <th>experimental rock</th>\n",
       "      <th>melancholia</th>\n",
       "      <th>post-punk</th>\n",
       "      <th>psychedelic rock</th>\n",
       "      <th>barbadian pop</th>\n",
       "      <th>puerto rican pop</th>\n",
       "      <th>trap latino</th>\n",
       "      <th>queens hip hop</th>\n",
       "      <th>progressive house</th>\n",
       "      <th>ohio hip hop</th>\n",
       "      <th>rap metal</th>\n",
       "      <th>deep big room</th>\n",
       "      <th>dutch house</th>\n",
       "      <th>lgbtq+ hip hop</th>\n",
       "      <th>reggaeton colombiano</th>\n",
       "      <th>houston rap</th>\n",
       "      <th>modern folk rock</th>\n",
       "      <th>stomp and holler</th>\n",
       "      <th>uk americana</th>\n",
       "      <th>alternative hip hop</th>\n",
       "      <th>europop</th>\n",
       "      <th>cartoon</th>\n",
       "      <th>children's music</th>\n",
       "      <th>arkansas country</th>\n",
       "      <th>funk</th>\n",
       "      <th>soul</th>\n",
       "      <th>mexican pop</th>\n",
       "      <th>crunk</th>\n",
       "      <th>electro</th>\n",
       "      <th>disco house</th>\n",
       "      <th>idol</th>\n",
       "      <th>social media pop</th>\n",
       "      <th>hawaiian hip hop</th>\n",
       "      <th>vapor trap</th>\n",
       "      <th>grunge</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>k-pop</th>\n",
       "      <th>k-pop boy group</th>\n",
       "      <th>electropowerpop</th>\n",
       "      <th>neon pop punk</th>\n",
       "      <th>trancecore</th>\n",
       "      <th>album rock</th>\n",
       "      <th>classic rock</th>\n",
       "      <th>dance rock</th>\n",
       "      <th>glam rock</th>\n",
       "      <th>protopunk</th>\n",
       "      <th>north carolina hip hop</th>\n",
       "      <th>house</th>\n",
       "      <th>uk dance</th>\n",
       "      <th>nu-metalcore</th>\n",
       "      <th>trap soul</th>\n",
       "      <th>rock-and-roll</th>\n",
       "      <th>rockabilly</th>\n",
       "      <th>groove metal</th>\n",
       "      <th>rap conscient</th>\n",
       "      <th>drill</th>\n",
       "      <th>baroque pop</th>\n",
       "      <th>uk contemporary r&amp;b</th>\n",
       "      <th>indiecoustica</th>\n",
       "      <th>lds youth</th>\n",
       "      <th>lilith</th>\n",
       "      <th>celtic rock</th>\n",
       "      <th>reggae fusion</th>\n",
       "      <th>canadian trap</th>\n",
       "      <th>outlaw country</th>\n",
       "      <th>ccm</th>\n",
       "      <th>christian alternative rock</th>\n",
       "      <th>christian indie</th>\n",
       "      <th>christian music</th>\n",
       "      <th>worship</th>\n",
       "      <th>moombahton</th>\n",
       "      <th>neo-singer-songwriter</th>\n",
       "      <th>neo-synthpop</th>\n",
       "      <th>neo-traditional country</th>\n",
       "      <th>folk</th>\n",
       "      <th>new wave pop</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>aussietronica</th>\n",
       "      <th>irish rock</th>\n",
       "      <th>disney</th>\n",
       "      <th>florida rap</th>\n",
       "      <th>colombian pop</th>\n",
       "      <th>a cappella</th>\n",
       "      <th>latin viral pop</th>\n",
       "      <th>rap latina</th>\n",
       "      <th>viral rap</th>\n",
       "      <th>la indie</th>\n",
       "      <th>indie electropop</th>\n",
       "      <th>la pop</th>\n",
       "      <th>pop edm</th>\n",
       "      <th>portland hip hop</th>\n",
       "      <th>viral trap</th>\n",
       "      <th>deep southern trap</th>\n",
       "      <th>hopebeat</th>\n",
       "      <th>k-hop</th>\n",
       "      <th>san diego rap</th>\n",
       "      <th>teen pop</th>\n",
       "      <th>modern alternative rock</th>\n",
       "      <th>nu gaze</th>\n",
       "      <th>motown</th>\n",
       "      <th>ghanaian hip hop</th>\n",
       "      <th>canadian indie</th>\n",
       "      <th>new americana</th>\n",
       "      <th>modern blues rock</th>\n",
       "      <th>south african rock</th>\n",
       "      <th>pop soul</th>\n",
       "      <th>swedish synthpop</th>\n",
       "      <th>escape room</th>\n",
       "      <th>indie soul</th>\n",
       "      <th>heartland rock</th>\n",
       "      <th>k-rap</th>\n",
       "      <th>funk metal</th>\n",
       "      <th>funk rock</th>\n",
       "      <th>nyc pop</th>\n",
       "      <th>garage rock</th>\n",
       "      <th>sheffield indie</th>\n",
       "      <th>uk alternative pop</th>\n",
       "      <th>mellow gold</th>\n",
       "      <th>soft rock</th>\n",
       "      <th>yacht rock</th>\n",
       "      <th>latin arena pop</th>\n",
       "      <th>latin rock</th>\n",
       "      <th>mexican rock</th>\n",
       "      <th>rock en espanol</th>\n",
       "      <th>bubblegum dance</th>\n",
       "      <th>eurodance</th>\n",
       "      <th>melbourne bounce international</th>\n",
       "      <th>country rock</th>\n",
       "      <th>comedy</th>\n",
       "      <th>comic</th>\n",
       "      <th>j-pop</th>\n",
       "      <th>japanese singer-songwriter</th>\n",
       "      <th>post-metal</th>\n",
       "      <th>progressive metal</th>\n",
       "      <th>progressive rock</th>\n",
       "      <th>blues rock</th>\n",
       "      <th>punk blues</th>\n",
       "      <th>detroit trap</th>\n",
       "      <th>bow pop</th>\n",
       "      <th>roots americana</th>\n",
       "      <th>hyphy</th>\n",
       "      <th>australian indie</th>\n",
       "      <th>filter house</th>\n",
       "      <th>ectofolk</th>\n",
       "      <th>nz pop</th>\n",
       "      <th>anthem worship</th>\n",
       "      <th>world worship</th>\n",
       "      <th>cedm</th>\n",
       "      <th>christian pop</th>\n",
       "      <th>minnesota hip hop</th>\n",
       "      <th>dancehall</th>\n",
       "      <th>canadian country</th>\n",
       "      <th>canadian singer-songwriter</th>\n",
       "      <th>canadian folk</th>\n",
       "      <th>folk rock</th>\n",
       "      <th>bass trap</th>\n",
       "      <th>vapor twitch</th>\n",
       "      <th>alt z</th>\n",
       "      <th>bedroom pop</th>\n",
       "      <th>vocal house</th>\n",
       "      <th>chicago hardcore</th>\n",
       "      <th>chicago punk</th>\n",
       "      <th>hardcore punk</th>\n",
       "      <th>cowboy western</th>\n",
       "      <th>traditional country</th>\n",
       "      <th>yodeling</th>\n",
       "      <th>alabama indie</th>\n",
       "      <th>lovers rock</th>\n",
       "      <th>country rap</th>\n",
       "      <th>queer country</th>\n",
       "      <th>movie tunes</th>\n",
       "      <th>k-pop girl group</th>\n",
       "      <th>chicago drill</th>\n",
       "      <th>uk funky</th>\n",
       "      <th>gospel</th>\n",
       "      <th>gospel r&amp;b</th>\n",
       "      <th>chicago indie</th>\n",
       "      <th>minneapolis sound</th>\n",
       "      <th>bubblegum pop</th>\n",
       "      <th>classic country pop</th>\n",
       "      <th>classic uk pop</th>\n",
       "      <th>nashville sound</th>\n",
       "      <th>boston hip hop</th>\n",
       "      <th>modern southern rock</th>\n",
       "      <th>trance</th>\n",
       "      <th>trap boricua</th>\n",
       "      <th>champeta</th>\n",
       "      <th>vallenato</th>\n",
       "      <th>liquid funk</th>\n",
       "      <th>chicago house</th>\n",
       "      <th>chinese hip hop</th>\n",
       "      <th>chinese idol pop</th>\n",
       "      <th>alternative pop rock</th>\n",
       "      <th>glam metal</th>\n",
       "      <th>virgin islands reggae</th>\n",
       "      <th>destroy techno</th>\n",
       "      <th>electronic rock</th>\n",
       "      <th>christian rock</th>\n",
       "      <th>rap rock</th>\n",
       "      <th>tennessee hip hop</th>\n",
       "      <th>jam band</th>\n",
       "      <th>french shoegaze</th>\n",
       "      <th>romanian pop</th>\n",
       "      <th>pop r&amp;b</th>\n",
       "      <th>australian electropop</th>\n",
       "      <th>israeli pop</th>\n",
       "      <th>rebel blues</th>\n",
       "      <th>celtic</th>\n",
       "      <th>middle earth</th>\n",
       "      <th>panamanian pop</th>\n",
       "      <th>brooklyn indie</th>\n",
       "      <th>lo star</th>\n",
       "      <th>drum and bass</th>\n",
       "      <th>canadian electronic</th>\n",
       "      <th>chamber pop</th>\n",
       "      <th>quebec indie</th>\n",
       "      <th>stomp pop</th>\n",
       "      <th>pop dance</th>\n",
       "      <th>slap house</th>\n",
       "      <th>broadway</th>\n",
       "      <th>alabama rap</th>\n",
       "      <th>shimmer pop</th>\n",
       "      <th>battle rap</th>\n",
       "      <th>alberta country</th>\n",
       "      <th>canadian contemporary country</th>\n",
       "      <th>classic girl group</th>\n",
       "      <th>irish singer-songwriter</th>\n",
       "      <th>indy indie</th>\n",
       "      <th>german pop</th>\n",
       "      <th>old school hip hop</th>\n",
       "      <th>deep euro house</th>\n",
       "      <th>deep house</th>\n",
       "      <th>german dance</th>\n",
       "      <th>bedroom soul</th>\n",
       "      <th>metal</th>\n",
       "      <th>scorecore</th>\n",
       "      <th>soundtrack</th>\n",
       "      <th>indie folk</th>\n",
       "      <th>progressive trance</th>\n",
       "      <th>grime</th>\n",
       "      <th>deep underground hip hop</th>\n",
       "      <th>vapor pop</th>\n",
       "      <th>modern salsa</th>\n",
       "      <th>salsa</th>\n",
       "      <th>pinoy hip hop</th>\n",
       "      <th>dutch hip hop</th>\n",
       "      <th>icelandic indie</th>\n",
       "      <th>icelandic rock</th>\n",
       "      <th>australian house</th>\n",
       "      <th>bass house</th>\n",
       "      <th>jazz rap</th>\n",
       "      <th>bmore</th>\n",
       "      <th>ninja</th>\n",
       "      <th>arkansas hip hop</th>\n",
       "      <th>antiviral pop</th>\n",
       "      <th>comedy rock</th>\n",
       "      <th>parody</th>\n",
       "      <th>indie r&amp;b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...Ready For It?Taylor Swift</td>\n",
       "      <td>['pop', 'post-teen pop']</td>\n",
       "      <td>2yLa0QULdQr0qAIvVwN6B5</td>\n",
       "      <td>208186.0</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.417</td>\n",
       "      <td>160.015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'Til Summer Comes AroundKeith Urban</td>\n",
       "      <td>['australian country', 'contemporary country',...</td>\n",
       "      <td>1CKmI1IQjVEVB3F7VmJmM3</td>\n",
       "      <td>331466.0</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.629</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.308</td>\n",
       "      <td>127.907</td>\n",
       "      <td>4.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'Tis The Damn SeasonTaylor Swift</td>\n",
       "      <td>['pop', 'post-teen pop']</td>\n",
       "      <td>7dW84mWkdWE5a6lFWxJCBG</td>\n",
       "      <td>229840.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.434</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-8.193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.348</td>\n",
       "      <td>145.916</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 SongID  \\\n",
       "5          ...Ready For It?Taylor Swift   \n",
       "13  'Til Summer Comes AroundKeith Urban   \n",
       "16     'Tis The Damn SeasonTaylor Swift   \n",
       "\n",
       "                                        spotify_genre        spotify_track_id  \\\n",
       "5                            ['pop', 'post-teen pop']  2yLa0QULdQr0qAIvVwN6B5   \n",
       "13  ['australian country', 'contemporary country',...  1CKmI1IQjVEVB3F7VmJmM3   \n",
       "16                           ['pop', 'post-teen pop']  7dW84mWkdWE5a6lFWxJCBG   \n",
       "\n",
       "    spotify_track_duration_ms  danceability  energy  key  loudness  mode  \\\n",
       "5                    208186.0         0.613   0.764  2.0    -6.509   1.0   \n",
       "13                   331466.0         0.570   0.629  9.0    -7.608   0.0   \n",
       "16                   229840.0         0.575   0.434  5.0    -8.193   1.0   \n",
       "\n",
       "    speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "5        0.1360        0.0527          0.000000     0.197    0.417  160.015   \n",
       "13       0.0331        0.5930          0.000136     0.770    0.308  127.907   \n",
       "16       0.0312        0.7350          0.000066     0.105    0.348  145.916   \n",
       "\n",
       "    time_signature  Max_Peak_Position  Max_Rank_Change  pop  rap  pop rap  \\\n",
       "5              4.0                4.0             22.0  0.0  0.0      0.0   \n",
       "13             4.0               92.0             14.0  0.0  1.0      1.0   \n",
       "16             4.0               39.0              0.0  0.0  0.0      0.0   \n",
       "\n",
       "    dance pop  post-teen pop  hip hop  trap  contemporary country  \\\n",
       "5         0.0            0.0      0.0   0.0                   0.0   \n",
       "13        0.0            0.0      0.0   0.0                   0.0   \n",
       "16        0.0            0.0      0.0   0.0                   1.0   \n",
       "\n",
       "    country road  country  southern hip hop  modern country rock  atl hip hop  \\\n",
       "5            0.0      0.0               0.0                  1.0          0.0   \n",
       "13           0.0      0.0               0.0                  0.0          0.0   \n",
       "16           0.0      0.0               0.0                  0.0          0.0   \n",
       "\n",
       "    r&b  canadian pop  melodic rap  urban contemporary  pop rock  hollywood  \\\n",
       "5   0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       "13  0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       "16  0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       "\n",
       "    glee club  neo mellow  canadian hip hop  toronto rap  edm  gangster rap  \\\n",
       "5         0.0         0.0               0.0          0.0  0.0           0.0   \n",
       "13        0.0         0.0               0.0          0.0  0.0           0.0   \n",
       "16        0.0         0.0               0.0          0.0  0.0           0.0   \n",
       "\n",
       "    country pop  tropical house  hip pop  modern rock  miami hip hop  latin  \\\n",
       "5           0.0             0.0      0.0          0.0            0.0    0.0   \n",
       "13          0.0             0.0      0.0          0.0            0.0    0.0   \n",
       "16          0.0             0.0      0.0          0.0            0.0    0.0   \n",
       "\n",
       "    electropop  chicago rap  conscious hip hop  viral pop  country dawn  \\\n",
       "5          0.0          0.0                0.0        0.0           0.0   \n",
       "13         0.0          0.0                0.0        0.0           0.0   \n",
       "16         0.0          0.0                0.0        0.0           0.0   \n",
       "\n",
       "    uk pop  dirty south rap  philly rap  detroit hip hop  alternative r&b  \\\n",
       "5      0.0              0.0         0.0              0.0              0.0   \n",
       "13     0.0              0.0         0.0              0.0              0.0   \n",
       "16     0.0              0.0         0.0              0.0              0.0   \n",
       "\n",
       "    post-grunge  oklahoma country  talent show  canadian contemporary r&b  \\\n",
       "5           0.0               0.0          0.0                        0.0   \n",
       "13          0.0               0.0          0.0                        0.0   \n",
       "16          0.0               0.0          0.0                        0.0   \n",
       "\n",
       "    neo soul  boy band  reggaeton  electro house  rock  atl trap  nc hip hop  \\\n",
       "5        0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       "13       0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       "16       0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       "\n",
       "    new orleans rap  emo rap  australian country  alternative rock  \\\n",
       "5               0.0      0.0                 NaN               NaN   \n",
       "13              0.0      0.0                 NaN               NaN   \n",
       "16              0.0      0.0                 NaN               NaN   \n",
       "\n",
       "    permanent wave  adult standards  brill building pop  easy listening  \\\n",
       "5              NaN              NaN                 NaN             NaN   \n",
       "13             NaN              NaN                 NaN             NaN   \n",
       "16             NaN              NaN                 NaN             NaN   \n",
       "\n",
       "    vocal jazz  plugg  underground hip hop  pittsburgh rap  cali rap  \\\n",
       "5          NaN    NaN                  NaN             NaN       NaN   \n",
       "13         NaN    NaN                  NaN             NaN       NaN   \n",
       "16         NaN    NaN                  NaN             NaN       NaN   \n",
       "\n",
       "    slow game  alternative dance  dance-punk  indie pop  indie rock  \\\n",
       "5         NaN                NaN         NaN        NaN         NaN   \n",
       "13        NaN                NaN         NaN        NaN         NaN   \n",
       "16        NaN                NaN         NaN        NaN         NaN   \n",
       "\n",
       "    indietronica  new rave  indie pop rap  bachata  latin pop  tropical  \\\n",
       "5            NaN       NaN            NaN      NaN        NaN       NaN   \n",
       "13           NaN       NaN            NaN      NaN        NaN       NaN   \n",
       "16           NaN       NaN            NaN      NaN        NaN       NaN   \n",
       "\n",
       "    deep pop r&b  metropopolis  baton rouge rap  brooklyn drill  nyc rap  \\\n",
       "5            NaN           NaN              NaN             NaN      NaN   \n",
       "13           NaN           NaN              NaN             NaN      NaN   \n",
       "16           NaN           NaN              NaN             NaN      NaN   \n",
       "\n",
       "    australian pop  west coast trap  g funk  complextro  german techno  \\\n",
       "5              NaN              NaN     NaN         NaN            NaN   \n",
       "13             NaN              NaN     NaN         NaN            NaN   \n",
       "16             NaN              NaN     NaN         NaN            NaN   \n",
       "\n",
       "    dmv rap  new jersey rap  danish pop  scandipop  texas country  dfw rap  \\\n",
       "5       NaN             NaN         NaN        NaN            NaN      NaN   \n",
       "13      NaN             NaN         NaN        NaN            NaN      NaN   \n",
       "16      NaN             NaN         NaN        NaN            NaN      NaN   \n",
       "\n",
       "    acoustic pop  deep talent show  redneck  american folk revival  \\\n",
       "5            NaN               NaN      NaN                    NaN   \n",
       "13           NaN               NaN      NaN                    NaN   \n",
       "16           NaN               NaN      NaN                    NaN   \n",
       "\n",
       "    country gospel  folk-pop  ny roots  east coast hip hop  candy pop  \\\n",
       "5              NaN       NaN       NaN                 NaN        NaN   \n",
       "13             NaN       NaN       NaN                 NaN        NaN   \n",
       "16             NaN       NaN       NaN                 NaN        NaN   \n",
       "\n",
       "    memphis hip hop  trap queen  pop reggaeton  downtempo  electronic trap  \\\n",
       "5               NaN         NaN            NaN        NaN              NaN   \n",
       "13              NaN         NaN            NaN        NaN              NaN   \n",
       "16              NaN         NaN            NaN        NaN              NaN   \n",
       "\n",
       "    shiver pop  latin hip hop  reggaeton flow  pop punk  punk  socal pop punk  \\\n",
       "5          NaN            NaN             NaN       NaN   NaN             NaN   \n",
       "13         NaN            NaN             NaN       NaN   NaN             NaN   \n",
       "16         NaN            NaN             NaN       NaN   NaN             NaN   \n",
       "\n",
       "    sertanejo  sertanejo pop  sertanejo universitario  emo  pixie  pop emo  \\\n",
       "5         NaN            NaN                      NaN  NaN    NaN      NaN   \n",
       "13        NaN            NaN                      NaN  NaN    NaN      NaN   \n",
       "16        NaN            NaN                      NaN  NaN    NaN      NaN   \n",
       "\n",
       "    new jack swing  quiet storm  swedish electropop  swedish pop  big room  \\\n",
       "5              NaN          NaN                 NaN          NaN       NaN   \n",
       "13             NaN          NaN                 NaN          NaN       NaN   \n",
       "16             NaN          NaN                 NaN          NaN       NaN   \n",
       "\n",
       "    brostep  catstep  electra  australian dance  british soul  lounge  \\\n",
       "5       NaN      NaN      NaN               NaN           NaN     NaN   \n",
       "13      NaN      NaN      NaN               NaN           NaN     NaN   \n",
       "16      NaN      NaN      NaN               NaN           NaN     NaN   \n",
       "\n",
       "    girl group  alternative metal  canadian metal  canadian rock  nu metal  \\\n",
       "5          NaN                NaN             NaN            NaN       NaN   \n",
       "13         NaN                NaN             NaN            NaN       NaN   \n",
       "16         NaN                NaN             NaN            NaN       NaN   \n",
       "\n",
       "    wrestling  piano rock  west coast rap  bronx hip hop  hardcore hip hop  \\\n",
       "5         NaN         NaN             NaN            NaN               NaN   \n",
       "13        NaN         NaN             NaN            NaN               NaN   \n",
       "16        NaN         NaN             NaN            NaN               NaN   \n",
       "\n",
       "    show tunes  etherpop  indie poptimism  progressive electro house  \\\n",
       "5          NaN       NaN              NaN                        NaN   \n",
       "13         NaN       NaN              NaN                        NaN   \n",
       "16         NaN       NaN              NaN                        NaN   \n",
       "\n",
       "    modern uplift  australian hip hop  kentucky hip hop  art pop  art rock  \\\n",
       "5             NaN                 NaN               NaN      NaN       NaN   \n",
       "13            NaN                 NaN               NaN      NaN       NaN   \n",
       "16            NaN                 NaN               NaN      NaN       NaN   \n",
       "\n",
       "    experimental  experimental rock  melancholia  post-punk  psychedelic rock  \\\n",
       "5            NaN                NaN          NaN        NaN               NaN   \n",
       "13           NaN                NaN          NaN        NaN               NaN   \n",
       "16           NaN                NaN          NaN        NaN               NaN   \n",
       "\n",
       "    barbadian pop  puerto rican pop  trap latino  queens hip hop  \\\n",
       "5             NaN               NaN          NaN             NaN   \n",
       "13            NaN               NaN          NaN             NaN   \n",
       "16            NaN               NaN          NaN             NaN   \n",
       "\n",
       "    progressive house  ohio hip hop  rap metal  deep big room  dutch house  \\\n",
       "5                 NaN           NaN        NaN            NaN          NaN   \n",
       "13                NaN           NaN        NaN            NaN          NaN   \n",
       "16                NaN           NaN        NaN            NaN          NaN   \n",
       "\n",
       "    lgbtq+ hip hop  reggaeton colombiano  houston rap  modern folk rock  \\\n",
       "5              NaN                   NaN          NaN               NaN   \n",
       "13             NaN                   NaN          NaN               NaN   \n",
       "16             NaN                   NaN          NaN               NaN   \n",
       "\n",
       "    stomp and holler  uk americana  alternative hip hop  europop  cartoon  \\\n",
       "5                NaN           NaN                  NaN      NaN      NaN   \n",
       "13               NaN           NaN                  NaN      NaN      NaN   \n",
       "16               NaN           NaN                  NaN      NaN      NaN   \n",
       "\n",
       "    children's music  arkansas country  funk  soul  mexican pop  crunk  \\\n",
       "5                NaN               NaN   NaN   NaN          NaN    NaN   \n",
       "13               NaN               NaN   NaN   NaN          NaN    NaN   \n",
       "16               NaN               NaN   NaN   NaN          NaN    NaN   \n",
       "\n",
       "    electro  disco house  idol  social media pop  hawaiian hip hop  \\\n",
       "5       NaN          NaN   NaN               NaN               NaN   \n",
       "13      NaN          NaN   NaN               NaN               NaN   \n",
       "16      NaN          NaN   NaN               NaN               NaN   \n",
       "\n",
       "    vapor trap  grunge  hard rock  k-pop  k-pop boy group  electropowerpop  \\\n",
       "5          NaN     NaN        NaN    NaN              NaN              NaN   \n",
       "13         NaN     NaN        NaN    NaN              NaN              NaN   \n",
       "16         NaN     NaN        NaN    NaN              NaN              NaN   \n",
       "\n",
       "    neon pop punk  trancecore  album rock  classic rock  dance rock  \\\n",
       "5             NaN         NaN         NaN           NaN         NaN   \n",
       "13            NaN         NaN         NaN           NaN         NaN   \n",
       "16            NaN         NaN         NaN           NaN         NaN   \n",
       "\n",
       "    glam rock  protopunk  north carolina hip hop  house  uk dance  \\\n",
       "5         NaN        NaN                     NaN    NaN       NaN   \n",
       "13        NaN        NaN                     NaN    NaN       NaN   \n",
       "16        NaN        NaN                     NaN    NaN       NaN   \n",
       "\n",
       "    nu-metalcore  trap soul  rock-and-roll  rockabilly  groove metal  \\\n",
       "5            NaN        NaN            NaN         NaN           NaN   \n",
       "13           NaN        NaN            NaN         NaN           NaN   \n",
       "16           NaN        NaN            NaN         NaN           NaN   \n",
       "\n",
       "    rap conscient  drill  baroque pop  uk contemporary r&b  indiecoustica  \\\n",
       "5             NaN    NaN          NaN                  NaN            NaN   \n",
       "13            NaN    NaN          NaN                  NaN            NaN   \n",
       "16            NaN    NaN          NaN                  NaN            NaN   \n",
       "\n",
       "    lds youth  lilith  celtic rock  reggae fusion  canadian trap  \\\n",
       "5         NaN     NaN          NaN            NaN            NaN   \n",
       "13        NaN     NaN          NaN            NaN            NaN   \n",
       "16        NaN     NaN          NaN            NaN            NaN   \n",
       "\n",
       "    outlaw country  ccm  christian alternative rock  christian indie  \\\n",
       "5              NaN  NaN                         NaN              NaN   \n",
       "13             NaN  NaN                         NaN              NaN   \n",
       "16             NaN  NaN                         NaN              NaN   \n",
       "\n",
       "    christian music  worship  moombahton  neo-singer-songwriter  neo-synthpop  \\\n",
       "5               NaN      NaN         NaN                    NaN           NaN   \n",
       "13              NaN      NaN         NaN                    NaN           NaN   \n",
       "16              NaN      NaN         NaN                    NaN           NaN   \n",
       "\n",
       "    neo-traditional country  folk  new wave pop  singer-songwriter  \\\n",
       "5                       NaN   NaN           NaN                NaN   \n",
       "13                      NaN   NaN           NaN                NaN   \n",
       "16                      NaN   NaN           NaN                NaN   \n",
       "\n",
       "    aussietronica  irish rock  disney  florida rap  colombian pop  a cappella  \\\n",
       "5             NaN         NaN     NaN          NaN            NaN         NaN   \n",
       "13            NaN         NaN     NaN          NaN            NaN         NaN   \n",
       "16            NaN         NaN     NaN          NaN            NaN         NaN   \n",
       "\n",
       "    latin viral pop  rap latina  viral rap  la indie  indie electropop  \\\n",
       "5               NaN         NaN        NaN       NaN               NaN   \n",
       "13              NaN         NaN        NaN       NaN               NaN   \n",
       "16              NaN         NaN        NaN       NaN               NaN   \n",
       "\n",
       "    la pop  pop edm  portland hip hop  viral trap  deep southern trap  \\\n",
       "5      NaN      NaN               NaN         NaN                 NaN   \n",
       "13     NaN      NaN               NaN         NaN                 NaN   \n",
       "16     NaN      NaN               NaN         NaN                 NaN   \n",
       "\n",
       "    hopebeat  k-hop  san diego rap  teen pop  modern alternative rock  \\\n",
       "5        NaN    NaN            NaN       NaN                      NaN   \n",
       "13       NaN    NaN            NaN       NaN                      NaN   \n",
       "16       NaN    NaN            NaN       NaN                      NaN   \n",
       "\n",
       "    nu gaze  motown  ghanaian hip hop  canadian indie  new americana  \\\n",
       "5       NaN     NaN               NaN             NaN            NaN   \n",
       "13      NaN     NaN               NaN             NaN            NaN   \n",
       "16      NaN     NaN               NaN             NaN            NaN   \n",
       "\n",
       "    modern blues rock  south african rock  pop soul  swedish synthpop  \\\n",
       "5                 NaN                 NaN       NaN               NaN   \n",
       "13                NaN                 NaN       NaN               NaN   \n",
       "16                NaN                 NaN       NaN               NaN   \n",
       "\n",
       "    escape room  indie soul  heartland rock  k-rap  funk metal  funk rock  \\\n",
       "5           NaN         NaN             NaN    NaN         NaN        NaN   \n",
       "13          NaN         NaN             NaN    NaN         NaN        NaN   \n",
       "16          NaN         NaN             NaN    NaN         NaN        NaN   \n",
       "\n",
       "    nyc pop  garage rock  sheffield indie  uk alternative pop  mellow gold  \\\n",
       "5       NaN          NaN              NaN                 NaN          NaN   \n",
       "13      NaN          NaN              NaN                 NaN          NaN   \n",
       "16      NaN          NaN              NaN                 NaN          NaN   \n",
       "\n",
       "    soft rock  yacht rock  latin arena pop  latin rock  mexican rock  \\\n",
       "5         NaN         NaN              NaN         NaN           NaN   \n",
       "13        NaN         NaN              NaN         NaN           NaN   \n",
       "16        NaN         NaN              NaN         NaN           NaN   \n",
       "\n",
       "    rock en espanol  bubblegum dance  eurodance  \\\n",
       "5               NaN              NaN        NaN   \n",
       "13              NaN              NaN        NaN   \n",
       "16              NaN              NaN        NaN   \n",
       "\n",
       "    melbourne bounce international  country rock  comedy  comic  j-pop  \\\n",
       "5                              NaN           NaN     NaN    NaN    NaN   \n",
       "13                             NaN           NaN     NaN    NaN    NaN   \n",
       "16                             NaN           NaN     NaN    NaN    NaN   \n",
       "\n",
       "    japanese singer-songwriter  post-metal  progressive metal  \\\n",
       "5                          NaN         NaN                NaN   \n",
       "13                         NaN         NaN                NaN   \n",
       "16                         NaN         NaN                NaN   \n",
       "\n",
       "    progressive rock  blues rock  punk blues  detroit trap  bow pop  \\\n",
       "5                NaN         NaN         NaN           NaN      NaN   \n",
       "13               NaN         NaN         NaN           NaN      NaN   \n",
       "16               NaN         NaN         NaN           NaN      NaN   \n",
       "\n",
       "    roots americana  hyphy  australian indie  filter house  ectofolk  nz pop  \\\n",
       "5               NaN    NaN               NaN           NaN       NaN     NaN   \n",
       "13              NaN    NaN               NaN           NaN       NaN     NaN   \n",
       "16              NaN    NaN               NaN           NaN       NaN     NaN   \n",
       "\n",
       "    anthem worship  world worship  cedm  christian pop  minnesota hip hop  \\\n",
       "5              NaN            NaN   NaN            NaN                NaN   \n",
       "13             NaN            NaN   NaN            NaN                NaN   \n",
       "16             NaN            NaN   NaN            NaN                NaN   \n",
       "\n",
       "    dancehall  canadian country  canadian singer-songwriter  canadian folk  \\\n",
       "5         NaN               NaN                         NaN            NaN   \n",
       "13        NaN               NaN                         NaN            NaN   \n",
       "16        NaN               NaN                         NaN            NaN   \n",
       "\n",
       "    folk rock  bass trap  vapor twitch  alt z  bedroom pop  vocal house  \\\n",
       "5         NaN        NaN           NaN    NaN          NaN          NaN   \n",
       "13        NaN        NaN           NaN    NaN          NaN          NaN   \n",
       "16        NaN        NaN           NaN    NaN          NaN          NaN   \n",
       "\n",
       "    chicago hardcore  chicago punk  hardcore punk  cowboy western  \\\n",
       "5                NaN           NaN            NaN             NaN   \n",
       "13               NaN           NaN            NaN             NaN   \n",
       "16               NaN           NaN            NaN             NaN   \n",
       "\n",
       "    traditional country  yodeling  alabama indie  lovers rock  country rap  \\\n",
       "5                   NaN       NaN            NaN          NaN          NaN   \n",
       "13                  NaN       NaN            NaN          NaN          NaN   \n",
       "16                  NaN       NaN            NaN          NaN          NaN   \n",
       "\n",
       "    queer country  movie tunes  k-pop girl group  chicago drill  uk funky  \\\n",
       "5             NaN          NaN               NaN            NaN       NaN   \n",
       "13            NaN          NaN               NaN            NaN       NaN   \n",
       "16            NaN          NaN               NaN            NaN       NaN   \n",
       "\n",
       "    gospel  gospel r&b  chicago indie  minneapolis sound  bubblegum pop  \\\n",
       "5      NaN         NaN            NaN                NaN            NaN   \n",
       "13     NaN         NaN            NaN                NaN            NaN   \n",
       "16     NaN         NaN            NaN                NaN            NaN   \n",
       "\n",
       "    classic country pop  classic uk pop  nashville sound  boston hip hop  \\\n",
       "5                   NaN             NaN              NaN             NaN   \n",
       "13                  NaN             NaN              NaN             NaN   \n",
       "16                  NaN             NaN              NaN             NaN   \n",
       "\n",
       "    modern southern rock  trance  trap boricua  champeta  vallenato  \\\n",
       "5                    NaN     NaN           NaN       NaN        NaN   \n",
       "13                   NaN     NaN           NaN       NaN        NaN   \n",
       "16                   NaN     NaN           NaN       NaN        NaN   \n",
       "\n",
       "    liquid funk  chicago house  chinese hip hop  chinese idol pop  \\\n",
       "5           NaN            NaN              NaN               NaN   \n",
       "13          NaN            NaN              NaN               NaN   \n",
       "16          NaN            NaN              NaN               NaN   \n",
       "\n",
       "    alternative pop rock  glam metal  virgin islands reggae  destroy techno  \\\n",
       "5                    NaN         NaN                    NaN             NaN   \n",
       "13                   NaN         NaN                    NaN             NaN   \n",
       "16                   NaN         NaN                    NaN             NaN   \n",
       "\n",
       "    electronic rock  christian rock  rap rock  tennessee hip hop  jam band  \\\n",
       "5               NaN             NaN       NaN                NaN       NaN   \n",
       "13              NaN             NaN       NaN                NaN       NaN   \n",
       "16              NaN             NaN       NaN                NaN       NaN   \n",
       "\n",
       "    french shoegaze  romanian pop  pop r&b  australian electropop  \\\n",
       "5               NaN           NaN      NaN                    NaN   \n",
       "13              NaN           NaN      NaN                    NaN   \n",
       "16              NaN           NaN      NaN                    NaN   \n",
       "\n",
       "    israeli pop  rebel blues  celtic  middle earth  panamanian pop  \\\n",
       "5           NaN          NaN     NaN           NaN             NaN   \n",
       "13          NaN          NaN     NaN           NaN             NaN   \n",
       "16          NaN          NaN     NaN           NaN             NaN   \n",
       "\n",
       "    brooklyn indie  lo star  drum and bass  canadian electronic  chamber pop  \\\n",
       "5              NaN      NaN            NaN                  NaN          NaN   \n",
       "13             NaN      NaN            NaN                  NaN          NaN   \n",
       "16             NaN      NaN            NaN                  NaN          NaN   \n",
       "\n",
       "    quebec indie  stomp pop  pop dance  slap house  broadway  alabama rap  \\\n",
       "5            NaN        NaN        NaN         NaN       NaN          NaN   \n",
       "13           NaN        NaN        NaN         NaN       NaN          NaN   \n",
       "16           NaN        NaN        NaN         NaN       NaN          NaN   \n",
       "\n",
       "    shimmer pop  battle rap  alberta country  canadian contemporary country  \\\n",
       "5           NaN         NaN              NaN                            NaN   \n",
       "13          NaN         NaN              NaN                            NaN   \n",
       "16          NaN         NaN              NaN                            NaN   \n",
       "\n",
       "    classic girl group  irish singer-songwriter  indy indie  german pop  \\\n",
       "5                  NaN                      NaN         NaN         NaN   \n",
       "13                 NaN                      NaN         NaN         NaN   \n",
       "16                 NaN                      NaN         NaN         NaN   \n",
       "\n",
       "    old school hip hop  deep euro house  deep house  german dance  \\\n",
       "5                  NaN              NaN         NaN           NaN   \n",
       "13                 NaN              NaN         NaN           NaN   \n",
       "16                 NaN              NaN         NaN           NaN   \n",
       "\n",
       "    bedroom soul  metal  scorecore  soundtrack  indie folk  \\\n",
       "5            NaN    NaN        NaN         NaN         NaN   \n",
       "13           NaN    NaN        NaN         NaN         NaN   \n",
       "16           NaN    NaN        NaN         NaN         NaN   \n",
       "\n",
       "    progressive trance  grime  deep underground hip hop  vapor pop  \\\n",
       "5                  NaN    NaN                       NaN        NaN   \n",
       "13                 NaN    NaN                       NaN        NaN   \n",
       "16                 NaN    NaN                       NaN        NaN   \n",
       "\n",
       "    modern salsa  salsa  pinoy hip hop  dutch hip hop  icelandic indie  \\\n",
       "5            NaN    NaN            NaN            NaN              NaN   \n",
       "13           NaN    NaN            NaN            NaN              NaN   \n",
       "16           NaN    NaN            NaN            NaN              NaN   \n",
       "\n",
       "    icelandic rock  australian house  bass house  jazz rap  bmore  ninja  \\\n",
       "5              NaN               NaN         NaN       NaN    NaN    NaN   \n",
       "13             NaN               NaN         NaN       NaN    NaN    NaN   \n",
       "16             NaN               NaN         NaN       NaN    NaN    NaN   \n",
       "\n",
       "    arkansas hip hop  antiviral pop  comedy rock  parody  indie r&b  \n",
       "5                NaN            NaN          NaN     NaN        NaN  \n",
       "13               NaN            NaN          NaN     NaN        NaN  \n",
       "16               NaN            NaN          NaN     NaN        NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongID</th>\n",
       "      <th>spotify_genre</th>\n",
       "      <th>spotify_track_id</th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>Max_Peak_Position</th>\n",
       "      <th>Max_Rank_Change</th>\n",
       "      <th>pop</th>\n",
       "      <th>rap</th>\n",
       "      <th>pop rap</th>\n",
       "      <th>dance pop</th>\n",
       "      <th>post-teen pop</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>trap</th>\n",
       "      <th>contemporary country</th>\n",
       "      <th>country road</th>\n",
       "      <th>country</th>\n",
       "      <th>southern hip hop</th>\n",
       "      <th>modern country rock</th>\n",
       "      <th>atl hip hop</th>\n",
       "      <th>r&amp;b</th>\n",
       "      <th>canadian pop</th>\n",
       "      <th>melodic rap</th>\n",
       "      <th>urban contemporary</th>\n",
       "      <th>pop rock</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>glee club</th>\n",
       "      <th>neo mellow</th>\n",
       "      <th>canadian hip hop</th>\n",
       "      <th>toronto rap</th>\n",
       "      <th>edm</th>\n",
       "      <th>gangster rap</th>\n",
       "      <th>country pop</th>\n",
       "      <th>tropical house</th>\n",
       "      <th>hip pop</th>\n",
       "      <th>modern rock</th>\n",
       "      <th>miami hip hop</th>\n",
       "      <th>latin</th>\n",
       "      <th>electropop</th>\n",
       "      <th>chicago rap</th>\n",
       "      <th>conscious hip hop</th>\n",
       "      <th>viral pop</th>\n",
       "      <th>country dawn</th>\n",
       "      <th>uk pop</th>\n",
       "      <th>dirty south rap</th>\n",
       "      <th>philly rap</th>\n",
       "      <th>detroit hip hop</th>\n",
       "      <th>alternative r&amp;b</th>\n",
       "      <th>post-grunge</th>\n",
       "      <th>oklahoma country</th>\n",
       "      <th>talent show</th>\n",
       "      <th>canadian contemporary r&amp;b</th>\n",
       "      <th>neo soul</th>\n",
       "      <th>boy band</th>\n",
       "      <th>reggaeton</th>\n",
       "      <th>electro house</th>\n",
       "      <th>rock</th>\n",
       "      <th>atl trap</th>\n",
       "      <th>nc hip hop</th>\n",
       "      <th>new orleans rap</th>\n",
       "      <th>emo rap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...Ready For It?Taylor Swift</td>\n",
       "      <td>['pop', 'post-teen pop']</td>\n",
       "      <td>2yLa0QULdQr0qAIvVwN6B5</td>\n",
       "      <td>208186.0</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.417</td>\n",
       "      <td>160.015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'Til Summer Comes AroundKeith Urban</td>\n",
       "      <td>['australian country', 'contemporary country',...</td>\n",
       "      <td>1CKmI1IQjVEVB3F7VmJmM3</td>\n",
       "      <td>331466.0</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.629</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.308</td>\n",
       "      <td>127.907</td>\n",
       "      <td>4.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'Tis The Damn SeasonTaylor Swift</td>\n",
       "      <td>['pop', 'post-teen pop']</td>\n",
       "      <td>7dW84mWkdWE5a6lFWxJCBG</td>\n",
       "      <td>229840.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.434</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-8.193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.348</td>\n",
       "      <td>145.916</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 SongID  \\\n",
       "5          ...Ready For It?Taylor Swift   \n",
       "13  'Til Summer Comes AroundKeith Urban   \n",
       "16     'Tis The Damn SeasonTaylor Swift   \n",
       "\n",
       "                                        spotify_genre        spotify_track_id  \\\n",
       "5                            ['pop', 'post-teen pop']  2yLa0QULdQr0qAIvVwN6B5   \n",
       "13  ['australian country', 'contemporary country',...  1CKmI1IQjVEVB3F7VmJmM3   \n",
       "16                           ['pop', 'post-teen pop']  7dW84mWkdWE5a6lFWxJCBG   \n",
       "\n",
       "    spotify_track_duration_ms  danceability  energy  key  loudness  mode  \\\n",
       "5                    208186.0         0.613   0.764  2.0    -6.509   1.0   \n",
       "13                   331466.0         0.570   0.629  9.0    -7.608   0.0   \n",
       "16                   229840.0         0.575   0.434  5.0    -8.193   1.0   \n",
       "\n",
       "    speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "5        0.1360        0.0527          0.000000     0.197    0.417  160.015   \n",
       "13       0.0331        0.5930          0.000136     0.770    0.308  127.907   \n",
       "16       0.0312        0.7350          0.000066     0.105    0.348  145.916   \n",
       "\n",
       "    time_signature  Max_Peak_Position  Max_Rank_Change  pop  rap  pop rap  \\\n",
       "5              4.0                4.0             22.0  0.0  0.0      0.0   \n",
       "13             4.0               92.0             14.0  0.0  1.0      1.0   \n",
       "16             4.0               39.0              0.0  0.0  0.0      0.0   \n",
       "\n",
       "    dance pop  post-teen pop  hip hop  trap  contemporary country  \\\n",
       "5         0.0            0.0      0.0   0.0                   0.0   \n",
       "13        0.0            0.0      0.0   0.0                   0.0   \n",
       "16        0.0            0.0      0.0   0.0                   1.0   \n",
       "\n",
       "    country road  country  southern hip hop  modern country rock  atl hip hop  \\\n",
       "5            0.0      0.0               0.0                  1.0          0.0   \n",
       "13           0.0      0.0               0.0                  0.0          0.0   \n",
       "16           0.0      0.0               0.0                  0.0          0.0   \n",
       "\n",
       "    r&b  canadian pop  melodic rap  urban contemporary  pop rock  hollywood  \\\n",
       "5   0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       "13  0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       "16  0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       "\n",
       "    glee club  neo mellow  canadian hip hop  toronto rap  edm  gangster rap  \\\n",
       "5         0.0         0.0               0.0          0.0  0.0           0.0   \n",
       "13        0.0         0.0               0.0          0.0  0.0           0.0   \n",
       "16        0.0         0.0               0.0          0.0  0.0           0.0   \n",
       "\n",
       "    country pop  tropical house  hip pop  modern rock  miami hip hop  latin  \\\n",
       "5           0.0             0.0      0.0          0.0            0.0    0.0   \n",
       "13          0.0             0.0      0.0          0.0            0.0    0.0   \n",
       "16          0.0             0.0      0.0          0.0            0.0    0.0   \n",
       "\n",
       "    electropop  chicago rap  conscious hip hop  viral pop  country dawn  \\\n",
       "5          0.0          0.0                0.0        0.0           0.0   \n",
       "13         0.0          0.0                0.0        0.0           0.0   \n",
       "16         0.0          0.0                0.0        0.0           0.0   \n",
       "\n",
       "    uk pop  dirty south rap  philly rap  detroit hip hop  alternative r&b  \\\n",
       "5      0.0              0.0         0.0              0.0              0.0   \n",
       "13     0.0              0.0         0.0              0.0              0.0   \n",
       "16     0.0              0.0         0.0              0.0              0.0   \n",
       "\n",
       "    post-grunge  oklahoma country  talent show  canadian contemporary r&b  \\\n",
       "5           0.0               0.0          0.0                        0.0   \n",
       "13          0.0               0.0          0.0                        0.0   \n",
       "16          0.0               0.0          0.0                        0.0   \n",
       "\n",
       "    neo soul  boy band  reggaeton  electro house  rock  atl trap  nc hip hop  \\\n",
       "5        0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       "13       0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       "16       0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       "\n",
       "    new orleans rap  emo rap  \n",
       "5               0.0      0.0  \n",
       "13              0.0      0.0  \n",
       "16              0.0      0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my code added columns for all genres in spotify_genre, removing unwanted columns :(\n",
    "last_col_to_keep = 'emo rap'\n",
    "df_cleaned = df_cleaned.loc[:, :last_col_to_keep]\n",
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    spotify_track_duration_ms  danceability  energy  key  loudness  mode  \\\n",
       " 5                    208186.0         0.613   0.764  2.0    -6.509   1.0   \n",
       " 13                   331466.0         0.570   0.629  9.0    -7.608   0.0   \n",
       " 16                   229840.0         0.575   0.434  5.0    -8.193   1.0   \n",
       " \n",
       "     speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       " 5        0.1360        0.0527          0.000000     0.197    0.417  160.015   \n",
       " 13       0.0331        0.5930          0.000136     0.770    0.308  127.907   \n",
       " 16       0.0312        0.7350          0.000066     0.105    0.348  145.916   \n",
       " \n",
       "     time_signature  Max_Peak_Position  Max_Rank_Change  pop  rap  pop rap  \\\n",
       " 5              4.0                4.0             22.0  0.0  0.0      0.0   \n",
       " 13             4.0               92.0             14.0  0.0  1.0      1.0   \n",
       " 16             4.0               39.0              0.0  0.0  0.0      0.0   \n",
       " \n",
       "     dance pop  post-teen pop  hip hop  trap  contemporary country  \\\n",
       " 5         0.0            0.0      0.0   0.0                   0.0   \n",
       " 13        0.0            0.0      0.0   0.0                   0.0   \n",
       " 16        0.0            0.0      0.0   0.0                   1.0   \n",
       " \n",
       "     country road  country  southern hip hop  modern country rock  atl hip hop  \\\n",
       " 5            0.0      0.0               0.0                  1.0          0.0   \n",
       " 13           0.0      0.0               0.0                  0.0          0.0   \n",
       " 16           0.0      0.0               0.0                  0.0          0.0   \n",
       " \n",
       "     r&b  canadian pop  melodic rap  urban contemporary  pop rock  hollywood  \\\n",
       " 5   0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       " 13  0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       " 16  0.0           0.0          0.0                 0.0       0.0        0.0   \n",
       " \n",
       "     glee club  neo mellow  canadian hip hop  toronto rap  edm  gangster rap  \\\n",
       " 5         0.0         0.0               0.0          0.0  0.0           0.0   \n",
       " 13        0.0         0.0               0.0          0.0  0.0           0.0   \n",
       " 16        0.0         0.0               0.0          0.0  0.0           0.0   \n",
       " \n",
       "     country pop  tropical house  hip pop  modern rock  miami hip hop  latin  \\\n",
       " 5           0.0             0.0      0.0          0.0            0.0    0.0   \n",
       " 13          0.0             0.0      0.0          0.0            0.0    0.0   \n",
       " 16          0.0             0.0      0.0          0.0            0.0    0.0   \n",
       " \n",
       "     electropop  chicago rap  conscious hip hop  viral pop  country dawn  \\\n",
       " 5          0.0          0.0                0.0        0.0           0.0   \n",
       " 13         0.0          0.0                0.0        0.0           0.0   \n",
       " 16         0.0          0.0                0.0        0.0           0.0   \n",
       " \n",
       "     uk pop  dirty south rap  philly rap  detroit hip hop  alternative r&b  \\\n",
       " 5      0.0              0.0         0.0              0.0              0.0   \n",
       " 13     0.0              0.0         0.0              0.0              0.0   \n",
       " 16     0.0              0.0         0.0              0.0              0.0   \n",
       " \n",
       "     post-grunge  oklahoma country  talent show  canadian contemporary r&b  \\\n",
       " 5           0.0               0.0          0.0                        0.0   \n",
       " 13          0.0               0.0          0.0                        0.0   \n",
       " 16          0.0               0.0          0.0                        0.0   \n",
       " \n",
       "     neo soul  boy band  reggaeton  electro house  rock  atl trap  nc hip hop  \\\n",
       " 5        0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       " 13       0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       " 16       0.0       0.0        0.0            0.0   0.0       0.0         0.0   \n",
       " \n",
       "     new orleans rap  emo rap  \n",
       " 5               0.0      0.0  \n",
       " 13              0.0      0.0  \n",
       " 16              0.0      0.0  ,\n",
       "       spotify_track_duration_ms  danceability  energy  key  loudness  mode  \\\n",
       " 4710                        NaN           NaN     NaN  NaN       NaN   NaN   \n",
       " 4711                        NaN           NaN     NaN  NaN       NaN   NaN   \n",
       " 4712                        NaN           NaN     NaN  NaN       NaN   NaN   \n",
       " \n",
       "       speechiness  acousticness  instrumentalness  liveness  valence  tempo  \\\n",
       " 4710          NaN           NaN               NaN       NaN      NaN    NaN   \n",
       " 4711          NaN           NaN               NaN       NaN      NaN    NaN   \n",
       " 4712          NaN           NaN               NaN       NaN      NaN    NaN   \n",
       " \n",
       "       time_signature  Max_Peak_Position  Max_Rank_Change  pop  rap  pop rap  \\\n",
       " 4710             NaN                NaN              NaN  NaN  1.0      1.0   \n",
       " 4711             NaN                NaN              NaN  NaN  NaN      NaN   \n",
       " 4712             NaN                NaN              NaN  NaN  1.0      1.0   \n",
       " \n",
       "       dance pop  post-teen pop  hip hop  trap  contemporary country  \\\n",
       " 4710        NaN            NaN      1.0   1.0                   NaN   \n",
       " 4711        NaN            NaN      NaN   NaN                   NaN   \n",
       " 4712        NaN            NaN      1.0   1.0                   NaN   \n",
       " \n",
       "       country road  country  southern hip hop  modern country rock  \\\n",
       " 4710           NaN      NaN               1.0                  NaN   \n",
       " 4711           NaN      NaN               NaN                  NaN   \n",
       " 4712           NaN      NaN               1.0                  NaN   \n",
       " \n",
       "       atl hip hop  r&b  canadian pop  melodic rap  urban contemporary  \\\n",
       " 4710          NaN  NaN           NaN          1.0                 NaN   \n",
       " 4711          NaN  NaN           NaN          NaN                 NaN   \n",
       " 4712          1.0  NaN           NaN          NaN                 NaN   \n",
       " \n",
       "       pop rock  hollywood  glee club  neo mellow  canadian hip hop  \\\n",
       " 4710       NaN        NaN        NaN         NaN               NaN   \n",
       " 4711       NaN        NaN        NaN         NaN               NaN   \n",
       " 4712       NaN        NaN        NaN         NaN               NaN   \n",
       " \n",
       "       toronto rap  edm  gangster rap  country pop  tropical house  hip pop  \\\n",
       " 4710          NaN  NaN           NaN          NaN             NaN      NaN   \n",
       " 4711          NaN  NaN           NaN          NaN             NaN      NaN   \n",
       " 4712          NaN  NaN           NaN          NaN             NaN      NaN   \n",
       " \n",
       "       modern rock  miami hip hop  latin  electropop  chicago rap  \\\n",
       " 4710          NaN            1.0    NaN         NaN          NaN   \n",
       " 4711          NaN            NaN    NaN         NaN          NaN   \n",
       " 4712          NaN            NaN    NaN         NaN          NaN   \n",
       " \n",
       "       conscious hip hop  viral pop  country dawn  uk pop  dirty south rap  \\\n",
       " 4710                NaN        NaN           NaN     NaN              NaN   \n",
       " 4711                NaN        NaN           NaN     NaN              NaN   \n",
       " 4712                NaN        NaN           NaN     NaN              NaN   \n",
       " \n",
       "       philly rap  detroit hip hop  alternative r&b  post-grunge  \\\n",
       " 4710         NaN              NaN              NaN          NaN   \n",
       " 4711         NaN              NaN              NaN          1.0   \n",
       " 4712         NaN              NaN              NaN          NaN   \n",
       " \n",
       "       oklahoma country  talent show  canadian contemporary r&b  neo soul  \\\n",
       " 4710               NaN          NaN                        NaN       NaN   \n",
       " 4711               NaN          NaN                        NaN       NaN   \n",
       " 4712               NaN          NaN                        NaN       NaN   \n",
       " \n",
       "       boy band  reggaeton  electro house  rock  atl trap  nc hip hop  \\\n",
       " 4710       NaN        NaN            NaN   NaN       NaN         NaN   \n",
       " 4711       NaN        NaN            NaN   NaN       NaN         NaN   \n",
       " 4712       NaN        NaN            NaN   NaN       NaN         NaN   \n",
       " \n",
       "       new orleans rap  emo rap  \n",
       " 4710              NaN      NaN  \n",
       " 4711              NaN      NaN  \n",
       " 4712              NaN      NaN  )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing fields used for prep/cleaning but not needed for analysis\n",
    "df_cleaned = df_cleaned.drop(['SongID', 'spotify_genre', 'spotify_track_id'], axis=1)\n",
    "df_cleaned.head(3), df_cleaned.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4713 entries, 5 to 29499\n",
      "Data columns (total 69 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   spotify_track_duration_ms  4713 non-null   float64\n",
      " 1   danceability               4713 non-null   float64\n",
      " 2   energy                     4713 non-null   float64\n",
      " 3   key                        4713 non-null   float64\n",
      " 4   loudness                   4713 non-null   float64\n",
      " 5   mode                       4713 non-null   float64\n",
      " 6   speechiness                4713 non-null   float64\n",
      " 7   acousticness               4713 non-null   float64\n",
      " 8   instrumentalness           4713 non-null   float64\n",
      " 9   liveness                   4713 non-null   float64\n",
      " 10  valence                    4713 non-null   float64\n",
      " 11  tempo                      4713 non-null   float64\n",
      " 12  time_signature             4713 non-null   float64\n",
      " 13  Max_Peak_Position          4713 non-null   float64\n",
      " 14  Max_Rank_Change            4713 non-null   float64\n",
      " 15  pop                        4713 non-null   float64\n",
      " 16  rap                        4713 non-null   float64\n",
      " 17  pop rap                    4713 non-null   float64\n",
      " 18  dance pop                  4713 non-null   float64\n",
      " 19  post-teen pop              4713 non-null   float64\n",
      " 20  hip hop                    4713 non-null   float64\n",
      " 21  trap                       4713 non-null   float64\n",
      " 22  contemporary country       4713 non-null   float64\n",
      " 23  country road               4713 non-null   float64\n",
      " 24  country                    4713 non-null   float64\n",
      " 25  southern hip hop           4713 non-null   float64\n",
      " 26  modern country rock        4713 non-null   float64\n",
      " 27  atl hip hop                4713 non-null   float64\n",
      " 28  r&b                        4713 non-null   float64\n",
      " 29  canadian pop               4713 non-null   float64\n",
      " 30  melodic rap                4713 non-null   float64\n",
      " 31  urban contemporary         4713 non-null   float64\n",
      " 32  pop rock                   4713 non-null   float64\n",
      " 33  hollywood                  4713 non-null   float64\n",
      " 34  glee club                  4713 non-null   float64\n",
      " 35  neo mellow                 4713 non-null   float64\n",
      " 36  canadian hip hop           4713 non-null   float64\n",
      " 37  toronto rap                4713 non-null   float64\n",
      " 38  edm                        4713 non-null   float64\n",
      " 39  gangster rap               4713 non-null   float64\n",
      " 40  country pop                4713 non-null   float64\n",
      " 41  tropical house             4713 non-null   float64\n",
      " 42  hip pop                    4713 non-null   float64\n",
      " 43  modern rock                4713 non-null   float64\n",
      " 44  miami hip hop              4713 non-null   float64\n",
      " 45  latin                      4713 non-null   float64\n",
      " 46  electropop                 4713 non-null   float64\n",
      " 47  chicago rap                4713 non-null   float64\n",
      " 48  conscious hip hop          4713 non-null   float64\n",
      " 49  viral pop                  4713 non-null   float64\n",
      " 50  country dawn               4713 non-null   float64\n",
      " 51  uk pop                     4713 non-null   float64\n",
      " 52  dirty south rap            4713 non-null   float64\n",
      " 53  philly rap                 4713 non-null   float64\n",
      " 54  detroit hip hop            4713 non-null   float64\n",
      " 55  alternative r&b            4713 non-null   float64\n",
      " 56  post-grunge                4713 non-null   float64\n",
      " 57  oklahoma country           4713 non-null   float64\n",
      " 58  talent show                4713 non-null   float64\n",
      " 59  canadian contemporary r&b  4713 non-null   float64\n",
      " 60  neo soul                   4713 non-null   float64\n",
      " 61  boy band                   4713 non-null   float64\n",
      " 62  reggaeton                  4713 non-null   float64\n",
      " 63  electro house              4713 non-null   float64\n",
      " 64  rock                       4713 non-null   float64\n",
      " 65  atl trap                   4713 non-null   float64\n",
      " 66  nc hip hop                 4713 non-null   float64\n",
      " 67  new orleans rap            4713 non-null   float64\n",
      " 68  emo rap                    4713 non-null   float64\n",
      "dtypes: float64(69)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_cleaned.dropna()\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for max_peak_position analysis\n",
    "X1 = df_cleaned.drop(['Max_Peak_Position', 'Max_Rank_Change'], axis=1)\n",
    "y1 = df_cleaned['Max_Peak_Position']\n",
    "\n",
    "# Splitting the data into training and testing sets (75-25 split and random_state of 42)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X1_train)\n",
    "X1_test_scaled = scaler.fit_transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for max_rank_change analysis\n",
    "X2 = df_cleaned.drop(['Max_Peak_Position', 'Max_Rank_Change'], axis=1)\n",
    "y2 = df_cleaned['Max_Rank_Change']\n",
    "\n",
    "# Splitting the data into training and testing sets (75-25 split and random_state of 42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X2_train_scaled = scaler.fit_transform(X2_train)\n",
    "X2_test_scaled = scaler.fit_transform(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN model for max_peak_position\n",
    "\n",
    "# testing different distance metrics to find optimal approach\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
    "k_value = 5\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop through list of metrics\n",
    "for metric in metrics:\n",
    "        # Create and evaluate model with different metrics and k=5\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_value, metric=metric)\n",
    "    # Get cross val scores for model\n",
    "    cv_scores = cross_val_score(knn, X1_train_scaled, y1_train, cv=5, scoring='accuracy')\n",
    "    # Store the mean of cv scores as value and metric name as key in results dictionary\n",
    "    results[metric] = cv_scores.mean()\n",
    "\n",
    "best_metric = max(results, key=results.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'euclidean': 0.011318222069070526, 'manhattan': 0.00877185249888809, 'chebyshev': 0.012734251976391487}\n",
      "\n",
      "Best metric: chebyshev with accuracy: 0.0127\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(f\"\\nBest metric: {best_metric} with accuracy: {results[best_metric]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# k-NN model for max_rank_change\n",
    "\n",
    "# testing different distance metrics to find optimal approach\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
    "k_value = 5\n",
    "\n",
    "# Dictionary to store results\n",
    "results2 = {}\n",
    "\n",
    "# Loop through list of metrics\n",
    "for metric in metrics:\n",
    "        # Create and evaluate model with different metrics and k=5\n",
    "    knn2 = KNeighborsClassifier(n_neighbors=k_value, metric=metric)\n",
    "    # Get cross val scores for model\n",
    "    cv_scores2 = cross_val_score(knn2, X2_train_scaled, y2_train, cv=5, scoring='accuracy')\n",
    "    # Store the mean of cv scores as value and metric name as key in results dictionary\n",
    "    results2[metric] = cv_scores2.mean()\n",
    "\n",
    "best_metric2 = max(results2, key=results2.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'euclidean': 0.26598523065580537, 'manhattan': 0.2739092282356524, 'chebyshev': 0.2710819766719691}\n",
      "\n",
      "Best metric: manhattan with accuracy: 0.2739\n"
     ]
    }
   ],
   "source": [
    "print(results2)\n",
    "print(f\"\\nBest metric: {best_metric2} with accuracy: {results2[best_metric2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Business Insight/Recommendation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau Dashboard link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "Text here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
