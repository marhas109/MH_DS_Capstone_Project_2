{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Add a relevant banner image here](path_to_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project seeks to build machine learning models to achieve two things:\n",
    "\n",
    "1. Predict the highest ranking a song will achieve on the Billboard Hot 100 list.\n",
    "2. Predict the largest week over week increase in a given song's ranking on the Hot 100 list.\n",
    "\n",
    "Key Insights:\n",
    "\n",
    "- A song's genre has a minimal impact on its ranking on the Billboard Hot 100 list.\n",
    "- Song characteristics such as tempo, danceability, etc. appear to be the strongest drivers of their performance on the Hot 100 list.\n",
    "- Analyzing music can quickly lead to an overwhelming number of features, so thoughtful and careful data selection is key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customer of this project is FutureProduct Advisors, a consultancy that helps their customers develop innovative and new consumer products. FutureProduct’s customers are increasingly seeking help from their consultants in go-to-market activities. \n",
    "\n",
    "FutureProduct’s consultants can support these go-to-market activities, but the business does not have all the infrastructure needed to support it. Their biggest ask is for a tool to help them find interesting, up-and-coming music to accompany social posts and online ads for go-to-market promotions. \n",
    "\n",
    "**Stakeholders**\n",
    "\n",
    "- FutureProduct Managing Director: oversees their consulting practice and is sponsoring this project.\n",
    "- FutureProduct Senior Consultants: the actual users of the prospective tool. A small subset of the consultants will pilot the prototype tool.\n",
    "- My consulting leadership: sponsors of this effort; will provide oversight and technical input of the project as needed.\n",
    "\n",
    "**Primary Goals**\n",
    "\n",
    "1.\tBuild a data tool that can evaluate any song in the Billboard Hot 100 list and make predictions about:\n",
    "    -\tThe song’s position on the Hot 100 list 4 weeks in the future\n",
    "    -\tThe song’s highest position on the list in the next 6 months\n",
    "2.\tCreate a rubric that lists the 3 most important factors for songs’ placement on the Hot 100 list for each hear from 2000 to 2021.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Billboard Hot 100 weekly charts (Kaggle): https://www.kaggle.com/datasets/thedevastator/billboard-hot-100-audio-features\n",
    "\n",
    "I’ve chosen this dataset because it has a direct measurement of song popularity (the Hot 100 list) and because its long history gives significant context to a song’s positioning in a given week.\n",
    "The features list gives a wide range of song attributes to explore and enables me to determine what features most significantly contribute to a song’s popularity and how that changes over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay, mean_squared_error, r2_score, pairwise_distances\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotlist_all = pd.read_csv('Data/Hot Stuff.csv')\n",
    "df_features_all = pd.read_csv('Data/Hot 100 Audio Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring hotlist df\n",
    "df_hotlist_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring features df\n",
    "df_features_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveness_dist = df_cleaned_genre['liveness'].value_counts()\n",
    "df_liveness_dist = pd.DataFrame(liveness_dist)\n",
    "df_liveness_dist = df_liveness_dist.reset_index()\n",
    "\n",
    "plt.bar(df_liveness_dist['liveness'], df_liveness_dist['count'], color='orange')\n",
    "plt.xlabel('Liveness Rating')\n",
    "plt.ylabel('Number of Songs')\n",
    "plt.title('Distribution of Liveness Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danceability_dist = df_cleaned_genre['danceability'].value_counts()\n",
    "df_danceability_dist = pd.DataFrame(danceability_dist)\n",
    "df_danceability_dist = df_danceability_dist.reset_index()\n",
    "\n",
    "plt.bar(df_danceability_dist['danceability'], df_danceability_dist['count'], color='skyblue')\n",
    "plt.xlabel('Danceability Rating')\n",
    "plt.ylabel('Number of Songs')\n",
    "plt.title('Distribution of Danceability Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acousticness_dist = df_cleaned_genre['acousticness'].value_counts()\n",
    "df_acousticness_dist = pd.DataFrame(acousticness_dist)\n",
    "df_acousticness_dist = df_acousticness_dist.reset_index()\n",
    "\n",
    "plt.bar(df_acousticness_dist['acousticness'], df_acousticness_dist['count'], color='orange')\n",
    "plt.xlabel('Acousticness Rating')\n",
    "plt.ylabel('Number of Songs')\n",
    "plt.title('Distribution of Acousticness Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_pos_dist = df_cleaned_genre['Max_Peak_Position'].value_counts()\n",
    "df_peak_pos_dist = pd.DataFrame(peak_pos_dist)\n",
    "df_peak_pos_dist = df_peak_pos_dist.reset_index()\n",
    "print(f\"Mean Highest Ranking: {df_cleaned_genre['Max_Peak_Position'].mean():.0f}\")\n",
    "print(f\"Standard Deviation of Highest Ranking: {df_cleaned_genre['Max_Peak_Position'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_peak_pos_dist['Max_Peak_Position'], df_peak_pos_dist['count'], color='skyblue')\n",
    "plt.xlabel('Highest Ranking')\n",
    "plt.ylabel('Number of Songs')\n",
    "plt.title('Frequency of Peak Rankings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rank_change = df_cleaned_genre['Max_Rank_Change'].value_counts()\n",
    "df_max_rank_change = pd.DataFrame(max_rank_change)\n",
    "df_max_rank_change = df_max_rank_change.reset_index()\n",
    "df_max_rank_change = df_max_rank_change[df_max_rank_change['Max_Rank_Change'] > 0]\n",
    "print(f\"Mean Largest Week over Week Rank Change: {df_cleaned_genre['Max_Rank_Change'].mean():.0f}\")\n",
    "print(f\"Standard Deviation of Largest Week over Week Rank Change: {df_cleaned_genre['Max_Rank_Change'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_max_rank_change['Max_Rank_Change'], df_max_rank_change['count'], color='orange')\n",
    "plt.xlabel('Largest Week over Week Rank Change')\n",
    "plt.ylabel('Number of Songs')\n",
    "plt.title('Frequency of Largest Week over Week Rank Change')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Initial Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marha\\AppData\\Local\\Temp\\ipykernel_18008\\3177740419.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s.apply(lambda x: diff(x['Week Position'], x['Previous Week Position']), axis=1)\n",
      "C:\\Users\\marha\\AppData\\Local\\Temp\\ipykernel_18008\\3177740419.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s['Rank_Change'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# removing hotlist df attributes that will not be used in cleaning or analysis\n",
    "df_hotlist_all = df_hotlist_all.drop(['index', 'url', 'Song', 'Performer', 'Instance'], axis=1)\n",
    "# converting WeekID to datetime\n",
    "df_hotlist_all['WeekID'] = pd.to_datetime(df_hotlist_all['WeekID'], errors='coerce')\n",
    "df_hotlist_all = df_hotlist_all.sort_values(by='WeekID')\n",
    "\n",
    "# creating a new hotlist df with only complete year data from 2000 - 2020, the time period being studied\n",
    "df_hotlist_2000s = df_hotlist_all.loc[(df_hotlist_all['WeekID'] > '1999-12-31') & (df_hotlist_all['WeekID'] < '2021-01-01')]\n",
    "\n",
    "# adding a column to calculate the week over week change in rank\n",
    "def diff(a, b):\n",
    "    return a - b\n",
    "\n",
    "df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s.apply(lambda x: diff(x['Week Position'], x['Previous Week Position']), axis=1)\n",
    "# replacing NaNs with 0\n",
    "df_hotlist_2000s['Rank_Change'] = df_hotlist_2000s['Rank_Change'].fillna(0)\n",
    "\n",
    "# removing features df attributes that will not be used in cleaning or analysis\n",
    "df_features_all = df_features_all.drop(['index', 'Performer', 'Song', 'spotify_track_album', \n",
    "                                        'spotify_track_id', 'spotify_track_preview_url',  \n",
    "                                        'spotify_track_explicit', 'spotify_track_popularity'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112098 entries, 0 to 112097\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   WeekID                     112098 non-null  datetime64[ns]\n",
      " 1   Week Position              112098 non-null  int64         \n",
      " 2   SongID                     112098 non-null  object        \n",
      " 3   Previous Week Position     101571 non-null  float64       \n",
      " 4   Peak Position              112098 non-null  int64         \n",
      " 5   Weeks on Chart             112098 non-null  int64         \n",
      " 6   Rank_Change                112098 non-null  float64       \n",
      " 7   spotify_genre              108091 non-null  object        \n",
      " 8   spotify_track_duration_ms  104590 non-null  float64       \n",
      " 9   danceability               104287 non-null  float64       \n",
      " 10  energy                     104287 non-null  float64       \n",
      " 11  key                        104287 non-null  float64       \n",
      " 12  loudness                   104287 non-null  float64       \n",
      " 13  mode                       104287 non-null  float64       \n",
      " 14  speechiness                104287 non-null  float64       \n",
      " 15  acousticness               104287 non-null  float64       \n",
      " 16  instrumentalness           104287 non-null  float64       \n",
      " 17  liveness                   104287 non-null  float64       \n",
      " 18  valence                    104287 non-null  float64       \n",
      " 19  tempo                      104287 non-null  float64       \n",
      " 20  time_signature             104287 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(15), int64(3), object(2)\n",
      "memory usage: 18.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# combining the hotlist and features into one dataframe\n",
    "\n",
    "df_hotlist_and_features_2000s = pd.merge(df_hotlist_2000s, df_features_all, on='SongID', how='left')\n",
    "df_hotlist_and_features_2000s.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The dataset has genre in a single column and the entry for each song has a variety of genres listed in that single column. \n",
    "This does not allow me to explore genre in a systematic way.\n",
    "I'll need to break genre out so that each genre has its own column with a 1 or 0 to indicate whether each song is tagged with that genre \n",
    "(ending with a one-hot encoded structure).\n",
    "\"\"\"\n",
    "\n",
    "# generating a df with unique genre names\n",
    "unique_genres = list(set(\n",
    "    genre \n",
    "    for genre_string in df_hotlist_and_features_2000s['spotify_genre'] \n",
    "    if pd.notna(genre_string)\n",
    "    for genre in ast.literal_eval(genre_string)\n",
    "))\n",
    "\n",
    "df_unique_genres = pd.DataFrame(unique_genres, columns=['genre'])\n",
    "\n",
    "# adding counts of each unique genre name\n",
    "# Extract all genres (with duplicates) and count them\n",
    "all_genres_list = []\n",
    "for genre_string in df_hotlist_and_features_2000s['spotify_genre']:\n",
    "    if pd.notna(genre_string):\n",
    "        genre_list = ast.literal_eval(genre_string)\n",
    "        all_genres_list.extend(genre_list)\n",
    "\n",
    "# Count occurrences\n",
    "genre_counts = Counter(all_genres_list)\n",
    "\n",
    "# Map counts to genres dataframe\n",
    "df_unique_genres['count'] = df_unique_genres['genre'].map(genre_counts)\n",
    "df_unique_genres = df_unique_genres.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to csv for easier review of the data\n",
    "df_unique_genres.to_csv('genre_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing the full set of genre counts, I'm only including genres that appear in 100 or more songs (i.e. at least 0.1% of songs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading list of genres with 100 or more instances in df_cleaned\n",
    "df_genres_100_up = pd.read_csv('genre_counts_100+inst.csv')\n",
    "\n",
    "# converting df to list\n",
    "final_genres_list = df_genres_100_up['genre'].tolist()\n",
    "\n",
    "# manually one-hot encoding each genre\n",
    "\n",
    "# creating a list of genres and counts\n",
    "genre_data = []\n",
    "\n",
    "for genre_string in df_hotlist_and_features_2000s['spotify_genre'] :\n",
    "    if pd.notna(genre_string):\n",
    "        genre_list = ast.literal_eval(genre_string)\n",
    "        row_dict = {genre: (1 if genre in genre_list else 0) for genre in final_genres_list} # dict with 1 if genre exists in list, 0 if not\n",
    "    else:\n",
    "         row_dict = {genre: 0 for genre in final_genres_list} # 0 of genre does not exist in list\n",
    "    genre_data.append(row_dict)\n",
    "\n",
    "# creating a df with the list of dicts\n",
    "genre_df = pd.DataFrame(genre_data)\n",
    "\n",
    "# concatenating genre data into df_clean\n",
    "df_hotlist_and_features_2000s = pd.concat([df_hotlist_and_features_2000s, genre_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekID</th>\n",
       "      <th>Week Position</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Previous Week Position</th>\n",
       "      <th>Peak Position</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "      <th>Rank_Change</th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>pop</th>\n",
       "      <th>dance pop</th>\n",
       "      <th>pop rap</th>\n",
       "      <th>rap</th>\n",
       "      <th>contemporary country</th>\n",
       "      <th>country</th>\n",
       "      <th>country road</th>\n",
       "      <th>post-teen pop</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>r&amp;b</th>\n",
       "      <th>urban contemporary</th>\n",
       "      <th>trap</th>\n",
       "      <th>southern hip hop</th>\n",
       "      <th>pop rock</th>\n",
       "      <th>hip pop</th>\n",
       "      <th>modern country rock</th>\n",
       "      <th>neo mellow</th>\n",
       "      <th>post-grunge</th>\n",
       "      <th>gangster rap</th>\n",
       "      <th>atl hip hop</th>\n",
       "      <th>alternative metal</th>\n",
       "      <th>neo soul</th>\n",
       "      <th>dirty south rap</th>\n",
       "      <th>country dawn</th>\n",
       "      <th>modern rock</th>\n",
       "      <th>nu metal</th>\n",
       "      <th>canadian pop</th>\n",
       "      <th>rock</th>\n",
       "      <th>melodic rap</th>\n",
       "      <th>deep pop r&amp;b</th>\n",
       "      <th>edm</th>\n",
       "      <th>new jack swing</th>\n",
       "      <th>permanent wave</th>\n",
       "      <th>miami hip hop</th>\n",
       "      <th>country pop</th>\n",
       "      <th>oklahoma country</th>\n",
       "      <th>latin</th>\n",
       "      <th>tropical house</th>\n",
       "      <th>electropop</th>\n",
       "      <th>uk pop</th>\n",
       "      <th>east coast hip hop</th>\n",
       "      <th>alternative rock</th>\n",
       "      <th>viral pop</th>\n",
       "      <th>quiet storm</th>\n",
       "      <th>chicago rap</th>\n",
       "      <th>redneck</th>\n",
       "      <th>pop punk</th>\n",
       "      <th>crunk</th>\n",
       "      <th>country rock</th>\n",
       "      <th>toronto rap</th>\n",
       "      <th>canadian hip hop</th>\n",
       "      <th>boy band</th>\n",
       "      <th>hardcore hip hop</th>\n",
       "      <th>queens hip hop</th>\n",
       "      <th>talent show</th>\n",
       "      <th>emo</th>\n",
       "      <th>europop</th>\n",
       "      <th>acoustic pop</th>\n",
       "      <th>alternative r&amp;b</th>\n",
       "      <th>conscious hip hop</th>\n",
       "      <th>australian pop</th>\n",
       "      <th>detroit hip hop</th>\n",
       "      <th>rap rock</th>\n",
       "      <th>latin pop</th>\n",
       "      <th>barbadian pop</th>\n",
       "      <th>g funk</th>\n",
       "      <th>girl group</th>\n",
       "      <th>canadian rock</th>\n",
       "      <th>tropical</th>\n",
       "      <th>piano rock</th>\n",
       "      <th>indie pop</th>\n",
       "      <th>electro house</th>\n",
       "      <th>indie poptimism</th>\n",
       "      <th>rap metal</th>\n",
       "      <th>west coast rap</th>\n",
       "      <th>new orleans rap</th>\n",
       "      <th>metropopolis</th>\n",
       "      <th>candy pop</th>\n",
       "      <th>lilith</th>\n",
       "      <th>australian country</th>\n",
       "      <th>philly rap</th>\n",
       "      <th>funk metal</th>\n",
       "      <th>reggaeton</th>\n",
       "      <th>dfw rap</th>\n",
       "      <th>canadian contemporary r&amp;b</th>\n",
       "      <th>soul</th>\n",
       "      <th>mexican pop</th>\n",
       "      <th>adult standards</th>\n",
       "      <th>nc hip hop</th>\n",
       "      <th>british soul</th>\n",
       "      <th>trap queen</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>arkansas country</th>\n",
       "      <th>atl trap</th>\n",
       "      <th>underground hip hop</th>\n",
       "      <th>texas country</th>\n",
       "      <th>uk dance</th>\n",
       "      <th>house</th>\n",
       "      <th>new wave pop</th>\n",
       "      <th>brostep</th>\n",
       "      <th>dancehall</th>\n",
       "      <th>progressive house</th>\n",
       "      <th>funk</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>latin hip hop</th>\n",
       "      <th>idol</th>\n",
       "      <th>garage rock</th>\n",
       "      <th>mellow gold</th>\n",
       "      <th>baroque pop</th>\n",
       "      <th>big room</th>\n",
       "      <th>art pop</th>\n",
       "      <th>reggae fusion</th>\n",
       "      <th>cali rap</th>\n",
       "      <th>bronx hip hop</th>\n",
       "      <th>folk-pop</th>\n",
       "      <th>country rap</th>\n",
       "      <th>stomp and holler</th>\n",
       "      <th>neon pop punk</th>\n",
       "      <th>emo rap</th>\n",
       "      <th>punk</th>\n",
       "      <th>indie rock</th>\n",
       "      <th>funk rock</th>\n",
       "      <th>memphis hip hop</th>\n",
       "      <th>modern alternative rock</th>\n",
       "      <th>lgbtq+ hip hop</th>\n",
       "      <th>progressive electro house</th>\n",
       "      <th>alternative hip hop</th>\n",
       "      <th>blues rock</th>\n",
       "      <th>colombian pop</th>\n",
       "      <th>eurodance</th>\n",
       "      <th>classic rock</th>\n",
       "      <th>baton rouge rap</th>\n",
       "      <th>australian dance</th>\n",
       "      <th>folk</th>\n",
       "      <th>pop emo</th>\n",
       "      <th>soft rock</th>\n",
       "      <th>motown</th>\n",
       "      <th>pixie</th>\n",
       "      <th>canadian country</th>\n",
       "      <th>wrestling</th>\n",
       "      <th>glee club</th>\n",
       "      <th>complextro</th>\n",
       "      <th>vapor trap</th>\n",
       "      <th>etherpop</th>\n",
       "      <th>pittsburgh rap</th>\n",
       "      <th>escape room</th>\n",
       "      <th>indietronica</th>\n",
       "      <th>comic</th>\n",
       "      <th>german techno</th>\n",
       "      <th>new jersey rap</th>\n",
       "      <th>trap latino</th>\n",
       "      <th>houston rap</th>\n",
       "      <th>social media pop</th>\n",
       "      <th>puerto rican pop</th>\n",
       "      <th>deep southern trap</th>\n",
       "      <th>heartland rock</th>\n",
       "      <th>alternative dance</th>\n",
       "      <th>bubblegum dance</th>\n",
       "      <th>alberta country</th>\n",
       "      <th>outlaw country</th>\n",
       "      <th>country gospel</th>\n",
       "      <th>florida rap</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>canadian metal</th>\n",
       "      <th>christian rock</th>\n",
       "      <th>soca</th>\n",
       "      <th>indiecoustica</th>\n",
       "      <th>harlem hip hop</th>\n",
       "      <th>new rave</th>\n",
       "      <th>electronic trap</th>\n",
       "      <th>christian music</th>\n",
       "      <th>grunge</th>\n",
       "      <th>show tunes</th>\n",
       "      <th>viral trap</th>\n",
       "      <th>la indie</th>\n",
       "      <th>swedish pop</th>\n",
       "      <th>swedish electropop</th>\n",
       "      <th>reggaeton flow</th>\n",
       "      <th>dance-punk</th>\n",
       "      <th>celtic rock</th>\n",
       "      <th>socal pop punk</th>\n",
       "      <th>lounge</th>\n",
       "      <th>chicano rap</th>\n",
       "      <th>stomp pop</th>\n",
       "      <th>ccm</th>\n",
       "      <th>vocal jazz</th>\n",
       "      <th>glam metal</th>\n",
       "      <th>worship</th>\n",
       "      <th>irish rock</th>\n",
       "      <th>electropowerpop</th>\n",
       "      <th>electro</th>\n",
       "      <th>indie pop rap</th>\n",
       "      <th>canadian contemporary country</th>\n",
       "      <th>bounce</th>\n",
       "      <th>christian alternative rock</th>\n",
       "      <th>south african rock</th>\n",
       "      <th>deep talent show</th>\n",
       "      <th>disco</th>\n",
       "      <th>hyphy</th>\n",
       "      <th>disco house</th>\n",
       "      <th>canadian latin</th>\n",
       "      <th>australian hip hop</th>\n",
       "      <th>nyc rap</th>\n",
       "      <th>brill building pop</th>\n",
       "      <th>k-pop</th>\n",
       "      <th>nz pop</th>\n",
       "      <th>minnesota hip hop</th>\n",
       "      <th>modern blues rock</th>\n",
       "      <th>album rock</th>\n",
       "      <th>modern folk rock</th>\n",
       "      <th>uk americana</th>\n",
       "      <th>old school hip hop</th>\n",
       "      <th>punk blues</th>\n",
       "      <th>dmv rap</th>\n",
       "      <th>industrial metal</th>\n",
       "      <th>skate punk</th>\n",
       "      <th>swedish synthpop</th>\n",
       "      <th>moombahton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>69</td>\n",
       "      <td>Deck The HallsSHeDAISY</td>\n",
       "      <td>97.0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>229773.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.444</td>\n",
       "      <td>118.827</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>83</td>\n",
       "      <td>Guerrilla RadioRage Against The Machine</td>\n",
       "      <td>87.0</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>206200.0</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.957</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.489</td>\n",
       "      <td>103.680</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>60</td>\n",
       "      <td>HeartbreakerMariah Carey Featuring Jay-Z</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>285706.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.789</td>\n",
       "      <td>200.031</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>97</td>\n",
       "      <td>Gotta ManEve</td>\n",
       "      <td>66.0</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>31.0</td>\n",
       "      <td>264733.0</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.903</td>\n",
       "      <td>90.496</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>Dancin'Guy</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>248626.0</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.792</td>\n",
       "      <td>101.015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WeekID  Week Position                                    SongID  \\\n",
       "0 2000-01-01             69                    Deck The HallsSHeDAISY   \n",
       "1 2000-01-01             83   Guerrilla RadioRage Against The Machine   \n",
       "2 2000-01-01             60  HeartbreakerMariah Carey Featuring Jay-Z   \n",
       "3 2000-01-01             97                              Gotta ManEve   \n",
       "4 2000-01-01             19                                Dancin'Guy   \n",
       "\n",
       "   Previous Week Position  Peak Position  Weeks on Chart  Rank_Change  \\\n",
       "0                    97.0             69               2        -28.0   \n",
       "1                    87.0             69              10         -4.0   \n",
       "2                    51.0              1              18          9.0   \n",
       "3                    66.0             26              16         31.0   \n",
       "4                    29.0             19               3        -10.0   \n",
       "\n",
       "   spotify_track_duration_ms  danceability  energy   key  loudness  mode  \\\n",
       "0                   229773.0         0.575   0.837   1.0    -7.141   0.0   \n",
       "1                   206200.0         0.599   0.957  11.0    -5.764   1.0   \n",
       "2                   285706.0         0.524   0.816   1.0    -5.872   1.0   \n",
       "3                   264733.0         0.796   0.871   5.0    -4.135   0.0   \n",
       "4                   248626.0         0.798   0.703  10.0    -4.050   0.0   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0406        0.0195          0.000009     0.144    0.444  118.827   \n",
       "1       0.1880        0.0129          0.000071     0.155    0.489  103.680   \n",
       "2       0.3700        0.3840          0.000000     0.349    0.789  200.031   \n",
       "3       0.1270        0.1480          0.000199     0.113    0.903   90.496   \n",
       "4       0.1350        0.1170          0.000000     0.121    0.792  101.015   \n",
       "\n",
       "   time_signature  pop  dance pop  pop rap  rap  contemporary country  \\\n",
       "0             4.0    0          0        0    0                     1   \n",
       "1             4.0    0          0        0    0                     0   \n",
       "2             4.0    1          1        0    0                     0   \n",
       "3             4.0    0          1        1    1                     0   \n",
       "4             4.0    0          0        0    0                     0   \n",
       "\n",
       "   country  country road  post-teen pop  hip hop  r&b  urban contemporary  \\\n",
       "0        1             1              0        0    0                   0   \n",
       "1        0             0              0        0    0                   0   \n",
       "2        0             0              0        0    1                   1   \n",
       "3        0             0              0        1    1                   1   \n",
       "4        0             0              0        0    0                   0   \n",
       "\n",
       "   trap  southern hip hop  pop rock  hip pop  modern country rock  neo mellow  \\\n",
       "0     0                 0         0        0                    0           0   \n",
       "1     0                 0         0        0                    0           0   \n",
       "2     0                 0         0        0                    0           0   \n",
       "3     0                 0         0        1                    0           0   \n",
       "4     0                 0         0        0                    0           0   \n",
       "\n",
       "   post-grunge  gangster rap  atl hip hop  alternative metal  neo soul  \\\n",
       "0            0             0            0                  0         0   \n",
       "1            1             0            0                  1         0   \n",
       "2            0             0            0                  0         0   \n",
       "3            0             0            0                  0         0   \n",
       "4            0             0            0                  0         0   \n",
       "\n",
       "   dirty south rap  country dawn  modern rock  nu metal  canadian pop  rock  \\\n",
       "0                0             1            0         0             0     0   \n",
       "1                0             0            0         1             0     1   \n",
       "2                0             0            0         0             0     0   \n",
       "3                0             0            0         0             0     0   \n",
       "4                0             0            0         0             0     0   \n",
       "\n",
       "   melodic rap  deep pop r&b  edm  new jack swing  permanent wave  \\\n",
       "0            0             0    0               0               0   \n",
       "1            0             0    0               0               0   \n",
       "2            0             0    0               0               0   \n",
       "3            0             0    0               0               0   \n",
       "4            0             0    0               0               0   \n",
       "\n",
       "   miami hip hop  country pop  oklahoma country  latin  tropical house  \\\n",
       "0              0            0                 0      0               0   \n",
       "1              0            0                 0      0               0   \n",
       "2              0            0                 0      0               0   \n",
       "3              0            0                 0      0               0   \n",
       "4              0            0                 0      0               0   \n",
       "\n",
       "   electropop  uk pop  east coast hip hop  alternative rock  viral pop  \\\n",
       "0           0       0                   0                 0          0   \n",
       "1           0       0                   0                 1          0   \n",
       "2           0       0                   0                 0          0   \n",
       "3           0       0                   0                 0          0   \n",
       "4           0       0                   0                 0          0   \n",
       "\n",
       "   quiet storm  chicago rap  redneck  pop punk  crunk  country rock  \\\n",
       "0            0            0        0         0      0             0   \n",
       "1            0            0        0         0      0             0   \n",
       "2            0            0        0         0      0             0   \n",
       "3            0            0        0         0      0             0   \n",
       "4            0            0        0         0      0             0   \n",
       "\n",
       "   toronto rap  canadian hip hop  boy band  hardcore hip hop  queens hip hop  \\\n",
       "0            0                 0         0                 0               0   \n",
       "1            0                 0         0                 0               0   \n",
       "2            0                 0         0                 0               0   \n",
       "3            0                 0         0                 0               0   \n",
       "4            0                 0         0                 0               0   \n",
       "\n",
       "   talent show  emo  europop  acoustic pop  alternative r&b  \\\n",
       "0            0    0        0             0                0   \n",
       "1            0    0        0             0                0   \n",
       "2            0    0        0             0                0   \n",
       "3            0    0        0             0                0   \n",
       "4            0    0        0             0                0   \n",
       "\n",
       "   conscious hip hop  australian pop  detroit hip hop  rap rock  latin pop  \\\n",
       "0                  0               0                0         0          0   \n",
       "1                  1               0                0         1          0   \n",
       "2                  0               0                0         0          0   \n",
       "3                  0               0                0         0          0   \n",
       "4                  0               0                0         0          0   \n",
       "\n",
       "   barbadian pop  g funk  girl group  canadian rock  tropical  piano rock  \\\n",
       "0              0       0           0              0         0           0   \n",
       "1              0       0           0              0         0           0   \n",
       "2              0       0           0              0         0           0   \n",
       "3              0       0           0              0         0           0   \n",
       "4              0       0           0              0         0           0   \n",
       "\n",
       "   indie pop  electro house  indie poptimism  rap metal  west coast rap  \\\n",
       "0          0              0                0          0               0   \n",
       "1          0              0                0          1               0   \n",
       "2          0              0                0          0               0   \n",
       "3          0              0                0          0               0   \n",
       "4          0              0                0          0               0   \n",
       "\n",
       "   new orleans rap  metropopolis  candy pop  lilith  australian country  \\\n",
       "0                0             0          0       0                   0   \n",
       "1                0             0          0       0                   0   \n",
       "2                0             0          0       0                   0   \n",
       "3                0             0          0       0                   0   \n",
       "4                0             0          0       0                   0   \n",
       "\n",
       "   philly rap  funk metal  reggaeton  dfw rap  canadian contemporary r&b  \\\n",
       "0           0           0          0        0                          0   \n",
       "1           0           1          0        0                          0   \n",
       "2           0           0          0        0                          0   \n",
       "3           1           0          0        0                          0   \n",
       "4           0           0          0        0                          0   \n",
       "\n",
       "   soul  mexican pop  adult standards  nc hip hop  british soul  trap queen  \\\n",
       "0     0            0                0           0             0           0   \n",
       "1     0            0                0           0             0           0   \n",
       "2     0            0                0           0             0           0   \n",
       "3     0            0                0           0             0           0   \n",
       "4     0            0                0           0             0           0   \n",
       "\n",
       "   hollywood  arkansas country  atl trap  underground hip hop  texas country  \\\n",
       "0          0                 0         0                    0              0   \n",
       "1          0                 0         0                    0              0   \n",
       "2          0                 0         0                    0              0   \n",
       "3          0                 0         0                    0              0   \n",
       "4          0                 0         0                    0              0   \n",
       "\n",
       "   uk dance  house  new wave pop  brostep  dancehall  progressive house  funk  \\\n",
       "0         0      0             0        0          0                  0     0   \n",
       "1         0      0             0        0          0                  0     0   \n",
       "2         0      0             0        0          0                  0     0   \n",
       "3         0      0             0        0          0                  0     0   \n",
       "4         0      0             0        0          0                  0     0   \n",
       "\n",
       "   singer-songwriter  latin hip hop  idol  garage rock  mellow gold  \\\n",
       "0                  0              0     0            0            0   \n",
       "1                  0              0     0            0            0   \n",
       "2                  0              0     0            0            0   \n",
       "3                  0              0     0            0            0   \n",
       "4                  0              0     0            0            0   \n",
       "\n",
       "   baroque pop  big room  art pop  reggae fusion  cali rap  bronx hip hop  \\\n",
       "0            0         0        0              0         0              0   \n",
       "1            0         0        0              0         0              0   \n",
       "2            0         0        0              0         0              0   \n",
       "3            0         0        0              0         0              0   \n",
       "4            0         0        0              0         0              0   \n",
       "\n",
       "   folk-pop  country rap  stomp and holler  neon pop punk  emo rap  punk  \\\n",
       "0         0            0                 0              0        0     0   \n",
       "1         0            0                 0              0        0     0   \n",
       "2         0            0                 0              0        0     0   \n",
       "3         0            0                 0              0        0     0   \n",
       "4         0            0                 0              0        0     0   \n",
       "\n",
       "   indie rock  funk rock  memphis hip hop  modern alternative rock  \\\n",
       "0           0          0                0                        0   \n",
       "1           0          0                0                        0   \n",
       "2           0          0                0                        0   \n",
       "3           0          0                0                        0   \n",
       "4           0          0                0                        0   \n",
       "\n",
       "   lgbtq+ hip hop  progressive electro house  alternative hip hop  blues rock  \\\n",
       "0               0                          0                    0           0   \n",
       "1               0                          0                    0           0   \n",
       "2               0                          0                    0           0   \n",
       "3               0                          0                    0           0   \n",
       "4               0                          0                    0           0   \n",
       "\n",
       "   colombian pop  eurodance  classic rock  baton rouge rap  australian dance  \\\n",
       "0              0          0             0                0                 0   \n",
       "1              0          0             0                0                 0   \n",
       "2              0          0             0                0                 0   \n",
       "3              0          0             0                0                 0   \n",
       "4              0          0             0                0                 0   \n",
       "\n",
       "   folk  pop emo  soft rock  motown  pixie  canadian country  wrestling  \\\n",
       "0     0        0          0       0      0                 0          0   \n",
       "1     0        0          0       0      0                 0          0   \n",
       "2     0        0          0       0      0                 0          0   \n",
       "3     0        0          0       0      0                 0          0   \n",
       "4     0        0          0       0      0                 0          0   \n",
       "\n",
       "   glee club  complextro  vapor trap  etherpop  pittsburgh rap  escape room  \\\n",
       "0          0           0           0         0               0            0   \n",
       "1          0           0           0         0               0            0   \n",
       "2          0           0           0         0               0            0   \n",
       "3          0           0           0         0               0            0   \n",
       "4          0           0           0         0               0            0   \n",
       "\n",
       "   indietronica  comic  german techno  new jersey rap  trap latino  \\\n",
       "0             0      0              0               0            0   \n",
       "1             0      0              0               0            0   \n",
       "2             0      0              0               0            0   \n",
       "3             0      0              0               0            0   \n",
       "4             0      0              0               0            0   \n",
       "\n",
       "   houston rap  social media pop  puerto rican pop  deep southern trap  \\\n",
       "0            0                 0                 0                   0   \n",
       "1            0                 0                 0                   0   \n",
       "2            0                 0                 0                   0   \n",
       "3            0                 0                 0                   0   \n",
       "4            0                 0                 0                   0   \n",
       "\n",
       "   heartland rock  alternative dance  bubblegum dance  alberta country  \\\n",
       "0               0                  0                0                0   \n",
       "1               0                  0                0                0   \n",
       "2               0                  0                0                0   \n",
       "3               0                  0                0                0   \n",
       "4               0                  0                0                0   \n",
       "\n",
       "   outlaw country  country gospel  florida rap  hard rock  canadian metal  \\\n",
       "0               0               0            0          0               0   \n",
       "1               0               0            0          0               0   \n",
       "2               0               0            0          0               0   \n",
       "3               0               0            0          0               0   \n",
       "4               0               0            0          0               0   \n",
       "\n",
       "   christian rock  soca  indiecoustica  harlem hip hop  new rave  \\\n",
       "0               0     0              0               0         0   \n",
       "1               0     0              0               0         0   \n",
       "2               0     0              0               0         0   \n",
       "3               0     0              0               0         0   \n",
       "4               0     0              0               0         0   \n",
       "\n",
       "   electronic trap  christian music  grunge  show tunes  viral trap  la indie  \\\n",
       "0                0                0       0           0           0         0   \n",
       "1                0                0       0           0           0         0   \n",
       "2                0                0       0           0           0         0   \n",
       "3                0                0       0           0           0         0   \n",
       "4                0                0       0           0           0         0   \n",
       "\n",
       "   swedish pop  swedish electropop  reggaeton flow  dance-punk  celtic rock  \\\n",
       "0            0                   0               0           0            0   \n",
       "1            0                   0               0           0            0   \n",
       "2            0                   0               0           0            0   \n",
       "3            0                   0               0           0            0   \n",
       "4            0                   0               0           0            0   \n",
       "\n",
       "   socal pop punk  lounge  chicano rap  stomp pop  ccm  vocal jazz  \\\n",
       "0               0       0            0          0    0           0   \n",
       "1               0       0            0          0    0           0   \n",
       "2               0       0            0          0    0           0   \n",
       "3               0       0            0          0    0           0   \n",
       "4               0       0            0          0    0           0   \n",
       "\n",
       "   glam metal  worship  irish rock  electropowerpop  electro  indie pop rap  \\\n",
       "0           0        0           0                0        0              0   \n",
       "1           0        0           0                0        0              0   \n",
       "2           0        0           0                0        0              0   \n",
       "3           0        0           0                0        0              0   \n",
       "4           0        0           0                0        0              0   \n",
       "\n",
       "   canadian contemporary country  bounce  christian alternative rock  \\\n",
       "0                              0       0                           0   \n",
       "1                              0       0                           0   \n",
       "2                              0       0                           0   \n",
       "3                              0       0                           0   \n",
       "4                              0       0                           0   \n",
       "\n",
       "   south african rock  deep talent show  disco  hyphy  disco house  \\\n",
       "0                   0                 0      0      0            0   \n",
       "1                   0                 0      0      0            0   \n",
       "2                   0                 0      0      0            0   \n",
       "3                   0                 0      0      0            0   \n",
       "4                   0                 0      0      0            0   \n",
       "\n",
       "   canadian latin  australian hip hop  nyc rap  brill building pop  k-pop  \\\n",
       "0               0                   0        0                   0      0   \n",
       "1               0                   0        0                   0      0   \n",
       "2               0                   0        0                   0      0   \n",
       "3               0                   0        0                   0      0   \n",
       "4               0                   0        0                   0      0   \n",
       "\n",
       "   nz pop  minnesota hip hop  modern blues rock  album rock  modern folk rock  \\\n",
       "0       0                  0                  0           0                 0   \n",
       "1       0                  0                  0           0                 0   \n",
       "2       0                  0                  0           0                 0   \n",
       "3       0                  0                  0           0                 0   \n",
       "4       0                  0                  0           0                 0   \n",
       "\n",
       "   uk americana  old school hip hop  punk blues  dmv rap  industrial metal  \\\n",
       "0             0                   0           0        0                 0   \n",
       "1             0                   0           0        0                 0   \n",
       "2             0                   0           0        0                 0   \n",
       "3             0                   0           0        0                 0   \n",
       "4             0                   0           0        0                 0   \n",
       "\n",
       "   skate punk  swedish synthpop  moombahton  \n",
       "0           0                 0           0  \n",
       "1           0                 0           0  \n",
       "2           0                 0           0  \n",
       "3           0                 0           0  \n",
       "4           0                 0           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing spotify_genre and spot-checking resulting df \n",
    "pd.set_option('display.max_columns', None)\n",
    "df_hotlist_and_features_2000s = df_hotlist_and_features_2000s.drop(['spotify_genre'], axis=1)\n",
    "df_hotlist_and_features_2000s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with most 5 most popular genres by week\n",
    "\n",
    "# Get all genre column names\n",
    "genre_start_idx = df_hotlist_and_features_2000s.columns.get_loc('pop')\n",
    "genre_cols = df_hotlist_and_features_2000s.columns[genre_start_idx:].tolist()\n",
    "\n",
    "# Group by WeekID and sum the genre columns to get counts\n",
    "genre_counts = df_hotlist_and_features_2000s.groupby('WeekID')[genre_cols].sum()\n",
    "\n",
    "# For each week, find the top 5 genres\n",
    "top_genres = []\n",
    "for week_id in genre_counts.index:\n",
    "    # Get the genre counts for this week and sort them\n",
    "    week_genres = genre_counts.loc[week_id].sort_values(ascending=False)\n",
    "    \n",
    "    # Get the top 3 genre names\n",
    "    top_5 = week_genres.head(5).index.tolist()\n",
    "    \n",
    "    # Pad with None if there are fewer than 5 genres\n",
    "    while len(top_5) < 5:\n",
    "        top_5.append(None)\n",
    "    \n",
    "    top_genres.append({\n",
    "        'WeekID': week_id,\n",
    "        'Most_Popular_Genre': top_5[0],\n",
    "        '2nd_Most_Popular_Genre': top_5[1],\n",
    "        '3rd_Most_Popular_Genre': top_5[2],\n",
    "        '4th_Most_Popular_Genre': top_5[3],\n",
    "        '5th_Most_Popular_Genre': top_5[4]\n",
    "    })\n",
    "\n",
    "# Create the new dataframe\n",
    "df_top_genres = pd.DataFrame(top_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column to the main df indicating whether each song is in a genre that's in the top 5 genres for a given week\n",
    "\n",
    "def is_in_top5_genres(row, df_top_genres):\n",
    "    week = row['WeekID']\n",
    "\n",
    "    top_genres = df_top_genres[df_top_genres['WeekID'] == week]\n",
    "\n",
    "    if len(top_genres) == 0:\n",
    "        return 0\n",
    "    \n",
    "    top_5 = [\n",
    "        top_genres.iloc[0]['Most_Popular_Genre'],\n",
    "        top_genres.iloc[0]['2nd_Most_Popular_Genre'],\n",
    "        top_genres.iloc[0]['3rd_Most_Popular_Genre'],\n",
    "        top_genres.iloc[0]['4th_Most_Popular_Genre'],\n",
    "        top_genres.iloc[0]['5th_Most_Popular_Genre'],\n",
    "        ]\n",
    "\n",
    "    for genre in top_5:\n",
    "        if genre in row.index and row[genre] == 1:\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "df_hotlist_and_features_2000s['in_top5_genres'] = df_hotlist_and_features_2000s.apply(\n",
    "    lambda row: is_in_top5_genres(row, df_top_genres), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new df with mean score of appearance in top 5 weekly genres\n",
    "df_mean_genre_match = df_hotlist_and_features_2000s.groupby('SongID', as_index=False)['in_top5_genres'].mean()\n",
    "df_mean_genre_match.rename(columns={'in_top5_genres': 'In_Top5genres_Mean'}, inplace=True)\n",
    "df_mean_genre_match.set_index('SongID', inplace=True)\n",
    "\n",
    "# new df with the max weekly rank change for each song \n",
    "df_max_rank_change = df_hotlist_and_features_2000s.groupby('SongID', as_index=False)['Rank_Change'].max()\n",
    "df_max_rank_change.rename(columns={'Rank_Change': 'Max_Rank_Change'}, inplace=True)\n",
    "df_max_rank_change.set_index('SongID', inplace=True)\n",
    "\n",
    "# new df with the max peak rank for each song \n",
    "df_max_peak_pos = df_hotlist_and_features_2000s.groupby('SongID', as_index=False)['Peak Position'].max()\n",
    "df_max_peak_pos.rename(columns={'Peak Position': 'Max_Peak_Position'}, inplace=True)\n",
    "df_max_peak_pos.set_index('SongID', inplace=True)\n",
    "\n",
    "# ensuring these new dfs have no null values\n",
    "df_max_rank_change['Max_Rank_Change'].isna().sum(), df_max_peak_pos['Max_Peak_Position'].isna().sum(), df_mean_genre_match['In_Top5genres_Mean'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekID</th>\n",
       "      <th>Week Position</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Previous Week Position</th>\n",
       "      <th>Peak Position</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "      <th>Rank_Change</th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>pop</th>\n",
       "      <th>dance pop</th>\n",
       "      <th>pop rap</th>\n",
       "      <th>rap</th>\n",
       "      <th>contemporary country</th>\n",
       "      <th>country</th>\n",
       "      <th>country road</th>\n",
       "      <th>post-teen pop</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>r&amp;b</th>\n",
       "      <th>urban contemporary</th>\n",
       "      <th>trap</th>\n",
       "      <th>southern hip hop</th>\n",
       "      <th>pop rock</th>\n",
       "      <th>hip pop</th>\n",
       "      <th>modern country rock</th>\n",
       "      <th>neo mellow</th>\n",
       "      <th>post-grunge</th>\n",
       "      <th>gangster rap</th>\n",
       "      <th>atl hip hop</th>\n",
       "      <th>alternative metal</th>\n",
       "      <th>neo soul</th>\n",
       "      <th>dirty south rap</th>\n",
       "      <th>country dawn</th>\n",
       "      <th>modern rock</th>\n",
       "      <th>nu metal</th>\n",
       "      <th>canadian pop</th>\n",
       "      <th>rock</th>\n",
       "      <th>melodic rap</th>\n",
       "      <th>deep pop r&amp;b</th>\n",
       "      <th>edm</th>\n",
       "      <th>new jack swing</th>\n",
       "      <th>permanent wave</th>\n",
       "      <th>miami hip hop</th>\n",
       "      <th>country pop</th>\n",
       "      <th>oklahoma country</th>\n",
       "      <th>latin</th>\n",
       "      <th>tropical house</th>\n",
       "      <th>electropop</th>\n",
       "      <th>uk pop</th>\n",
       "      <th>east coast hip hop</th>\n",
       "      <th>alternative rock</th>\n",
       "      <th>viral pop</th>\n",
       "      <th>quiet storm</th>\n",
       "      <th>chicago rap</th>\n",
       "      <th>redneck</th>\n",
       "      <th>pop punk</th>\n",
       "      <th>crunk</th>\n",
       "      <th>country rock</th>\n",
       "      <th>toronto rap</th>\n",
       "      <th>canadian hip hop</th>\n",
       "      <th>boy band</th>\n",
       "      <th>hardcore hip hop</th>\n",
       "      <th>queens hip hop</th>\n",
       "      <th>talent show</th>\n",
       "      <th>emo</th>\n",
       "      <th>europop</th>\n",
       "      <th>acoustic pop</th>\n",
       "      <th>alternative r&amp;b</th>\n",
       "      <th>conscious hip hop</th>\n",
       "      <th>australian pop</th>\n",
       "      <th>detroit hip hop</th>\n",
       "      <th>rap rock</th>\n",
       "      <th>latin pop</th>\n",
       "      <th>barbadian pop</th>\n",
       "      <th>g funk</th>\n",
       "      <th>girl group</th>\n",
       "      <th>canadian rock</th>\n",
       "      <th>tropical</th>\n",
       "      <th>piano rock</th>\n",
       "      <th>indie pop</th>\n",
       "      <th>electro house</th>\n",
       "      <th>indie poptimism</th>\n",
       "      <th>rap metal</th>\n",
       "      <th>west coast rap</th>\n",
       "      <th>new orleans rap</th>\n",
       "      <th>metropopolis</th>\n",
       "      <th>candy pop</th>\n",
       "      <th>lilith</th>\n",
       "      <th>australian country</th>\n",
       "      <th>philly rap</th>\n",
       "      <th>funk metal</th>\n",
       "      <th>reggaeton</th>\n",
       "      <th>dfw rap</th>\n",
       "      <th>canadian contemporary r&amp;b</th>\n",
       "      <th>soul</th>\n",
       "      <th>mexican pop</th>\n",
       "      <th>adult standards</th>\n",
       "      <th>nc hip hop</th>\n",
       "      <th>british soul</th>\n",
       "      <th>trap queen</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>arkansas country</th>\n",
       "      <th>atl trap</th>\n",
       "      <th>underground hip hop</th>\n",
       "      <th>texas country</th>\n",
       "      <th>uk dance</th>\n",
       "      <th>house</th>\n",
       "      <th>new wave pop</th>\n",
       "      <th>brostep</th>\n",
       "      <th>dancehall</th>\n",
       "      <th>progressive house</th>\n",
       "      <th>funk</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>latin hip hop</th>\n",
       "      <th>idol</th>\n",
       "      <th>garage rock</th>\n",
       "      <th>mellow gold</th>\n",
       "      <th>baroque pop</th>\n",
       "      <th>big room</th>\n",
       "      <th>art pop</th>\n",
       "      <th>reggae fusion</th>\n",
       "      <th>cali rap</th>\n",
       "      <th>bronx hip hop</th>\n",
       "      <th>folk-pop</th>\n",
       "      <th>country rap</th>\n",
       "      <th>stomp and holler</th>\n",
       "      <th>neon pop punk</th>\n",
       "      <th>emo rap</th>\n",
       "      <th>punk</th>\n",
       "      <th>indie rock</th>\n",
       "      <th>funk rock</th>\n",
       "      <th>memphis hip hop</th>\n",
       "      <th>modern alternative rock</th>\n",
       "      <th>lgbtq+ hip hop</th>\n",
       "      <th>progressive electro house</th>\n",
       "      <th>alternative hip hop</th>\n",
       "      <th>blues rock</th>\n",
       "      <th>colombian pop</th>\n",
       "      <th>eurodance</th>\n",
       "      <th>classic rock</th>\n",
       "      <th>baton rouge rap</th>\n",
       "      <th>australian dance</th>\n",
       "      <th>folk</th>\n",
       "      <th>pop emo</th>\n",
       "      <th>soft rock</th>\n",
       "      <th>motown</th>\n",
       "      <th>pixie</th>\n",
       "      <th>canadian country</th>\n",
       "      <th>wrestling</th>\n",
       "      <th>glee club</th>\n",
       "      <th>complextro</th>\n",
       "      <th>vapor trap</th>\n",
       "      <th>etherpop</th>\n",
       "      <th>pittsburgh rap</th>\n",
       "      <th>escape room</th>\n",
       "      <th>indietronica</th>\n",
       "      <th>comic</th>\n",
       "      <th>german techno</th>\n",
       "      <th>new jersey rap</th>\n",
       "      <th>trap latino</th>\n",
       "      <th>houston rap</th>\n",
       "      <th>social media pop</th>\n",
       "      <th>puerto rican pop</th>\n",
       "      <th>deep southern trap</th>\n",
       "      <th>heartland rock</th>\n",
       "      <th>alternative dance</th>\n",
       "      <th>bubblegum dance</th>\n",
       "      <th>alberta country</th>\n",
       "      <th>outlaw country</th>\n",
       "      <th>country gospel</th>\n",
       "      <th>florida rap</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>canadian metal</th>\n",
       "      <th>christian rock</th>\n",
       "      <th>soca</th>\n",
       "      <th>indiecoustica</th>\n",
       "      <th>harlem hip hop</th>\n",
       "      <th>new rave</th>\n",
       "      <th>electronic trap</th>\n",
       "      <th>christian music</th>\n",
       "      <th>grunge</th>\n",
       "      <th>show tunes</th>\n",
       "      <th>viral trap</th>\n",
       "      <th>la indie</th>\n",
       "      <th>swedish pop</th>\n",
       "      <th>swedish electropop</th>\n",
       "      <th>reggaeton flow</th>\n",
       "      <th>dance-punk</th>\n",
       "      <th>celtic rock</th>\n",
       "      <th>socal pop punk</th>\n",
       "      <th>lounge</th>\n",
       "      <th>chicano rap</th>\n",
       "      <th>stomp pop</th>\n",
       "      <th>ccm</th>\n",
       "      <th>vocal jazz</th>\n",
       "      <th>glam metal</th>\n",
       "      <th>worship</th>\n",
       "      <th>irish rock</th>\n",
       "      <th>electropowerpop</th>\n",
       "      <th>electro</th>\n",
       "      <th>indie pop rap</th>\n",
       "      <th>canadian contemporary country</th>\n",
       "      <th>bounce</th>\n",
       "      <th>christian alternative rock</th>\n",
       "      <th>south african rock</th>\n",
       "      <th>deep talent show</th>\n",
       "      <th>disco</th>\n",
       "      <th>hyphy</th>\n",
       "      <th>disco house</th>\n",
       "      <th>canadian latin</th>\n",
       "      <th>australian hip hop</th>\n",
       "      <th>nyc rap</th>\n",
       "      <th>brill building pop</th>\n",
       "      <th>k-pop</th>\n",
       "      <th>nz pop</th>\n",
       "      <th>minnesota hip hop</th>\n",
       "      <th>modern blues rock</th>\n",
       "      <th>album rock</th>\n",
       "      <th>modern folk rock</th>\n",
       "      <th>uk americana</th>\n",
       "      <th>old school hip hop</th>\n",
       "      <th>punk blues</th>\n",
       "      <th>dmv rap</th>\n",
       "      <th>industrial metal</th>\n",
       "      <th>skate punk</th>\n",
       "      <th>swedish synthpop</th>\n",
       "      <th>moombahton</th>\n",
       "      <th>in_top5_genres</th>\n",
       "      <th>Max_Peak_Position</th>\n",
       "      <th>Max_Rank_Change</th>\n",
       "      <th>In_Top5genres_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>69</td>\n",
       "      <td>Deck The HallsSHeDAISY</td>\n",
       "      <td>97.0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>229773.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.444</td>\n",
       "      <td>118.827</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>83</td>\n",
       "      <td>Guerrilla RadioRage Against The Machine</td>\n",
       "      <td>87.0</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>206200.0</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.957</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.489</td>\n",
       "      <td>103.680</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>60</td>\n",
       "      <td>HeartbreakerMariah Carey Featuring Jay-Z</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>285706.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.789</td>\n",
       "      <td>200.031</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>97</td>\n",
       "      <td>Gotta ManEve</td>\n",
       "      <td>66.0</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>31.0</td>\n",
       "      <td>264733.0</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.903</td>\n",
       "      <td>90.496</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>Dancin'Guy</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>248626.0</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.792</td>\n",
       "      <td>101.015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WeekID  Week Position                                    SongID  \\\n",
       "0 2000-01-01             69                    Deck The HallsSHeDAISY   \n",
       "1 2000-01-01             83   Guerrilla RadioRage Against The Machine   \n",
       "2 2000-01-01             60  HeartbreakerMariah Carey Featuring Jay-Z   \n",
       "3 2000-01-01             97                              Gotta ManEve   \n",
       "4 2000-01-01             19                                Dancin'Guy   \n",
       "\n",
       "   Previous Week Position  Peak Position  Weeks on Chart  Rank_Change  \\\n",
       "0                    97.0             69               2        -28.0   \n",
       "1                    87.0             69              10         -4.0   \n",
       "2                    51.0              1              18          9.0   \n",
       "3                    66.0             26              16         31.0   \n",
       "4                    29.0             19               3        -10.0   \n",
       "\n",
       "   spotify_track_duration_ms  danceability  energy   key  loudness  mode  \\\n",
       "0                   229773.0         0.575   0.837   1.0    -7.141   0.0   \n",
       "1                   206200.0         0.599   0.957  11.0    -5.764   1.0   \n",
       "2                   285706.0         0.524   0.816   1.0    -5.872   1.0   \n",
       "3                   264733.0         0.796   0.871   5.0    -4.135   0.0   \n",
       "4                   248626.0         0.798   0.703  10.0    -4.050   0.0   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0406        0.0195          0.000009     0.144    0.444  118.827   \n",
       "1       0.1880        0.0129          0.000071     0.155    0.489  103.680   \n",
       "2       0.3700        0.3840          0.000000     0.349    0.789  200.031   \n",
       "3       0.1270        0.1480          0.000199     0.113    0.903   90.496   \n",
       "4       0.1350        0.1170          0.000000     0.121    0.792  101.015   \n",
       "\n",
       "   time_signature  pop  dance pop  pop rap  rap  contemporary country  \\\n",
       "0             4.0    0          0        0    0                     1   \n",
       "1             4.0    0          0        0    0                     0   \n",
       "2             4.0    1          1        0    0                     0   \n",
       "3             4.0    0          1        1    1                     0   \n",
       "4             4.0    0          0        0    0                     0   \n",
       "\n",
       "   country  country road  post-teen pop  hip hop  r&b  urban contemporary  \\\n",
       "0        1             1              0        0    0                   0   \n",
       "1        0             0              0        0    0                   0   \n",
       "2        0             0              0        0    1                   1   \n",
       "3        0             0              0        1    1                   1   \n",
       "4        0             0              0        0    0                   0   \n",
       "\n",
       "   trap  southern hip hop  pop rock  hip pop  modern country rock  neo mellow  \\\n",
       "0     0                 0         0        0                    0           0   \n",
       "1     0                 0         0        0                    0           0   \n",
       "2     0                 0         0        0                    0           0   \n",
       "3     0                 0         0        1                    0           0   \n",
       "4     0                 0         0        0                    0           0   \n",
       "\n",
       "   post-grunge  gangster rap  atl hip hop  alternative metal  neo soul  \\\n",
       "0            0             0            0                  0         0   \n",
       "1            1             0            0                  1         0   \n",
       "2            0             0            0                  0         0   \n",
       "3            0             0            0                  0         0   \n",
       "4            0             0            0                  0         0   \n",
       "\n",
       "   dirty south rap  country dawn  modern rock  nu metal  canadian pop  rock  \\\n",
       "0                0             1            0         0             0     0   \n",
       "1                0             0            0         1             0     1   \n",
       "2                0             0            0         0             0     0   \n",
       "3                0             0            0         0             0     0   \n",
       "4                0             0            0         0             0     0   \n",
       "\n",
       "   melodic rap  deep pop r&b  edm  new jack swing  permanent wave  \\\n",
       "0            0             0    0               0               0   \n",
       "1            0             0    0               0               0   \n",
       "2            0             0    0               0               0   \n",
       "3            0             0    0               0               0   \n",
       "4            0             0    0               0               0   \n",
       "\n",
       "   miami hip hop  country pop  oklahoma country  latin  tropical house  \\\n",
       "0              0            0                 0      0               0   \n",
       "1              0            0                 0      0               0   \n",
       "2              0            0                 0      0               0   \n",
       "3              0            0                 0      0               0   \n",
       "4              0            0                 0      0               0   \n",
       "\n",
       "   electropop  uk pop  east coast hip hop  alternative rock  viral pop  \\\n",
       "0           0       0                   0                 0          0   \n",
       "1           0       0                   0                 1          0   \n",
       "2           0       0                   0                 0          0   \n",
       "3           0       0                   0                 0          0   \n",
       "4           0       0                   0                 0          0   \n",
       "\n",
       "   quiet storm  chicago rap  redneck  pop punk  crunk  country rock  \\\n",
       "0            0            0        0         0      0             0   \n",
       "1            0            0        0         0      0             0   \n",
       "2            0            0        0         0      0             0   \n",
       "3            0            0        0         0      0             0   \n",
       "4            0            0        0         0      0             0   \n",
       "\n",
       "   toronto rap  canadian hip hop  boy band  hardcore hip hop  queens hip hop  \\\n",
       "0            0                 0         0                 0               0   \n",
       "1            0                 0         0                 0               0   \n",
       "2            0                 0         0                 0               0   \n",
       "3            0                 0         0                 0               0   \n",
       "4            0                 0         0                 0               0   \n",
       "\n",
       "   talent show  emo  europop  acoustic pop  alternative r&b  \\\n",
       "0            0    0        0             0                0   \n",
       "1            0    0        0             0                0   \n",
       "2            0    0        0             0                0   \n",
       "3            0    0        0             0                0   \n",
       "4            0    0        0             0                0   \n",
       "\n",
       "   conscious hip hop  australian pop  detroit hip hop  rap rock  latin pop  \\\n",
       "0                  0               0                0         0          0   \n",
       "1                  1               0                0         1          0   \n",
       "2                  0               0                0         0          0   \n",
       "3                  0               0                0         0          0   \n",
       "4                  0               0                0         0          0   \n",
       "\n",
       "   barbadian pop  g funk  girl group  canadian rock  tropical  piano rock  \\\n",
       "0              0       0           0              0         0           0   \n",
       "1              0       0           0              0         0           0   \n",
       "2              0       0           0              0         0           0   \n",
       "3              0       0           0              0         0           0   \n",
       "4              0       0           0              0         0           0   \n",
       "\n",
       "   indie pop  electro house  indie poptimism  rap metal  west coast rap  \\\n",
       "0          0              0                0          0               0   \n",
       "1          0              0                0          1               0   \n",
       "2          0              0                0          0               0   \n",
       "3          0              0                0          0               0   \n",
       "4          0              0                0          0               0   \n",
       "\n",
       "   new orleans rap  metropopolis  candy pop  lilith  australian country  \\\n",
       "0                0             0          0       0                   0   \n",
       "1                0             0          0       0                   0   \n",
       "2                0             0          0       0                   0   \n",
       "3                0             0          0       0                   0   \n",
       "4                0             0          0       0                   0   \n",
       "\n",
       "   philly rap  funk metal  reggaeton  dfw rap  canadian contemporary r&b  \\\n",
       "0           0           0          0        0                          0   \n",
       "1           0           1          0        0                          0   \n",
       "2           0           0          0        0                          0   \n",
       "3           1           0          0        0                          0   \n",
       "4           0           0          0        0                          0   \n",
       "\n",
       "   soul  mexican pop  adult standards  nc hip hop  british soul  trap queen  \\\n",
       "0     0            0                0           0             0           0   \n",
       "1     0            0                0           0             0           0   \n",
       "2     0            0                0           0             0           0   \n",
       "3     0            0                0           0             0           0   \n",
       "4     0            0                0           0             0           0   \n",
       "\n",
       "   hollywood  arkansas country  atl trap  underground hip hop  texas country  \\\n",
       "0          0                 0         0                    0              0   \n",
       "1          0                 0         0                    0              0   \n",
       "2          0                 0         0                    0              0   \n",
       "3          0                 0         0                    0              0   \n",
       "4          0                 0         0                    0              0   \n",
       "\n",
       "   uk dance  house  new wave pop  brostep  dancehall  progressive house  funk  \\\n",
       "0         0      0             0        0          0                  0     0   \n",
       "1         0      0             0        0          0                  0     0   \n",
       "2         0      0             0        0          0                  0     0   \n",
       "3         0      0             0        0          0                  0     0   \n",
       "4         0      0             0        0          0                  0     0   \n",
       "\n",
       "   singer-songwriter  latin hip hop  idol  garage rock  mellow gold  \\\n",
       "0                  0              0     0            0            0   \n",
       "1                  0              0     0            0            0   \n",
       "2                  0              0     0            0            0   \n",
       "3                  0              0     0            0            0   \n",
       "4                  0              0     0            0            0   \n",
       "\n",
       "   baroque pop  big room  art pop  reggae fusion  cali rap  bronx hip hop  \\\n",
       "0            0         0        0              0         0              0   \n",
       "1            0         0        0              0         0              0   \n",
       "2            0         0        0              0         0              0   \n",
       "3            0         0        0              0         0              0   \n",
       "4            0         0        0              0         0              0   \n",
       "\n",
       "   folk-pop  country rap  stomp and holler  neon pop punk  emo rap  punk  \\\n",
       "0         0            0                 0              0        0     0   \n",
       "1         0            0                 0              0        0     0   \n",
       "2         0            0                 0              0        0     0   \n",
       "3         0            0                 0              0        0     0   \n",
       "4         0            0                 0              0        0     0   \n",
       "\n",
       "   indie rock  funk rock  memphis hip hop  modern alternative rock  \\\n",
       "0           0          0                0                        0   \n",
       "1           0          0                0                        0   \n",
       "2           0          0                0                        0   \n",
       "3           0          0                0                        0   \n",
       "4           0          0                0                        0   \n",
       "\n",
       "   lgbtq+ hip hop  progressive electro house  alternative hip hop  blues rock  \\\n",
       "0               0                          0                    0           0   \n",
       "1               0                          0                    0           0   \n",
       "2               0                          0                    0           0   \n",
       "3               0                          0                    0           0   \n",
       "4               0                          0                    0           0   \n",
       "\n",
       "   colombian pop  eurodance  classic rock  baton rouge rap  australian dance  \\\n",
       "0              0          0             0                0                 0   \n",
       "1              0          0             0                0                 0   \n",
       "2              0          0             0                0                 0   \n",
       "3              0          0             0                0                 0   \n",
       "4              0          0             0                0                 0   \n",
       "\n",
       "   folk  pop emo  soft rock  motown  pixie  canadian country  wrestling  \\\n",
       "0     0        0          0       0      0                 0          0   \n",
       "1     0        0          0       0      0                 0          0   \n",
       "2     0        0          0       0      0                 0          0   \n",
       "3     0        0          0       0      0                 0          0   \n",
       "4     0        0          0       0      0                 0          0   \n",
       "\n",
       "   glee club  complextro  vapor trap  etherpop  pittsburgh rap  escape room  \\\n",
       "0          0           0           0         0               0            0   \n",
       "1          0           0           0         0               0            0   \n",
       "2          0           0           0         0               0            0   \n",
       "3          0           0           0         0               0            0   \n",
       "4          0           0           0         0               0            0   \n",
       "\n",
       "   indietronica  comic  german techno  new jersey rap  trap latino  \\\n",
       "0             0      0              0               0            0   \n",
       "1             0      0              0               0            0   \n",
       "2             0      0              0               0            0   \n",
       "3             0      0              0               0            0   \n",
       "4             0      0              0               0            0   \n",
       "\n",
       "   houston rap  social media pop  puerto rican pop  deep southern trap  \\\n",
       "0            0                 0                 0                   0   \n",
       "1            0                 0                 0                   0   \n",
       "2            0                 0                 0                   0   \n",
       "3            0                 0                 0                   0   \n",
       "4            0                 0                 0                   0   \n",
       "\n",
       "   heartland rock  alternative dance  bubblegum dance  alberta country  \\\n",
       "0               0                  0                0                0   \n",
       "1               0                  0                0                0   \n",
       "2               0                  0                0                0   \n",
       "3               0                  0                0                0   \n",
       "4               0                  0                0                0   \n",
       "\n",
       "   outlaw country  country gospel  florida rap  hard rock  canadian metal  \\\n",
       "0               0               0            0          0               0   \n",
       "1               0               0            0          0               0   \n",
       "2               0               0            0          0               0   \n",
       "3               0               0            0          0               0   \n",
       "4               0               0            0          0               0   \n",
       "\n",
       "   christian rock  soca  indiecoustica  harlem hip hop  new rave  \\\n",
       "0               0     0              0               0         0   \n",
       "1               0     0              0               0         0   \n",
       "2               0     0              0               0         0   \n",
       "3               0     0              0               0         0   \n",
       "4               0     0              0               0         0   \n",
       "\n",
       "   electronic trap  christian music  grunge  show tunes  viral trap  la indie  \\\n",
       "0                0                0       0           0           0         0   \n",
       "1                0                0       0           0           0         0   \n",
       "2                0                0       0           0           0         0   \n",
       "3                0                0       0           0           0         0   \n",
       "4                0                0       0           0           0         0   \n",
       "\n",
       "   swedish pop  swedish electropop  reggaeton flow  dance-punk  celtic rock  \\\n",
       "0            0                   0               0           0            0   \n",
       "1            0                   0               0           0            0   \n",
       "2            0                   0               0           0            0   \n",
       "3            0                   0               0           0            0   \n",
       "4            0                   0               0           0            0   \n",
       "\n",
       "   socal pop punk  lounge  chicano rap  stomp pop  ccm  vocal jazz  \\\n",
       "0               0       0            0          0    0           0   \n",
       "1               0       0            0          0    0           0   \n",
       "2               0       0            0          0    0           0   \n",
       "3               0       0            0          0    0           0   \n",
       "4               0       0            0          0    0           0   \n",
       "\n",
       "   glam metal  worship  irish rock  electropowerpop  electro  indie pop rap  \\\n",
       "0           0        0           0                0        0              0   \n",
       "1           0        0           0                0        0              0   \n",
       "2           0        0           0                0        0              0   \n",
       "3           0        0           0                0        0              0   \n",
       "4           0        0           0                0        0              0   \n",
       "\n",
       "   canadian contemporary country  bounce  christian alternative rock  \\\n",
       "0                              0       0                           0   \n",
       "1                              0       0                           0   \n",
       "2                              0       0                           0   \n",
       "3                              0       0                           0   \n",
       "4                              0       0                           0   \n",
       "\n",
       "   south african rock  deep talent show  disco  hyphy  disco house  \\\n",
       "0                   0                 0      0      0            0   \n",
       "1                   0                 0      0      0            0   \n",
       "2                   0                 0      0      0            0   \n",
       "3                   0                 0      0      0            0   \n",
       "4                   0                 0      0      0            0   \n",
       "\n",
       "   canadian latin  australian hip hop  nyc rap  brill building pop  k-pop  \\\n",
       "0               0                   0        0                   0      0   \n",
       "1               0                   0        0                   0      0   \n",
       "2               0                   0        0                   0      0   \n",
       "3               0                   0        0                   0      0   \n",
       "4               0                   0        0                   0      0   \n",
       "\n",
       "   nz pop  minnesota hip hop  modern blues rock  album rock  modern folk rock  \\\n",
       "0       0                  0                  0           0                 0   \n",
       "1       0                  0                  0           0                 0   \n",
       "2       0                  0                  0           0                 0   \n",
       "3       0                  0                  0           0                 0   \n",
       "4       0                  0                  0           0                 0   \n",
       "\n",
       "   uk americana  old school hip hop  punk blues  dmv rap  industrial metal  \\\n",
       "0             0                   0           0        0                 0   \n",
       "1             0                   0           0        0                 0   \n",
       "2             0                   0           0        0                 0   \n",
       "3             0                   0           0        0                 0   \n",
       "4             0                   0           0        0                 0   \n",
       "\n",
       "   skate punk  swedish synthpop  moombahton  in_top5_genres  \\\n",
       "0           0                 0           0               0   \n",
       "1           0                 0           0               0   \n",
       "2           0                 0           0               1   \n",
       "3           0                 0           0               1   \n",
       "4           0                 0           0               0   \n",
       "\n",
       "   Max_Peak_Position  Max_Rank_Change  In_Top5genres_Mean  \n",
       "0                 69             -8.0                 0.0  \n",
       "1                 69             10.0                 0.0  \n",
       "2                  1              9.0                 1.0  \n",
       "3                 26             31.0                 1.0  \n",
       "4                 19             19.0                 0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding max peak position to main df\n",
    "df_2000s_data = df_hotlist_and_features_2000s.join(df_max_peak_pos, on='SongID')\n",
    "\n",
    "# adding max rank change to main df\n",
    "df_2000s_data = df_2000s_data.join(df_max_rank_change, on='SongID')\n",
    "\n",
    "# adding in top5genres mean to main df\n",
    "df_2000s_data = df_2000s_data.join(df_mean_genre_match, on='SongID')\n",
    "\n",
    "df_2000s_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103420, 112098)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a clean df with genre information\n",
    "df_clean_withgenre = df_2000s_data.drop(['WeekID', 'Week Position', 'Previous Week Position', 'Peak Position',\n",
    "                                         'Weeks on Chart', 'Rank_Change', 'in_top5_genres'], axis=1)\n",
    "\n",
    "# counting duplicates and all rows\n",
    "df_clean_withgenre.duplicated().sum(), len(df_clean_withgenre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 8678\n",
      "Duplicate rows: 0\n",
      "Rows with missing values: 820\n"
     ]
    }
   ],
   "source": [
    "# removing duplicate rows\n",
    "df_clean_withgenre = df_clean_withgenre.drop_duplicates()\n",
    "\n",
    "# checking duplicate rows and rows with missing values\n",
    "print(f\"Total rows: {len(df_clean_withgenre)}\")\n",
    "print(f\"Duplicate rows: {df_clean_withgenre.duplicated().sum()}\")\n",
    "print(f\"Rows with missing values: {df_clean_withgenre.isna().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 7858\n",
      "Duplicate rows: 0\n",
      "Rows with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# dropping rows with missing values (unfortunately there is no reliable way to infer or estimate song characteristics)\n",
    "df_clean_withgenre = df_clean_withgenre.dropna()\n",
    "\n",
    "# re-checking duplicate rows and rows with missing values\n",
    "print(f\"Total rows: {len(df_clean_withgenre)}\")\n",
    "print(f\"Duplicate rows: {df_clean_withgenre.duplicated().sum()}\")\n",
    "print(f\"Rows with missing values: {df_clean_withgenre.isna().any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a clean df with no genre\n",
    "nogenre_cols = ['spotify_track_duration_ms', 'danceability', 'energy', 'key', 'loudness',\n",
    "                'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', \n",
    "                'time_signature', 'Max_Peak_Position', 'Max_Rank_Change', 'In_Top5genres_Mean']\n",
    "df_clean_nogenre = df_clean_withgenre[nogenre_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have two datasets: one containing genre and one without. This will allow me to model this data with and without genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>pop</th>\n",
       "      <th>dance pop</th>\n",
       "      <th>pop rap</th>\n",
       "      <th>rap</th>\n",
       "      <th>contemporary country</th>\n",
       "      <th>country</th>\n",
       "      <th>country road</th>\n",
       "      <th>post-teen pop</th>\n",
       "      <th>hip hop</th>\n",
       "      <th>r&amp;b</th>\n",
       "      <th>urban contemporary</th>\n",
       "      <th>trap</th>\n",
       "      <th>southern hip hop</th>\n",
       "      <th>pop rock</th>\n",
       "      <th>hip pop</th>\n",
       "      <th>modern country rock</th>\n",
       "      <th>neo mellow</th>\n",
       "      <th>post-grunge</th>\n",
       "      <th>gangster rap</th>\n",
       "      <th>atl hip hop</th>\n",
       "      <th>alternative metal</th>\n",
       "      <th>neo soul</th>\n",
       "      <th>dirty south rap</th>\n",
       "      <th>country dawn</th>\n",
       "      <th>modern rock</th>\n",
       "      <th>nu metal</th>\n",
       "      <th>canadian pop</th>\n",
       "      <th>rock</th>\n",
       "      <th>melodic rap</th>\n",
       "      <th>deep pop r&amp;b</th>\n",
       "      <th>edm</th>\n",
       "      <th>new jack swing</th>\n",
       "      <th>permanent wave</th>\n",
       "      <th>miami hip hop</th>\n",
       "      <th>country pop</th>\n",
       "      <th>oklahoma country</th>\n",
       "      <th>latin</th>\n",
       "      <th>tropical house</th>\n",
       "      <th>electropop</th>\n",
       "      <th>uk pop</th>\n",
       "      <th>east coast hip hop</th>\n",
       "      <th>alternative rock</th>\n",
       "      <th>viral pop</th>\n",
       "      <th>quiet storm</th>\n",
       "      <th>chicago rap</th>\n",
       "      <th>redneck</th>\n",
       "      <th>pop punk</th>\n",
       "      <th>crunk</th>\n",
       "      <th>country rock</th>\n",
       "      <th>toronto rap</th>\n",
       "      <th>canadian hip hop</th>\n",
       "      <th>boy band</th>\n",
       "      <th>hardcore hip hop</th>\n",
       "      <th>queens hip hop</th>\n",
       "      <th>talent show</th>\n",
       "      <th>emo</th>\n",
       "      <th>europop</th>\n",
       "      <th>acoustic pop</th>\n",
       "      <th>alternative r&amp;b</th>\n",
       "      <th>conscious hip hop</th>\n",
       "      <th>australian pop</th>\n",
       "      <th>detroit hip hop</th>\n",
       "      <th>rap rock</th>\n",
       "      <th>latin pop</th>\n",
       "      <th>barbadian pop</th>\n",
       "      <th>g funk</th>\n",
       "      <th>girl group</th>\n",
       "      <th>canadian rock</th>\n",
       "      <th>tropical</th>\n",
       "      <th>piano rock</th>\n",
       "      <th>indie pop</th>\n",
       "      <th>electro house</th>\n",
       "      <th>indie poptimism</th>\n",
       "      <th>rap metal</th>\n",
       "      <th>west coast rap</th>\n",
       "      <th>new orleans rap</th>\n",
       "      <th>metropopolis</th>\n",
       "      <th>candy pop</th>\n",
       "      <th>lilith</th>\n",
       "      <th>australian country</th>\n",
       "      <th>philly rap</th>\n",
       "      <th>funk metal</th>\n",
       "      <th>reggaeton</th>\n",
       "      <th>dfw rap</th>\n",
       "      <th>canadian contemporary r&amp;b</th>\n",
       "      <th>soul</th>\n",
       "      <th>mexican pop</th>\n",
       "      <th>adult standards</th>\n",
       "      <th>nc hip hop</th>\n",
       "      <th>british soul</th>\n",
       "      <th>trap queen</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>arkansas country</th>\n",
       "      <th>atl trap</th>\n",
       "      <th>underground hip hop</th>\n",
       "      <th>texas country</th>\n",
       "      <th>uk dance</th>\n",
       "      <th>house</th>\n",
       "      <th>new wave pop</th>\n",
       "      <th>brostep</th>\n",
       "      <th>dancehall</th>\n",
       "      <th>progressive house</th>\n",
       "      <th>funk</th>\n",
       "      <th>singer-songwriter</th>\n",
       "      <th>latin hip hop</th>\n",
       "      <th>idol</th>\n",
       "      <th>garage rock</th>\n",
       "      <th>mellow gold</th>\n",
       "      <th>baroque pop</th>\n",
       "      <th>big room</th>\n",
       "      <th>art pop</th>\n",
       "      <th>reggae fusion</th>\n",
       "      <th>cali rap</th>\n",
       "      <th>bronx hip hop</th>\n",
       "      <th>folk-pop</th>\n",
       "      <th>country rap</th>\n",
       "      <th>stomp and holler</th>\n",
       "      <th>neon pop punk</th>\n",
       "      <th>emo rap</th>\n",
       "      <th>punk</th>\n",
       "      <th>indie rock</th>\n",
       "      <th>funk rock</th>\n",
       "      <th>memphis hip hop</th>\n",
       "      <th>modern alternative rock</th>\n",
       "      <th>lgbtq+ hip hop</th>\n",
       "      <th>progressive electro house</th>\n",
       "      <th>alternative hip hop</th>\n",
       "      <th>blues rock</th>\n",
       "      <th>colombian pop</th>\n",
       "      <th>eurodance</th>\n",
       "      <th>classic rock</th>\n",
       "      <th>baton rouge rap</th>\n",
       "      <th>australian dance</th>\n",
       "      <th>folk</th>\n",
       "      <th>pop emo</th>\n",
       "      <th>soft rock</th>\n",
       "      <th>motown</th>\n",
       "      <th>pixie</th>\n",
       "      <th>canadian country</th>\n",
       "      <th>wrestling</th>\n",
       "      <th>glee club</th>\n",
       "      <th>complextro</th>\n",
       "      <th>vapor trap</th>\n",
       "      <th>etherpop</th>\n",
       "      <th>pittsburgh rap</th>\n",
       "      <th>escape room</th>\n",
       "      <th>indietronica</th>\n",
       "      <th>comic</th>\n",
       "      <th>german techno</th>\n",
       "      <th>new jersey rap</th>\n",
       "      <th>trap latino</th>\n",
       "      <th>houston rap</th>\n",
       "      <th>social media pop</th>\n",
       "      <th>puerto rican pop</th>\n",
       "      <th>deep southern trap</th>\n",
       "      <th>heartland rock</th>\n",
       "      <th>alternative dance</th>\n",
       "      <th>bubblegum dance</th>\n",
       "      <th>alberta country</th>\n",
       "      <th>outlaw country</th>\n",
       "      <th>country gospel</th>\n",
       "      <th>florida rap</th>\n",
       "      <th>hard rock</th>\n",
       "      <th>canadian metal</th>\n",
       "      <th>christian rock</th>\n",
       "      <th>soca</th>\n",
       "      <th>indiecoustica</th>\n",
       "      <th>harlem hip hop</th>\n",
       "      <th>new rave</th>\n",
       "      <th>electronic trap</th>\n",
       "      <th>christian music</th>\n",
       "      <th>grunge</th>\n",
       "      <th>show tunes</th>\n",
       "      <th>viral trap</th>\n",
       "      <th>la indie</th>\n",
       "      <th>swedish pop</th>\n",
       "      <th>swedish electropop</th>\n",
       "      <th>reggaeton flow</th>\n",
       "      <th>dance-punk</th>\n",
       "      <th>celtic rock</th>\n",
       "      <th>socal pop punk</th>\n",
       "      <th>lounge</th>\n",
       "      <th>chicano rap</th>\n",
       "      <th>stomp pop</th>\n",
       "      <th>ccm</th>\n",
       "      <th>vocal jazz</th>\n",
       "      <th>glam metal</th>\n",
       "      <th>worship</th>\n",
       "      <th>irish rock</th>\n",
       "      <th>electropowerpop</th>\n",
       "      <th>electro</th>\n",
       "      <th>indie pop rap</th>\n",
       "      <th>canadian contemporary country</th>\n",
       "      <th>bounce</th>\n",
       "      <th>christian alternative rock</th>\n",
       "      <th>south african rock</th>\n",
       "      <th>deep talent show</th>\n",
       "      <th>disco</th>\n",
       "      <th>hyphy</th>\n",
       "      <th>disco house</th>\n",
       "      <th>canadian latin</th>\n",
       "      <th>australian hip hop</th>\n",
       "      <th>nyc rap</th>\n",
       "      <th>brill building pop</th>\n",
       "      <th>k-pop</th>\n",
       "      <th>nz pop</th>\n",
       "      <th>minnesota hip hop</th>\n",
       "      <th>modern blues rock</th>\n",
       "      <th>album rock</th>\n",
       "      <th>modern folk rock</th>\n",
       "      <th>uk americana</th>\n",
       "      <th>old school hip hop</th>\n",
       "      <th>punk blues</th>\n",
       "      <th>dmv rap</th>\n",
       "      <th>industrial metal</th>\n",
       "      <th>skate punk</th>\n",
       "      <th>swedish synthpop</th>\n",
       "      <th>moombahton</th>\n",
       "      <th>Max_Peak_Position</th>\n",
       "      <th>Max_Rank_Change</th>\n",
       "      <th>In_Top5genres_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.00000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>225877.547340</td>\n",
       "      <td>0.634195</td>\n",
       "      <td>0.683831</td>\n",
       "      <td>5.258590</td>\n",
       "      <td>-5.955137</td>\n",
       "      <td>0.663019</td>\n",
       "      <td>0.110003</td>\n",
       "      <td>0.173873</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>0.506799</td>\n",
       "      <td>122.323709</td>\n",
       "      <td>3.972003</td>\n",
       "      <td>0.313566</td>\n",
       "      <td>0.278315</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>0.252354</td>\n",
       "      <td>0.162001</td>\n",
       "      <td>0.153092</td>\n",
       "      <td>0.145839</td>\n",
       "      <td>0.181598</td>\n",
       "      <td>0.187580</td>\n",
       "      <td>0.113006</td>\n",
       "      <td>0.103334</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>0.116187</td>\n",
       "      <td>0.072410</td>\n",
       "      <td>0.078264</td>\n",
       "      <td>0.068465</td>\n",
       "      <td>0.050904</td>\n",
       "      <td>0.049631</td>\n",
       "      <td>0.058030</td>\n",
       "      <td>0.058285</td>\n",
       "      <td>0.034869</td>\n",
       "      <td>0.037414</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.032324</td>\n",
       "      <td>0.029142</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.032706</td>\n",
       "      <td>0.034742</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.016544</td>\n",
       "      <td>0.022525</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.013871</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.00789</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.029906</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>75.775261</td>\n",
       "      <td>12.531815</td>\n",
       "      <td>0.383706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46659.091277</td>\n",
       "      <td>0.149508</td>\n",
       "      <td>0.172011</td>\n",
       "      <td>3.589907</td>\n",
       "      <td>2.228035</td>\n",
       "      <td>0.472709</td>\n",
       "      <td>0.110535</td>\n",
       "      <td>0.215344</td>\n",
       "      <td>0.066326</td>\n",
       "      <td>0.140660</td>\n",
       "      <td>0.223494</td>\n",
       "      <td>29.558487</td>\n",
       "      <td>0.273062</td>\n",
       "      <td>0.463972</td>\n",
       "      <td>0.448198</td>\n",
       "      <td>0.450128</td>\n",
       "      <td>0.434391</td>\n",
       "      <td>0.368475</td>\n",
       "      <td>0.360099</td>\n",
       "      <td>0.352967</td>\n",
       "      <td>0.385538</td>\n",
       "      <td>0.390401</td>\n",
       "      <td>0.316620</td>\n",
       "      <td>0.304414</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.320470</td>\n",
       "      <td>0.259183</td>\n",
       "      <td>0.268604</td>\n",
       "      <td>0.252559</td>\n",
       "      <td>0.219815</td>\n",
       "      <td>0.217195</td>\n",
       "      <td>0.233815</td>\n",
       "      <td>0.234296</td>\n",
       "      <td>0.183459</td>\n",
       "      <td>0.189786</td>\n",
       "      <td>0.190096</td>\n",
       "      <td>0.176870</td>\n",
       "      <td>0.168216</td>\n",
       "      <td>0.160538</td>\n",
       "      <td>0.199717</td>\n",
       "      <td>0.177876</td>\n",
       "      <td>0.183136</td>\n",
       "      <td>0.138623</td>\n",
       "      <td>0.139063</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.144655</td>\n",
       "      <td>0.143810</td>\n",
       "      <td>0.133675</td>\n",
       "      <td>0.127562</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>0.128043</td>\n",
       "      <td>0.130422</td>\n",
       "      <td>0.116964</td>\n",
       "      <td>0.124136</td>\n",
       "      <td>0.132755</td>\n",
       "      <td>0.128043</td>\n",
       "      <td>0.122637</td>\n",
       "      <td>0.136398</td>\n",
       "      <td>0.119578</td>\n",
       "      <td>0.115365</td>\n",
       "      <td>0.110423</td>\n",
       "      <td>0.110984</td>\n",
       "      <td>0.138623</td>\n",
       "      <td>0.138181</td>\n",
       "      <td>0.120607</td>\n",
       "      <td>0.109293</td>\n",
       "      <td>0.107574</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>0.098510</td>\n",
       "      <td>0.092627</td>\n",
       "      <td>0.103447</td>\n",
       "      <td>0.123639</td>\n",
       "      <td>0.089885</td>\n",
       "      <td>0.115901</td>\n",
       "      <td>0.084123</td>\n",
       "      <td>0.104644</td>\n",
       "      <td>0.072049</td>\n",
       "      <td>0.103447</td>\n",
       "      <td>0.08848</td>\n",
       "      <td>0.072049</td>\n",
       "      <td>0.095941</td>\n",
       "      <td>0.077111</td>\n",
       "      <td>0.084123</td>\n",
       "      <td>0.084123</td>\n",
       "      <td>0.075462</td>\n",
       "      <td>0.084123</td>\n",
       "      <td>0.089185</td>\n",
       "      <td>0.102236</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.084865</td>\n",
       "      <td>0.076291</td>\n",
       "      <td>0.071169</td>\n",
       "      <td>0.110984</td>\n",
       "      <td>0.072049</td>\n",
       "      <td>0.094630</td>\n",
       "      <td>0.071169</td>\n",
       "      <td>0.087053</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.082617</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.084123</td>\n",
       "      <td>0.065640</td>\n",
       "      <td>0.068462</td>\n",
       "      <td>0.170338</td>\n",
       "      <td>0.063688</td>\n",
       "      <td>0.084123</td>\n",
       "      <td>0.078725</td>\n",
       "      <td>0.064672</td>\n",
       "      <td>0.056318</td>\n",
       "      <td>0.057430</td>\n",
       "      <td>0.065640</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>0.056318</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.071169</td>\n",
       "      <td>0.065640</td>\n",
       "      <td>0.073776</td>\n",
       "      <td>0.068462</td>\n",
       "      <td>0.072049</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.062689</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.057430</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.079519</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>0.063688</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.050389</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>0.046465</td>\n",
       "      <td>0.057430</td>\n",
       "      <td>0.075462</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.054026</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>0.050389</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.159028</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.069376</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.046465</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.046465</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.069376</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.029835</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.035653</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.022558</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>24.561479</td>\n",
       "      <td>11.760207</td>\n",
       "      <td>0.466419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37013.000000</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.023000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>48.718000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>198219.250000</td>\n",
       "      <td>0.533250</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-7.079000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>97.943500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>221798.500000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-5.640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>121.070000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>248459.500000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-4.406500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>142.397250</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>992160.000000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>213.737000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spotify_track_duration_ms  danceability       energy          key  \\\n",
       "count                7858.000000   7858.000000  7858.000000  7858.000000   \n",
       "mean               225877.547340      0.634195     0.683831     5.258590   \n",
       "std                 46659.091277      0.149508     0.172011     3.589907   \n",
       "min                 37013.000000      0.113000     0.031600     0.000000   \n",
       "25%                198219.250000      0.533250     0.571000     2.000000   \n",
       "50%                221798.500000      0.638000     0.704000     5.000000   \n",
       "75%                248459.500000      0.740000     0.819000     8.000000   \n",
       "max                992160.000000      0.986000     0.996000    11.000000   \n",
       "\n",
       "          loudness         mode  speechiness  acousticness  instrumentalness  \\\n",
       "count  7858.000000  7858.000000  7858.000000   7858.000000       7858.000000   \n",
       "mean     -5.955137     0.663019     0.110003      0.173873          0.008682   \n",
       "std       2.228035     0.472709     0.110535      0.215344          0.066326   \n",
       "min     -23.023000     0.000000     0.022400      0.000003          0.000000   \n",
       "25%      -7.079000     0.000000     0.036200      0.019225          0.000000   \n",
       "50%      -5.640000     1.000000     0.057250      0.081900          0.000000   \n",
       "75%      -4.406500     1.000000     0.143000      0.247000          0.000017   \n",
       "max       0.175000     1.000000     0.951000      0.987000          0.982000   \n",
       "\n",
       "          liveness      valence        tempo  time_signature          pop  \\\n",
       "count  7858.000000  7858.000000  7858.000000     7858.000000  7858.000000   \n",
       "mean      0.184399     0.506799   122.323709        3.972003     0.313566   \n",
       "std       0.140660     0.223494    29.558487        0.273062     0.463972   \n",
       "min       0.020000     0.034900    48.718000        0.000000     0.000000   \n",
       "25%       0.095900     0.330000    97.943500        4.000000     0.000000   \n",
       "50%       0.128000     0.505000   121.070000        4.000000     0.000000   \n",
       "75%       0.234000     0.679000   142.397250        4.000000     1.000000   \n",
       "max       0.986000     0.976000   213.737000        5.000000     1.000000   \n",
       "\n",
       "         dance pop      pop rap          rap  contemporary country  \\\n",
       "count  7858.000000  7858.000000  7858.000000           7858.000000   \n",
       "mean      0.278315     0.282260     0.252354              0.162001   \n",
       "std       0.448198     0.450128     0.434391              0.368475   \n",
       "min       0.000000     0.000000     0.000000              0.000000   \n",
       "25%       0.000000     0.000000     0.000000              0.000000   \n",
       "50%       0.000000     0.000000     0.000000              0.000000   \n",
       "75%       1.000000     1.000000     1.000000              0.000000   \n",
       "max       1.000000     1.000000     1.000000              1.000000   \n",
       "\n",
       "           country  country road  post-teen pop      hip hop          r&b  \\\n",
       "count  7858.000000   7858.000000    7858.000000  7858.000000  7858.000000   \n",
       "mean      0.153092      0.145839       0.181598     0.187580     0.113006   \n",
       "std       0.360099      0.352967       0.385538     0.390401     0.316620   \n",
       "min       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "75%       0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "max       1.000000      1.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "       urban contemporary         trap  southern hip hop     pop rock  \\\n",
       "count         7858.000000  7858.000000       7858.000000  7858.000000   \n",
       "mean             0.103334     0.147875          0.116187     0.072410   \n",
       "std              0.304414     0.354998          0.320470     0.259183   \n",
       "min              0.000000     0.000000          0.000000     0.000000   \n",
       "25%              0.000000     0.000000          0.000000     0.000000   \n",
       "50%              0.000000     0.000000          0.000000     0.000000   \n",
       "75%              0.000000     0.000000          0.000000     0.000000   \n",
       "max              1.000000     1.000000          1.000000     1.000000   \n",
       "\n",
       "           hip pop  modern country rock   neo mellow  post-grunge  \\\n",
       "count  7858.000000          7858.000000  7858.000000  7858.000000   \n",
       "mean      0.078264             0.068465     0.050904     0.049631   \n",
       "std       0.268604             0.252559     0.219815     0.217195   \n",
       "min       0.000000             0.000000     0.000000     0.000000   \n",
       "25%       0.000000             0.000000     0.000000     0.000000   \n",
       "50%       0.000000             0.000000     0.000000     0.000000   \n",
       "75%       0.000000             0.000000     0.000000     0.000000   \n",
       "max       1.000000             1.000000     1.000000     1.000000   \n",
       "\n",
       "       gangster rap  atl hip hop  alternative metal     neo soul  \\\n",
       "count   7858.000000  7858.000000        7858.000000  7858.000000   \n",
       "mean       0.058030     0.058285           0.034869     0.037414   \n",
       "std        0.233815     0.234296           0.183459     0.189786   \n",
       "min        0.000000     0.000000           0.000000     0.000000   \n",
       "25%        0.000000     0.000000           0.000000     0.000000   \n",
       "50%        0.000000     0.000000           0.000000     0.000000   \n",
       "75%        0.000000     0.000000           0.000000     0.000000   \n",
       "max        1.000000     1.000000           1.000000     1.000000   \n",
       "\n",
       "       dirty south rap  country dawn  modern rock     nu metal  canadian pop  \\\n",
       "count      7858.000000   7858.000000  7858.000000  7858.000000   7858.000000   \n",
       "mean          0.037541      0.032324     0.029142     0.026470      0.041614   \n",
       "std           0.190096      0.176870     0.168216     0.160538      0.199717   \n",
       "min           0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "25%           0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "50%           0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "75%           0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "max           1.000000      1.000000     1.000000     1.000000      1.000000   \n",
       "\n",
       "              rock  melodic rap  deep pop r&b          edm  new jack swing  \\\n",
       "count  7858.000000  7858.000000   7858.000000  7858.000000     7858.000000   \n",
       "mean      0.032706     0.034742      0.019598     0.019725        0.018325   \n",
       "std       0.177876     0.183136      0.138623     0.139063        0.134133   \n",
       "min       0.000000     0.000000      0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000      0.000000     0.000000        0.000000   \n",
       "50%       0.000000     0.000000      0.000000     0.000000        0.000000   \n",
       "75%       0.000000     0.000000      0.000000     0.000000        0.000000   \n",
       "max       1.000000     1.000000      1.000000     1.000000        1.000000   \n",
       "\n",
       "       permanent wave  miami hip hop  country pop  oklahoma country  \\\n",
       "count     7858.000000    7858.000000  7858.000000       7858.000000   \n",
       "mean         0.021379       0.021125     0.018198          0.016544   \n",
       "std          0.144655       0.143810     0.133675          0.127562   \n",
       "min          0.000000       0.000000     0.000000          0.000000   \n",
       "25%          0.000000       0.000000     0.000000          0.000000   \n",
       "50%          0.000000       0.000000     0.000000          0.000000   \n",
       "75%          0.000000       0.000000     0.000000          0.000000   \n",
       "max          1.000000       1.000000     1.000000          1.000000   \n",
       "\n",
       "             latin  tropical house   electropop       uk pop  \\\n",
       "count  7858.000000     7858.000000  7858.000000  7858.000000   \n",
       "mean      0.022525        0.016671     0.017307     0.013871   \n",
       "std       0.148392        0.128043     0.130422     0.116964   \n",
       "min       0.000000        0.000000     0.000000     0.000000   \n",
       "25%       0.000000        0.000000     0.000000     0.000000   \n",
       "50%       0.000000        0.000000     0.000000     0.000000   \n",
       "75%       0.000000        0.000000     0.000000     0.000000   \n",
       "max       1.000000        1.000000     1.000000     1.000000   \n",
       "\n",
       "       east coast hip hop  alternative rock    viral pop  quiet storm  \\\n",
       "count         7858.000000       7858.000000  7858.000000  7858.000000   \n",
       "mean             0.015653          0.017943     0.016671     0.015271   \n",
       "std              0.124136          0.132755     0.128043     0.122637   \n",
       "min              0.000000          0.000000     0.000000     0.000000   \n",
       "25%              0.000000          0.000000     0.000000     0.000000   \n",
       "50%              0.000000          0.000000     0.000000     0.000000   \n",
       "75%              0.000000          0.000000     0.000000     0.000000   \n",
       "max              1.000000          1.000000     1.000000     1.000000   \n",
       "\n",
       "       chicago rap      redneck     pop punk        crunk  country rock  \\\n",
       "count  7858.000000  7858.000000  7858.000000  7858.000000   7858.000000   \n",
       "mean      0.018962     0.014508     0.013489     0.012344      0.012471   \n",
       "std       0.136398     0.119578     0.115365     0.110423      0.110984   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "\n",
       "       toronto rap  canadian hip hop     boy band  hardcore hip hop  \\\n",
       "count  7858.000000       7858.000000  7858.000000       7858.000000   \n",
       "mean      0.019598          0.019471     0.014762          0.012090   \n",
       "std       0.138623          0.138181     0.120607          0.109293   \n",
       "min       0.000000          0.000000     0.000000          0.000000   \n",
       "25%       0.000000          0.000000     0.000000          0.000000   \n",
       "50%       0.000000          0.000000     0.000000          0.000000   \n",
       "75%       0.000000          0.000000     0.000000          0.000000   \n",
       "max       1.000000          1.000000     1.000000          1.000000   \n",
       "\n",
       "       queens hip hop  talent show          emo      europop  acoustic pop  \\\n",
       "count     7858.000000  7858.000000  7858.000000  7858.000000   7858.000000   \n",
       "mean         0.011708     0.010435     0.010435     0.009799      0.008654   \n",
       "std          0.107574     0.101625     0.101625     0.098510      0.092627   \n",
       "min          0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%          0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "50%          0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "75%          0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "max          1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "\n",
       "       alternative r&b  conscious hip hop  australian pop  detroit hip hop  \\\n",
       "count      7858.000000        7858.000000     7858.000000      7858.000000   \n",
       "mean          0.010817           0.015526        0.008145         0.013617   \n",
       "std           0.103447           0.123639        0.089885         0.115901   \n",
       "min           0.000000           0.000000        0.000000         0.000000   \n",
       "25%           0.000000           0.000000        0.000000         0.000000   \n",
       "50%           0.000000           0.000000        0.000000         0.000000   \n",
       "75%           0.000000           0.000000        0.000000         0.000000   \n",
       "max           1.000000           1.000000        1.000000         1.000000   \n",
       "\n",
       "          rap rock    latin pop  barbadian pop       g funk  girl group  \\\n",
       "count  7858.000000  7858.000000    7858.000000  7858.000000  7858.00000   \n",
       "mean      0.007126     0.011072       0.005218     0.010817     0.00789   \n",
       "std       0.084123     0.104644       0.072049     0.103447     0.08848   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.00000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.00000   \n",
       "50%       0.000000     0.000000       0.000000     0.000000     0.00000   \n",
       "75%       0.000000     0.000000       0.000000     0.000000     0.00000   \n",
       "max       1.000000     1.000000       1.000000     1.000000     1.00000   \n",
       "\n",
       "       canadian rock     tropical   piano rock    indie pop  electro house  \\\n",
       "count    7858.000000  7858.000000  7858.000000  7858.000000    7858.000000   \n",
       "mean        0.005218     0.009290     0.005981     0.007126       0.007126   \n",
       "std         0.072049     0.095941     0.077111     0.084123       0.084123   \n",
       "min         0.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "25%         0.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "50%         0.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "75%         0.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "max         1.000000     1.000000     1.000000     1.000000       1.000000   \n",
       "\n",
       "       indie poptimism    rap metal  west coast rap  new orleans rap  \\\n",
       "count      7858.000000  7858.000000     7858.000000      7858.000000   \n",
       "mean          0.005727     0.007126        0.008017         0.010562   \n",
       "std           0.075462     0.084123        0.089185         0.102236   \n",
       "min           0.000000     0.000000        0.000000         0.000000   \n",
       "25%           0.000000     0.000000        0.000000         0.000000   \n",
       "50%           0.000000     0.000000        0.000000         0.000000   \n",
       "75%           0.000000     0.000000        0.000000         0.000000   \n",
       "max           1.000000     1.000000        1.000000         1.000000   \n",
       "\n",
       "       metropopolis    candy pop       lilith  australian country  \\\n",
       "count   7858.000000  7858.000000  7858.000000         7858.000000   \n",
       "mean       0.004581     0.007254     0.005854            0.005090   \n",
       "std        0.067535     0.084865     0.076291            0.071169   \n",
       "min        0.000000     0.000000     0.000000            0.000000   \n",
       "25%        0.000000     0.000000     0.000000            0.000000   \n",
       "50%        0.000000     0.000000     0.000000            0.000000   \n",
       "75%        0.000000     0.000000     0.000000            0.000000   \n",
       "max        1.000000     1.000000     1.000000            1.000000   \n",
       "\n",
       "        philly rap   funk metal    reggaeton      dfw rap  \\\n",
       "count  7858.000000  7858.000000  7858.000000  7858.000000   \n",
       "mean      0.012471     0.005218     0.009035     0.005090   \n",
       "std       0.110984     0.072049     0.094630     0.071169   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       canadian contemporary r&b         soul  mexican pop  adult standards  \\\n",
       "count                7858.000000  7858.000000  7858.000000      7858.000000   \n",
       "mean                    0.007636     0.006108     0.006872         0.006108   \n",
       "std                     0.087053     0.077922     0.082617         0.077922   \n",
       "min                     0.000000     0.000000     0.000000         0.000000   \n",
       "25%                     0.000000     0.000000     0.000000         0.000000   \n",
       "50%                     0.000000     0.000000     0.000000         0.000000   \n",
       "75%                     0.000000     0.000000     0.000000         0.000000   \n",
       "max                     1.000000     1.000000     1.000000         1.000000   \n",
       "\n",
       "        nc hip hop  british soul   trap queen    hollywood  arkansas country  \\\n",
       "count  7858.000000   7858.000000  7858.000000  7858.000000       7858.000000   \n",
       "mean      0.007126      0.004327     0.004709     0.029906          0.004072   \n",
       "std       0.084123      0.065640     0.068462     0.170338          0.063688   \n",
       "min       0.000000      0.000000     0.000000     0.000000          0.000000   \n",
       "25%       0.000000      0.000000     0.000000     0.000000          0.000000   \n",
       "50%       0.000000      0.000000     0.000000     0.000000          0.000000   \n",
       "75%       0.000000      0.000000     0.000000     0.000000          0.000000   \n",
       "max       1.000000      1.000000     1.000000     1.000000          1.000000   \n",
       "\n",
       "          atl trap  underground hip hop  texas country     uk dance  \\\n",
       "count  7858.000000          7858.000000    7858.000000  7858.000000   \n",
       "mean      0.007126             0.006236       0.004200     0.003181   \n",
       "std       0.084123             0.078725       0.064672     0.056318   \n",
       "min       0.000000             0.000000       0.000000     0.000000   \n",
       "25%       0.000000             0.000000       0.000000     0.000000   \n",
       "50%       0.000000             0.000000       0.000000     0.000000   \n",
       "75%       0.000000             0.000000       0.000000     0.000000   \n",
       "max       1.000000             1.000000       1.000000     1.000000   \n",
       "\n",
       "             house  new wave pop      brostep    dancehall  progressive house  \\\n",
       "count  7858.000000   7858.000000  7858.000000  7858.000000        7858.000000   \n",
       "mean      0.003309      0.004327     0.002800     0.003181           0.003818   \n",
       "std       0.057430      0.065640     0.052841     0.056318           0.061674   \n",
       "min       0.000000      0.000000     0.000000     0.000000           0.000000   \n",
       "25%       0.000000      0.000000     0.000000     0.000000           0.000000   \n",
       "50%       0.000000      0.000000     0.000000     0.000000           0.000000   \n",
       "75%       0.000000      0.000000     0.000000     0.000000           0.000000   \n",
       "max       1.000000      1.000000     1.000000     1.000000           1.000000   \n",
       "\n",
       "              funk  singer-songwriter  latin hip hop         idol  \\\n",
       "count  7858.000000        7858.000000    7858.000000  7858.000000   \n",
       "mean      0.004581           0.005090       0.004327     0.005472   \n",
       "std       0.067535           0.071169       0.065640     0.073776   \n",
       "min       0.000000           0.000000       0.000000     0.000000   \n",
       "25%       0.000000           0.000000       0.000000     0.000000   \n",
       "50%       0.000000           0.000000       0.000000     0.000000   \n",
       "75%       0.000000           0.000000       0.000000     0.000000   \n",
       "max       1.000000           1.000000       1.000000     1.000000   \n",
       "\n",
       "       garage rock  mellow gold  baroque pop     big room      art pop  \\\n",
       "count  7858.000000  7858.000000  7858.000000  7858.000000  7858.000000   \n",
       "mean      0.004709     0.005218     0.002927     0.003945     0.004581   \n",
       "std       0.068462     0.072049     0.054026     0.062689     0.067535   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       reggae fusion     cali rap  bronx hip hop     folk-pop  country rap  \\\n",
       "count    7858.000000  7858.000000    7858.000000  7858.000000  7858.000000   \n",
       "mean        0.003309     0.003054       0.002800     0.002418     0.002418   \n",
       "std         0.057430     0.055184       0.052841     0.049116     0.049116   \n",
       "min         0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%         0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%         0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "75%         0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "max         1.000000     1.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "       stomp and holler  neon pop punk      emo rap         punk   indie rock  \\\n",
       "count       7858.000000    7858.000000  7858.000000  7858.000000  7858.000000   \n",
       "mean           0.003563       0.002418     0.006363     0.003054     0.004072   \n",
       "std            0.059590       0.049116     0.079519     0.055184     0.063688   \n",
       "min            0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%            0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "50%            0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "75%            0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "max            1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         funk rock  memphis hip hop  modern alternative rock  lgbtq+ hip hop  \\\n",
       "count  7858.000000      7858.000000              7858.000000     7858.000000   \n",
       "mean      0.002927         0.003436                 0.001782        0.003436   \n",
       "std       0.054026         0.058520                 0.042174        0.058520   \n",
       "min       0.000000         0.000000                 0.000000        0.000000   \n",
       "25%       0.000000         0.000000                 0.000000        0.000000   \n",
       "50%       0.000000         0.000000                 0.000000        0.000000   \n",
       "75%       0.000000         0.000000                 0.000000        0.000000   \n",
       "max       1.000000         1.000000                 1.000000        1.000000   \n",
       "\n",
       "       progressive electro house  alternative hip hop   blues rock  \\\n",
       "count                7858.000000          7858.000000  7858.000000   \n",
       "mean                    0.001654             0.003563     0.002545   \n",
       "std                     0.040643             0.059590     0.050389   \n",
       "min                     0.000000             0.000000     0.000000   \n",
       "25%                     0.000000             0.000000     0.000000   \n",
       "50%                     0.000000             0.000000     0.000000   \n",
       "75%                     0.000000             0.000000     0.000000   \n",
       "max                     1.000000             1.000000     1.000000   \n",
       "\n",
       "       colombian pop    eurodance  classic rock  baton rouge rap  \\\n",
       "count    7858.000000  7858.000000   7858.000000      7858.000000   \n",
       "mean        0.002800     0.002163      0.003309         0.005727   \n",
       "std         0.052841     0.046465      0.057430         0.075462   \n",
       "min         0.000000     0.000000      0.000000         0.000000   \n",
       "25%         0.000000     0.000000      0.000000         0.000000   \n",
       "50%         0.000000     0.000000      0.000000         0.000000   \n",
       "75%         0.000000     0.000000      0.000000         0.000000   \n",
       "max         1.000000     1.000000      1.000000         1.000000   \n",
       "\n",
       "       australian dance         folk      pop emo    soft rock       motown  \\\n",
       "count       7858.000000  7858.000000  7858.000000  7858.000000  7858.000000   \n",
       "mean           0.001909     0.002927     0.002927     0.003818     0.002800   \n",
       "std            0.043652     0.054026     0.054026     0.061674     0.052841   \n",
       "min            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max            1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             pixie  canadian country    wrestling    glee club   complextro  \\\n",
       "count  7858.000000       7858.000000  7858.000000  7858.000000  7858.000000   \n",
       "mean      0.002545          0.002418     0.001909     0.025961     0.002036   \n",
       "std       0.050389          0.049116     0.043652     0.159028     0.045081   \n",
       "min       0.000000          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000          0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        vapor trap     etherpop  pittsburgh rap  escape room  indietronica  \\\n",
       "count  7858.000000  7858.000000     7858.000000  7858.000000   7858.000000   \n",
       "mean      0.002036     0.001273        0.004836     0.002036      0.002800   \n",
       "std       0.045081     0.035653        0.069376     0.045081      0.052841   \n",
       "min       0.000000     0.000000        0.000000     0.000000      0.000000   \n",
       "25%       0.000000     0.000000        0.000000     0.000000      0.000000   \n",
       "50%       0.000000     0.000000        0.000000     0.000000      0.000000   \n",
       "75%       0.000000     0.000000        0.000000     0.000000      0.000000   \n",
       "max       1.000000     1.000000        1.000000     1.000000      1.000000   \n",
       "\n",
       "             comic  german techno  new jersey rap  trap latino  houston rap  \\\n",
       "count  7858.000000    7858.000000     7858.000000  7858.000000  7858.000000   \n",
       "mean      0.003054       0.001782        0.001527     0.003818     0.002291   \n",
       "std       0.055184       0.042174        0.039051     0.061674     0.047809   \n",
       "min       0.000000       0.000000        0.000000     0.000000     0.000000   \n",
       "25%       0.000000       0.000000        0.000000     0.000000     0.000000   \n",
       "50%       0.000000       0.000000        0.000000     0.000000     0.000000   \n",
       "75%       0.000000       0.000000        0.000000     0.000000     0.000000   \n",
       "max       1.000000       1.000000        1.000000     1.000000     1.000000   \n",
       "\n",
       "       social media pop  puerto rican pop  deep southern trap  heartland rock  \\\n",
       "count       7858.000000       7858.000000         7858.000000     7858.000000   \n",
       "mean           0.006108          0.002418            0.001527        0.002036   \n",
       "std            0.077922          0.049116            0.039051        0.045081   \n",
       "min            0.000000          0.000000            0.000000        0.000000   \n",
       "25%            0.000000          0.000000            0.000000        0.000000   \n",
       "50%            0.000000          0.000000            0.000000        0.000000   \n",
       "75%            0.000000          0.000000            0.000000        0.000000   \n",
       "max            1.000000          1.000000            1.000000        1.000000   \n",
       "\n",
       "       alternative dance  bubblegum dance  alberta country  outlaw country  \\\n",
       "count        7858.000000      7858.000000      7858.000000     7858.000000   \n",
       "mean            0.002163         0.001273         0.001527        0.002036   \n",
       "std             0.046465         0.035653         0.039051        0.045081   \n",
       "min             0.000000         0.000000         0.000000        0.000000   \n",
       "25%             0.000000         0.000000         0.000000        0.000000   \n",
       "50%             0.000000         0.000000         0.000000        0.000000   \n",
       "75%             0.000000         0.000000         0.000000        0.000000   \n",
       "max             1.000000         1.000000         1.000000        1.000000   \n",
       "\n",
       "       country gospel  florida rap    hard rock  canadian metal  \\\n",
       "count     7858.000000  7858.000000  7858.000000     7858.000000   \n",
       "mean         0.001400     0.003691     0.002291        0.001273   \n",
       "std          0.037391     0.060641     0.047809        0.035653   \n",
       "min          0.000000     0.000000     0.000000        0.000000   \n",
       "25%          0.000000     0.000000     0.000000        0.000000   \n",
       "50%          0.000000     0.000000     0.000000        0.000000   \n",
       "75%          0.000000     0.000000     0.000000        0.000000   \n",
       "max          1.000000     1.000000     1.000000        1.000000   \n",
       "\n",
       "       christian rock         soca  indiecoustica  harlem hip hop  \\\n",
       "count     7858.000000  7858.000000    7858.000000     7858.000000   \n",
       "mean         0.001909     0.001400       0.002418        0.000891   \n",
       "std          0.043652     0.037391       0.049116        0.029835   \n",
       "min          0.000000     0.000000       0.000000        0.000000   \n",
       "25%          0.000000     0.000000       0.000000        0.000000   \n",
       "50%          0.000000     0.000000       0.000000        0.000000   \n",
       "75%          0.000000     0.000000       0.000000        0.000000   \n",
       "max          1.000000     1.000000       1.000000        1.000000   \n",
       "\n",
       "          new rave  electronic trap  christian music       grunge  \\\n",
       "count  7858.000000      7858.000000      7858.000000  7858.000000   \n",
       "mean      0.002036         0.001145         0.002036     0.002163   \n",
       "std       0.045081         0.033825         0.045081     0.046465   \n",
       "min       0.000000         0.000000         0.000000     0.000000   \n",
       "25%       0.000000         0.000000         0.000000     0.000000   \n",
       "50%       0.000000         0.000000         0.000000     0.000000   \n",
       "75%       0.000000         0.000000         0.000000     0.000000   \n",
       "max       1.000000         1.000000         1.000000     1.000000   \n",
       "\n",
       "        show tunes   viral trap     la indie  swedish pop  swedish electropop  \\\n",
       "count  7858.000000  7858.000000  7858.000000  7858.000000         7858.000000   \n",
       "mean      0.001909     0.001145     0.000891     0.001145            0.001145   \n",
       "std       0.043652     0.033825     0.029835     0.033825            0.033825   \n",
       "min       0.000000     0.000000     0.000000     0.000000            0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000            0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000            0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000            0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000            1.000000   \n",
       "\n",
       "       reggaeton flow   dance-punk  celtic rock  socal pop punk       lounge  \\\n",
       "count     7858.000000  7858.000000  7858.000000     7858.000000  7858.000000   \n",
       "mean         0.001654     0.002291     0.000891        0.001782     0.002036   \n",
       "std          0.040643     0.047809     0.029835        0.042174     0.045081   \n",
       "min          0.000000     0.000000     0.000000        0.000000     0.000000   \n",
       "25%          0.000000     0.000000     0.000000        0.000000     0.000000   \n",
       "50%          0.000000     0.000000     0.000000        0.000000     0.000000   \n",
       "75%          0.000000     0.000000     0.000000        0.000000     0.000000   \n",
       "max          1.000000     1.000000     1.000000        1.000000     1.000000   \n",
       "\n",
       "       chicano rap    stomp pop          ccm   vocal jazz   glam metal  \\\n",
       "count  7858.000000  7858.000000  7858.000000  7858.000000  7858.000000   \n",
       "mean      0.001400     0.000382     0.001654     0.001654     0.001400   \n",
       "std       0.037391     0.019537     0.040643     0.040643     0.037391   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           worship   irish rock  electropowerpop      electro  indie pop rap  \\\n",
       "count  7858.000000  7858.000000      7858.000000  7858.000000    7858.000000   \n",
       "mean      0.001527     0.001654         0.001654     0.001018       0.002036   \n",
       "std       0.039051     0.040643         0.040643     0.031893       0.045081   \n",
       "min       0.000000     0.000000         0.000000     0.000000       0.000000   \n",
       "25%       0.000000     0.000000         0.000000     0.000000       0.000000   \n",
       "50%       0.000000     0.000000         0.000000     0.000000       0.000000   \n",
       "75%       0.000000     0.000000         0.000000     0.000000       0.000000   \n",
       "max       1.000000     1.000000         1.000000     1.000000       1.000000   \n",
       "\n",
       "       canadian contemporary country       bounce  christian alternative rock  \\\n",
       "count                    7858.000000  7858.000000                 7858.000000   \n",
       "mean                        0.001018     0.001018                    0.001909   \n",
       "std                         0.031893     0.031893                    0.043652   \n",
       "min                         0.000000     0.000000                    0.000000   \n",
       "25%                         0.000000     0.000000                    0.000000   \n",
       "50%                         0.000000     0.000000                    0.000000   \n",
       "75%                         0.000000     0.000000                    0.000000   \n",
       "max                         1.000000     1.000000                    1.000000   \n",
       "\n",
       "       south african rock  deep talent show        disco        hyphy  \\\n",
       "count         7858.000000       7858.000000  7858.000000  7858.000000   \n",
       "mean             0.001018          0.004836     0.001145     0.001145   \n",
       "std              0.031893          0.069376     0.033825     0.033825   \n",
       "min              0.000000          0.000000     0.000000     0.000000   \n",
       "25%              0.000000          0.000000     0.000000     0.000000   \n",
       "50%              0.000000          0.000000     0.000000     0.000000   \n",
       "75%              0.000000          0.000000     0.000000     0.000000   \n",
       "max              1.000000          1.000000     1.000000     1.000000   \n",
       "\n",
       "       disco house  canadian latin  australian hip hop      nyc rap  \\\n",
       "count  7858.000000     7858.000000         7858.000000  7858.000000   \n",
       "mean      0.000891        0.000891            0.001273     0.001273   \n",
       "std       0.029835        0.029835            0.035653     0.035653   \n",
       "min       0.000000        0.000000            0.000000     0.000000   \n",
       "25%       0.000000        0.000000            0.000000     0.000000   \n",
       "50%       0.000000        0.000000            0.000000     0.000000   \n",
       "75%       0.000000        0.000000            0.000000     0.000000   \n",
       "max       1.000000        1.000000            1.000000     1.000000   \n",
       "\n",
       "       brill building pop        k-pop       nz pop  minnesota hip hop  \\\n",
       "count         7858.000000  7858.000000  7858.000000        7858.000000   \n",
       "mean             0.001018     0.003436     0.001018           0.000382   \n",
       "std              0.031893     0.058520     0.031893           0.019537   \n",
       "min              0.000000     0.000000     0.000000           0.000000   \n",
       "25%              0.000000     0.000000     0.000000           0.000000   \n",
       "50%              0.000000     0.000000     0.000000           0.000000   \n",
       "75%              0.000000     0.000000     0.000000           0.000000   \n",
       "max              1.000000     1.000000     1.000000           1.000000   \n",
       "\n",
       "       modern blues rock   album rock  modern folk rock  uk americana  \\\n",
       "count        7858.000000  7858.000000       7858.000000   7858.000000   \n",
       "mean            0.001273     0.002418          0.001400      0.001400   \n",
       "std             0.035653     0.049116          0.037391      0.037391   \n",
       "min             0.000000     0.000000          0.000000      0.000000   \n",
       "25%             0.000000     0.000000          0.000000      0.000000   \n",
       "50%             0.000000     0.000000          0.000000      0.000000   \n",
       "75%             0.000000     0.000000          0.000000      0.000000   \n",
       "max             1.000000     1.000000          1.000000      1.000000   \n",
       "\n",
       "       old school hip hop   punk blues      dmv rap  industrial metal  \\\n",
       "count         7858.000000  7858.000000  7858.000000       7858.000000   \n",
       "mean             0.001145     0.001273     0.002418          0.001273   \n",
       "std              0.033825     0.035653     0.049116          0.035653   \n",
       "min              0.000000     0.000000     0.000000          0.000000   \n",
       "25%              0.000000     0.000000     0.000000          0.000000   \n",
       "50%              0.000000     0.000000     0.000000          0.000000   \n",
       "75%              0.000000     0.000000     0.000000          0.000000   \n",
       "max              1.000000     1.000000     1.000000          1.000000   \n",
       "\n",
       "        skate punk  swedish synthpop   moombahton  Max_Peak_Position  \\\n",
       "count  7858.000000       7858.000000  7858.000000        7858.000000   \n",
       "mean      0.001145          0.000509     0.001018          75.775261   \n",
       "std       0.033825          0.022558     0.031893          24.561479   \n",
       "min       0.000000          0.000000     0.000000           1.000000   \n",
       "25%       0.000000          0.000000     0.000000          66.000000   \n",
       "50%       0.000000          0.000000     0.000000          84.000000   \n",
       "75%       0.000000          0.000000     0.000000          95.000000   \n",
       "max       1.000000          1.000000     1.000000         100.000000   \n",
       "\n",
       "       Max_Rank_Change  In_Top5genres_Mean  \n",
       "count      7858.000000         7858.000000  \n",
       "mean         12.531815            0.383706  \n",
       "std          11.760207            0.466419  \n",
       "min          -8.000000            0.000000  \n",
       "25%           3.000000            0.000000  \n",
       "50%          11.000000            0.000000  \n",
       "75%          17.000000            1.000000  \n",
       "max          79.000000            1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_withgenre = df_clean_withgenre.drop(['SongID'], axis=1)\n",
    "df_clean_withgenre.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>Max_Peak_Position</th>\n",
       "      <th>Max_Rank_Change</th>\n",
       "      <th>In_Top5genres_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "      <td>7858.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>225877.547340</td>\n",
       "      <td>0.634195</td>\n",
       "      <td>0.683831</td>\n",
       "      <td>5.258590</td>\n",
       "      <td>-5.955137</td>\n",
       "      <td>0.663019</td>\n",
       "      <td>0.110003</td>\n",
       "      <td>0.173873</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>0.184399</td>\n",
       "      <td>0.506799</td>\n",
       "      <td>122.323709</td>\n",
       "      <td>3.972003</td>\n",
       "      <td>75.775261</td>\n",
       "      <td>12.531815</td>\n",
       "      <td>0.383706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46659.091277</td>\n",
       "      <td>0.149508</td>\n",
       "      <td>0.172011</td>\n",
       "      <td>3.589907</td>\n",
       "      <td>2.228035</td>\n",
       "      <td>0.472709</td>\n",
       "      <td>0.110535</td>\n",
       "      <td>0.215344</td>\n",
       "      <td>0.066326</td>\n",
       "      <td>0.140660</td>\n",
       "      <td>0.223494</td>\n",
       "      <td>29.558487</td>\n",
       "      <td>0.273062</td>\n",
       "      <td>24.561479</td>\n",
       "      <td>11.760207</td>\n",
       "      <td>0.466419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37013.000000</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.023000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>48.718000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>198219.250000</td>\n",
       "      <td>0.533250</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-7.079000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>97.943500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>221798.500000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-5.640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>121.070000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>248459.500000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-4.406500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>142.397250</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>992160.000000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>213.737000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spotify_track_duration_ms  danceability       energy          key  \\\n",
       "count                7858.000000   7858.000000  7858.000000  7858.000000   \n",
       "mean               225877.547340      0.634195     0.683831     5.258590   \n",
       "std                 46659.091277      0.149508     0.172011     3.589907   \n",
       "min                 37013.000000      0.113000     0.031600     0.000000   \n",
       "25%                198219.250000      0.533250     0.571000     2.000000   \n",
       "50%                221798.500000      0.638000     0.704000     5.000000   \n",
       "75%                248459.500000      0.740000     0.819000     8.000000   \n",
       "max                992160.000000      0.986000     0.996000    11.000000   \n",
       "\n",
       "          loudness         mode  speechiness  acousticness  instrumentalness  \\\n",
       "count  7858.000000  7858.000000  7858.000000   7858.000000       7858.000000   \n",
       "mean     -5.955137     0.663019     0.110003      0.173873          0.008682   \n",
       "std       2.228035     0.472709     0.110535      0.215344          0.066326   \n",
       "min     -23.023000     0.000000     0.022400      0.000003          0.000000   \n",
       "25%      -7.079000     0.000000     0.036200      0.019225          0.000000   \n",
       "50%      -5.640000     1.000000     0.057250      0.081900          0.000000   \n",
       "75%      -4.406500     1.000000     0.143000      0.247000          0.000017   \n",
       "max       0.175000     1.000000     0.951000      0.987000          0.982000   \n",
       "\n",
       "          liveness      valence        tempo  time_signature  \\\n",
       "count  7858.000000  7858.000000  7858.000000     7858.000000   \n",
       "mean      0.184399     0.506799   122.323709        3.972003   \n",
       "std       0.140660     0.223494    29.558487        0.273062   \n",
       "min       0.020000     0.034900    48.718000        0.000000   \n",
       "25%       0.095900     0.330000    97.943500        4.000000   \n",
       "50%       0.128000     0.505000   121.070000        4.000000   \n",
       "75%       0.234000     0.679000   142.397250        4.000000   \n",
       "max       0.986000     0.976000   213.737000        5.000000   \n",
       "\n",
       "       Max_Peak_Position  Max_Rank_Change  In_Top5genres_Mean  \n",
       "count        7858.000000      7858.000000         7858.000000  \n",
       "mean           75.775261        12.531815            0.383706  \n",
       "std            24.561479        11.760207            0.466419  \n",
       "min             1.000000        -8.000000            0.000000  \n",
       "25%            66.000000         3.000000            0.000000  \n",
       "50%            84.000000        11.000000            0.000000  \n",
       "75%            95.000000        17.000000            1.000000  \n",
       "max           100.000000        79.000000            1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_nogenre.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target Variables\n",
    "\n",
    "I'm prepping 4 versions for XGBoost and k-NN:\n",
    "\n",
    "1. Max Peak Position, no genre (nogenre__1 variables)\n",
    "2. Max Peak Position, with genre (withgenre_1 variables)\n",
    "3. Max Rank Change, no genre (nogenre_2 variables)\n",
    "4. Max Rank Change, with genre (withgenre_2 variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for XGBoost and k-NN max_peak_position analysis, no genre\n",
    "X_nogenre_1 = df_clean_nogenre.drop(['Max_Peak_Position'], axis=1)\n",
    "y_nogenre_1 = df_clean_nogenre['Max_Peak_Position']\n",
    "\n",
    "# Splitting the data into training and testing sets (75-25 split and random_state of 42)\n",
    "X_nogenre_1_train, X_nogenre_1_test, y_nogenre_1_train, y_nogenre_1_test = train_test_split(X_nogenre_1, y_nogenre_1, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_nogenre_1_train_scaled = scaler.fit_transform(X_nogenre_1_train)\n",
    "X_nogenre_1_test_scaled = scaler.fit_transform(X_nogenre_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for XGBoost and k-NN max_peak_position analysis, including genre\n",
    "X_withgenre_1 = df_clean_withgenre.drop(['Max_Peak_Position'], axis=1)\n",
    "y_withgenre_1 = df_clean_withgenre['Max_Peak_Position']\n",
    "\n",
    "# Splitting the data into training and testing sets (75-25 split and random_state of 42)\n",
    "X_withgenre_1_train, X_withgenre_1_test, y_withgenre_1_train, y_withgenre_1_test = train_test_split(X_withgenre_1, y_withgenre_1, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_withgenre_1_train_scaled = scaler.fit_transform(X_withgenre_1_train)\n",
    "X_withgenre_1_test_scaled = scaler.fit_transform(X_withgenre_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for XGBoost and k-NN max_rank_change analysis, no genre\n",
    "X_nogenre_2 = df_clean_nogenre.drop(['Max_Peak_Position', 'Max_Rank_Change'], axis=1)\n",
    "y_nogenre_2 = df_clean_nogenre['Max_Rank_Change']\n",
    "\n",
    "# Splitting the data into training and testing sets (75-25 split and random_state of 42)\n",
    "X_nogenre_2_train, X_nogenre_2_test, y_nogenre_2_train, y_nogenre_2_test = train_test_split(X_nogenre_2, y_nogenre_2, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_nogenre_2_train_scaled = scaler.fit_transform(X_nogenre_2_train)\n",
    "X_nogenre_2_test_scaled = scaler.fit_transform(X_nogenre_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for XGBoost and k-NN max_rank_change analysis, including genre\n",
    "X_withgenre_2 = df_clean_withgenre.drop(['Max_Peak_Position', 'Max_Rank_Change'], axis=1)\n",
    "y_withgenre_2 = df_clean_withgenre['Max_Rank_Change']\n",
    "\n",
    "# Splitting the data into training and testing sets (75-25 split and random_state of 42)\n",
    "X_withgenre_2_train, X_withgenre_2_test, y_withgenre_2_train, y_withgenre_2_test = train_test_split(X_withgenre_2, y_withgenre_2, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_withgenre_2_train_scaled = scaler.fit_transform(X_withgenre_2_train)\n",
    "X_withgenre_2_test_scaled = scaler.fit_transform(X_withgenre_2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another 4 versions of the data for the deep learning model\n",
    "\n",
    "1. Max Peak Position, no genre (nogenre_3 variables)\n",
    "2. Max Peak Position, with genre (withgenre_3 variables)\n",
    "3. Max Rank Change, no genre (nogenre_4 variables)\n",
    "4. Max Rank Change, with genre (withgenre_4 variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and target for deep learning max_peak_position analysis, no genre\n",
    "X_nogenre_3 = df_clean_nogenre.drop(['Max_Peak_Position'], axis=1)\n",
    "y_nogenre_3 = df_clean_nogenre['Max_Peak_Position']\n",
    "\n",
    "# Splitting the data into training and testing sets \n",
    "X_nogenre_3_train, X_nogenre_3_test, y_nogenre_3_train, y_nogenre_3_test = train_test_split(X_nogenre_3, y_nogenre_3, test_size=0.2, random_state=42)\n",
    "\n",
    "# splitting training data into training and validiation\n",
    "X_nogenre_3_train_final, X_nogenre_3_val, y_nogenre_3_train_final, y_nogenre_3_val = train_test_split(X_nogenre_3_train, y_nogenre_3_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalizing \n",
    "scaler.fit(X_nogenre_3_train_final)\n",
    "X3_1_train_scaled = scaler.transform(X_nogenre_3_train_final)\n",
    "X3_1_val_scaled = scaler.transform(X_nogenre_3_val)\n",
    "X3_1_test_scaled = scaler.transform(X_nogenre_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and target for deep learning max_peak_position analysis, including genre\n",
    "X_withgenre_3 = df_clean_withgenre.drop(['Max_Peak_Position'], axis=1)\n",
    "y_withgenre_3 = df_clean_withgenre['Max_Peak_Position']\n",
    "\n",
    "# Splitting the data into training and testing sets \n",
    "X_withgenre_3_train, X_withgenre_3_test, y_withgenre_3_train, y_withgenre_3_test = train_test_split(X_withgenre_3, y_withgenre_3, test_size=0.2, random_state=42)\n",
    "\n",
    "# splitting training data into training and validiation\n",
    "X_withgenre_3_train_final, X_withgenre_3_val, y_withgenre_3_train_final, y_withgenre_3_val = train_test_split(X_withgenre_3_train, y_withgenre_3_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalizing\n",
    "scaler.fit(X_withgenre_3_train_final)\n",
    "X3_2_train_scaled = scaler.transform(X_withgenre_3_train_final)\n",
    "X3_2_val_scaled = scaler.transform(X_withgenre_3_val)\n",
    "X3_2_test_scaled = scaler.transform(X_withgenre_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and target for deep learning max_rank_change analysis, no genre\n",
    "X_nogenre_4 = df_clean_nogenre.drop(['Max_Peak_Position', 'Max_Rank_Change'], axis=1)\n",
    "y_nogenre_4 = df_clean_nogenre['Max_Rank_Change']\n",
    "\n",
    "# Splitting the data into training and testing sets \n",
    "X_nogenre_4_train, X_nogenre_4_test, y_nogenre_4_train, y_nogenre_4_test = train_test_split(X_nogenre_4, y_nogenre_4, test_size=0.2, random_state=42)\n",
    "\n",
    "# splitting training data into training and validiation\n",
    "X_nogenre_4_train_final, X_nogenre_4_val, y_nogenre_4_train_final, y_nogenre_4_val = train_test_split(X_nogenre_4_train, y_nogenre_4_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalizing\n",
    "scaler.fit(X_nogenre_4_train_final)\n",
    "X4_1_train_scaled = scaler.transform(X_nogenre_4_train_final)\n",
    "X4_1_val_scaled = scaler.transform(X_nogenre_4_val)\n",
    "X4_1_test_scaled = scaler.transform(X_nogenre_4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for simple deep learning max_rank_change analysis, including genre\n",
    "X_withgenre_4 = df_clean_withgenre.drop(['Max_Peak_Position', 'Max_Rank_Change'], axis=1)\n",
    "y_withgenre_4 = df_clean_withgenre['Max_Rank_Change']\n",
    "\n",
    "# Splitting the data into training and testing sets \n",
    "X_withgenre_4_train, X_withgenre_4_test, y_withgenre_4_train, y_withgenre_4_test = train_test_split(X_withgenre_4, y_withgenre_4, test_size=0.2, random_state=42)\n",
    "\n",
    "# splitting training data into training and validiation\n",
    "X_withgenre_4_train_final, X_withgenre_4_val, y_withgenre_4_train_final, y_withgenre_4_val = train_test_split(X_withgenre_4_train, y_withgenre_4_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalizing\n",
    "scaler.fit(X_withgenre_4_train_final)\n",
    "X4_2_train_scaled = scaler.transform(X_withgenre_4_train_final)\n",
    "X4_2_val_scaled = scaler.transform(X_withgenre_4_val)\n",
    "X4_2_test_scaled = scaler.transform(X_withgenre_4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "**XGBoost | Max Peak Position - No Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 25.189\n",
      "R²: 0.009\n"
     ]
    }
   ],
   "source": [
    "# XGBoost for max_peak_position, no genre\n",
    "\n",
    "xgb_maxpeak_nogenre = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "xgb_maxpeak_nogenre.fit(X_nogenre_1_train_scaled, y_nogenre_1_train)\n",
    "y_nogenre_1_pred = xgb_maxpeak_nogenre.predict(X_nogenre_1_test_scaled)\n",
    "y_nogenre_1_pred = np.clip(np.round(y_nogenre_1_pred), 1, 100)\n",
    "\n",
    "rmse_nogenre_1 = np.sqrt(mean_squared_error(y_nogenre_1_test, y_nogenre_1_pred))\n",
    "r2_nogenre_1 = r2_score(y_nogenre_1_test, y_nogenre_1_pred)\n",
    "\n",
    "print(f'RMSE: {rmse_nogenre_1:.3f}')\n",
    "print(f'R²: {r2_nogenre_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 1\n",
    "\n",
    "param_grid1 = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_search_xgb_nogenre_1 = GridSearchCV(estimator=xgb_maxpeak_nogenre,\n",
    "                            param_grid=param_grid1,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_nogenre_1.fit(X_nogenre_1_train, y_nogenre_1_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_nogenre_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 2, 'subsample': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "135 fits failed out of a total of 405.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\sklearn.py\", line 1170, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.14928596 0.1497933  0.14933232 0.1519076  0.1538763  0.15317112\n",
      " 0.14956039 0.14933785 0.15139946 0.15320263 0.15275146 0.1530459\n",
      " 0.14947191 0.14825419 0.14977659 0.13353322 0.13985333 0.13783634\n",
      " 0.15055884 0.14790804 0.15182688 0.13723545 0.1396863  0.13820686\n",
      " 0.12488542 0.12580568 0.13303351 0.14951099 0.14986331 0.15052954\n",
      " 0.15149311 0.15313528 0.15195441 0.15239897 0.15245192 0.15317686\n",
      " 0.15170226 0.15120819 0.15521759 0.1480341  0.14980488 0.15103229\n",
      " 0.1380379  0.14412221 0.14086841 0.14997244 0.15279588 0.15103062\n",
      " 0.13215508 0.13735918 0.14146951 0.11673868 0.12705541 0.12914339\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 2\n",
    "\n",
    "param_grid2 = {\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'learning_rate': [0.05, 0.1, 0.15,],\n",
    "    'subsample': [0.75, 0.8, 0.85],\n",
    "    'colsample_bytree': [0.9, 1.0, 1.1]\n",
    "}\n",
    "\n",
    "grid_search_xgb_nogenre_2 = GridSearchCV(estimator=xgb_maxpeak_nogenre,\n",
    "                            param_grid=param_grid2,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_nogenre_2.fit(X_nogenre_1_train, y_nogenre_1_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_nogenre_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 2, 'subsample': 0.85}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 3\n",
    "\n",
    "param_grid3 = {\n",
    "    'max_depth': [2],\n",
    "    'learning_rate': [0.07, 0.1, 0.13],\n",
    "    'subsample': [0.85],\n",
    "    'colsample_bytree': [1.0],\n",
    "}\n",
    "\n",
    "grid_search_xgb_nogenre_3 = GridSearchCV(estimator=xgb_maxpeak_nogenre,\n",
    "                            param_grid=param_grid3,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_nogenre_3.fit(X_nogenre_1_train, y_nogenre_1_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_nogenre_3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22.851\n",
      "R²: 0.185\n"
     ]
    }
   ],
   "source": [
    "# Extract best/final model for max_peak_position\n",
    "best_xgb1_1 = grid_search_xgb_nogenre_3.best_estimator_\n",
    "\n",
    "# predictions\n",
    "y_nogenre_1_pred_best = best_xgb1_1.predict(X_nogenre_1_test)\n",
    "y_nogenre_1_pred_best = np.clip(np.round(y_nogenre_1_pred_best), 1, 100)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "rmse_nogenre_1_best = np.sqrt(mean_squared_error(y_nogenre_1_test, y_nogenre_1_pred_best))\n",
    "r2_nogenre_1_best = r2_score(y_nogenre_1_test, y_nogenre_1_pred_best)\n",
    "\n",
    "print(f'RMSE: {rmse_nogenre_1_best:.3f}')\n",
    "print(f'R²: {r2_nogenre_1_best:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost | Max Peak Position - With Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22.751\n",
      "R²: 0.192\n"
     ]
    }
   ],
   "source": [
    "# XGBoost for max_peak_position, with genre\n",
    "\n",
    "xgb_maxpeak_withgenre = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "xgb_maxpeak_withgenre.fit(X_withgenre_1_train, y_withgenre_1_train)\n",
    "y_withgenre_1_pred = xgb_maxpeak_withgenre.predict(X_withgenre_1_test)\n",
    "y_withgenre_1_pred = np.clip(np.round(y_withgenre_1_pred), 1, 100)\n",
    "\n",
    "rmse_withgenre_1 = np.sqrt(mean_squared_error(y_withgenre_1_test, y_withgenre_1_pred))\n",
    "r2_withgenre_1 = r2_score(y_withgenre_1_test, y_withgenre_1_pred)\n",
    "\n",
    "print(f'RMSE: {rmse_withgenre_1:.3f}')\n",
    "print(f'R²: {r2_withgenre_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 3, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 1\n",
    "\n",
    "param_grid1 = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_search_xgb_withgenre_1 = GridSearchCV(estimator=xgb_maxpeak_withgenre,\n",
    "                            param_grid=param_grid1,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_withgenre_1.fit(X_withgenre_1_train, y_withgenre_1_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_withgenre_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "135 fits failed out of a total of 405.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\sklearn.py\", line 1170, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.22290783 0.22476627        nan 0.22961248 0.23208994        nan\n",
      " 0.22492174 0.22395395        nan 0.22358264 0.22480186        nan\n",
      " 0.22946347 0.22976409        nan 0.22246672 0.22280164        nan\n",
      " 0.22506559 0.22599194        nan 0.22510593 0.22972054        nan\n",
      " 0.21419413 0.21712435        nan 0.22480632 0.22179151        nan\n",
      " 0.22939501 0.23055565        nan 0.22415408 0.22779516        nan\n",
      " 0.22766875 0.22672504        nan 0.2268309  0.22682267        nan\n",
      " 0.22377956 0.22375016        nan 0.22684716 0.22516409        nan\n",
      " 0.2178275  0.21981466        nan 0.20304011 0.21110715        nan\n",
      " 0.22454622 0.22334156        nan 0.22969245 0.2287244         nan\n",
      " 0.2288182  0.22858987        nan 0.22661289 0.22694678        nan\n",
      " 0.22954861 0.22734727        nan 0.21356106 0.22451347        nan\n",
      " 0.22868726 0.22631047        nan 0.21676042 0.22319322        nan\n",
      " 0.21143588 0.20957587        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 3, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 2\n",
    "\n",
    "param_grid4 = {\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'learning_rate': [0.15, 0.2, 0.25],\n",
    "    'subsample': [0.9, 1.0, 1.1],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "}\n",
    "\n",
    "grid_search_xgb_withgenre_2 = GridSearchCV(estimator=xgb_maxpeak_withgenre,\n",
    "                            param_grid=param_grid4,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_withgenre_2.fit(X_withgenre_1_train, y_withgenre_1_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_withgenre_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters: {'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 3, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 3\n",
    "\n",
    "param_grid5 = {\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.12, 0.15, 0.17],\n",
    "    'subsample': [1.0],\n",
    "    'colsample_bytree': [0.5, 0.6],\n",
    "}\n",
    "\n",
    "grid_search_xgb_withgenre_3 = GridSearchCV(estimator=xgb_maxpeak_withgenre,\n",
    "                            param_grid=param_grid5,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_withgenre_3.fit(X_withgenre_1_train, y_withgenre_1_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_withgenre_3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 21.607\n",
      "R²: 0.271\n"
     ]
    }
   ],
   "source": [
    "# Extract best/final model \n",
    "best_xgb_maxpeak_withgenre = grid_search_xgb_withgenre_3.best_estimator_\n",
    "\n",
    "# predictions\n",
    "y_withgenre_1_pred_best = best_xgb_maxpeak_withgenre.predict(X_withgenre_1_test)\n",
    "y_withgenre_1_pred_best = np.clip(np.round(y_withgenre_1_pred_best), 1, 100)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "rmse_withgenre_2_best = np.sqrt(mean_squared_error(y_withgenre_1_test, y_withgenre_1_pred_best))\n",
    "r2_withgenre_2_best = r2_score(y_withgenre_1_test, y_withgenre_1_pred_best)\n",
    "\n",
    "print(f'RMSE: {rmse_withgenre_2_best:.3f}')\n",
    "print(f'R²: {r2_withgenre_2_best:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost | Max Rank Change - No Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 12.605\n",
      "R²: -0.097\n"
     ]
    }
   ],
   "source": [
    "# XGBoost for max_rank_change\n",
    "\n",
    "xgb_maxrank_nogenre = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "xgb_maxrank_nogenre.fit(X_nogenre_2_train, y_nogenre_2_train)\n",
    "y_nogenre_2_pred = xgb_maxrank_nogenre.predict(X_nogenre_2_test)\n",
    "y_nogenre_2_pred = np.clip(np.round(y_nogenre_2_pred), 1, 100)\n",
    "\n",
    "rmse_maxrank_nogenre_2 = np.sqrt(mean_squared_error(y_nogenre_2_test, y_nogenre_2_pred))\n",
    "r2_maxrank_nogenre_2 = r2_score(y_nogenre_2_test, y_nogenre_2_pred)\n",
    "\n",
    "print(f'RMSE: {rmse_maxrank_nogenre_2:.3f}')\n",
    "print(f'R²: {r2_maxrank_nogenre_2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 1 for max_rank_change\n",
    "\n",
    "param_grid1 = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_search_xgb_maxrank_nogenre_1 = GridSearchCV(estimator=xgb_maxrank_nogenre,\n",
    "                            param_grid=param_grid1,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_maxrank_nogenre_1.fit(X_nogenre_2_train, y_nogenre_2_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_maxrank_nogenre_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.015, 'max_depth': 3, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "135 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\sklearn.py\", line 1170, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\sklearn.py\", line 1170, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.00972437        nan 0.01147871        nan 0.0099106         nan\n",
      " 0.01288679        nan 0.01492339        nan 0.0120229         nan\n",
      " 0.01355836        nan 0.01520104        nan 0.011404          nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 2 for max_rank_change\n",
    "\n",
    "param_grid4 = {\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'learning_rate': [0.005, 0.01, 0.015],\n",
    "    'subsample': [1.0, 1.1],\n",
    "    'colsample_bytree': [1.0, 1.1],\n",
    "}\n",
    "\n",
    "grid_search_xgb_maxrank_nogenre_2 = GridSearchCV(estimator=xgb_maxrank_nogenre,\n",
    "                            param_grid=param_grid4,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_maxrank_nogenre_2.fit(X_nogenre_2_train, y_nogenre_2_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_maxrank_nogenre_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.918\n",
      "R²: 0.020\n"
     ]
    }
   ],
   "source": [
    "# Extract best/final model  for max_rank_change\n",
    "best_xgb_maxrank_nogenre = grid_search_xgb_maxrank_nogenre_2.best_estimator_\n",
    "\n",
    "y_nogenre_2_pred_best = best_xgb_maxrank_nogenre.predict(X_nogenre_2_test)\n",
    "y_nogenre_2_pred_best = np.clip(np.round(y_nogenre_2_pred_best), 1, 100)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "rmse_maxrank_nogenre_2_best = np.sqrt(mean_squared_error(y_nogenre_2_test, y_nogenre_2_pred_best))\n",
    "r2_maxrank_nogenre_2_best = r2_score(y_nogenre_2_test, y_nogenre_2_pred_best)\n",
    "\n",
    "print(f'RMSE: {rmse_maxrank_nogenre_2_best:.3f}')\n",
    "print(f'R²: {r2_maxrank_nogenre_2_best:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost | Max Rank Change - With Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 12.342\n",
      "R²: -0.051\n"
     ]
    }
   ],
   "source": [
    "# XGBoost for max_rank_change\n",
    "\n",
    "xgb_maxrank_withgenre = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "xgb_maxrank_withgenre.fit(X_withgenre_2_train, y_withgenre_2_train)\n",
    "y_withgenre_2_pred = xgb_maxrank_withgenre.predict(X_withgenre_2_test)\n",
    "y_withgenre_2_pred = np.clip(np.round(y_withgenre_2_pred), 1, 100)\n",
    "\n",
    "rmse_maxpeak_withgenre_1 = np.sqrt(mean_squared_error(y_withgenre_2_test, y_withgenre_2_pred))\n",
    "r2_maxpeak_withgenre_1 = r2_score(y_withgenre_2_test, y_withgenre_2_pred)\n",
    "\n",
    "print(f'RMSE: {rmse_maxpeak_withgenre_1:.3f}')\n",
    "print(f'R²: {r2_maxpeak_withgenre_1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 1\n",
    "\n",
    "param_grid1 = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_search_xgb_maxrank_withgenre_1 = GridSearchCV(estimator=xgb_maxrank_withgenre,\n",
    "                            param_grid=param_grid1,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_maxrank_withgenre_1.fit(X_withgenre_2_train, y_withgenre_2_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_maxrank_withgenre_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "90 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\sklearn.py\", line 1170, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.0224043  0.0229799  0.02310325 0.023507   0.02370381 0.02407839\n",
      " 0.03057899 0.03026649 0.0313546  0.03141223 0.0324422  0.03149776\n",
      " 0.03260914 0.03307942 0.03341982 0.0323358  0.03272635 0.03061318\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.015, 'max_depth': 6, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 2\n",
    "\n",
    "param_grid6 = {\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'learning_rate': [0.005, 0.01, 0.015],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [1.0, 1.1],\n",
    "}\n",
    "\n",
    "grid_search_xgb_maxrank_withgenre_2 = GridSearchCV(estimator=xgb_maxrank_withgenre,\n",
    "                            param_grid=param_grid6,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_maxrank_withgenre_2.fit(X_withgenre_2_train, y_withgenre_2_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_maxrank_withgenre_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.015, 'max_depth': 6, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning 3\n",
    "\n",
    "param_grid7 = {\n",
    "    'max_depth': [6],\n",
    "    'learning_rate': [0.013, 0.015, 0.017],\n",
    "    'subsample': [0.5, 0.6, 0.7],\n",
    "    'colsample_bytree': [1.0],\n",
    "}\n",
    "\n",
    "grid_search_xgb_maxrank_withgenre_3 = GridSearchCV(estimator=xgb_maxrank_withgenre,\n",
    "                            param_grid=param_grid7,\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1)\n",
    "grid_search_xgb_maxrank_withgenre_3.fit(X_withgenre_2_train, y_withgenre_2_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_xgb_maxrank_withgenre_3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.764\n",
      "R²: 0.045\n"
     ]
    }
   ],
   "source": [
    "# Extract best/final model  for max_rank_change\n",
    "best_xgb_maxrank_withgenre = grid_search_xgb_maxrank_withgenre_3.best_estimator_\n",
    "\n",
    "y_withgenre_2_pred_best = best_xgb_maxrank_withgenre.predict(X_withgenre_2_test)\n",
    "y_withgenre_2_pred_best = np.clip(np.round(y_withgenre_2_pred_best), 1, 100)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "rmse_maxpeak_withgenre_2_best = np.sqrt(mean_squared_error(y_withgenre_2_test, y_withgenre_2_pred_best))\n",
    "r2_maxpeak_withgenre_2_best = r2_score(y_withgenre_2_test, y_withgenre_2_pred_best)\n",
    "\n",
    "print(f'RMSE: {rmse_maxpeak_withgenre_2_best:.3f}')\n",
    "print(f'R²: {r2_maxpeak_withgenre_2_best:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Summary\n",
    "\n",
    "Using XGBoost, including the genre features slightly improved model performance. However, the Max Rank Change models both had an r<sup>2</sup> value less than 0.001, essentially indicating no fit of the model to the test data. Max Peak Position performed better, but the highest r<sup>2</sup> value was 0.271 so their predictive value is low.\n",
    "\n",
    "Given the lack of predictive power in these outcomes, I'm shifting focus to the other two techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors\n",
    "\n",
    "**k-Nearest Neighbors | Max Peak Position - No Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for standard metrics\n",
    "param_grid8 = {\n",
    "    'n_neighbors': list(range(1, 31, 2)),  # Odd values to avoid ties\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
    "    'algorithm': ['auto']\n",
    "}\n",
    "\n",
    "# Create standard KNN model for grid search\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "print(\"Starting grid search for standard metrics...\")\n",
    "grid_search1_1 = GridSearchCV(knn, param_grid8, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search1_1.fit(X1_1_train_scaled, y1_1_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "standard_best_params1_1 = grid_search1_1.best_params_\n",
    "standard_best_score1_1 = grid_search1_1.best_score_\n",
    "print(f\"Best parameters (standard metrics): {standard_best_params1_1}\")\n",
    "print(f\"Best cross-validation accuracy: {standard_best_score1_1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model with best parameters\n",
    "final_model1_1 = grid_search1_1.best_estimator_\n",
    "\n",
    "# predictions on test set\n",
    "y1_1_pred = final_model1_1.predict(X1_1_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy1_1 = accuracy_score(y1_1_test, y1_1_pred)\n",
    "\n",
    "print(f\"Best accuracy: {accuracy1_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-Nearest Neighbors | Max Peak Position - With Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arameter grid for standard metrics\n",
    "param_grid8 = {\n",
    "    'n_neighbors': list(range(1, 31, 2)),  # Odd values to avoid ties\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
    "    'algorithm': ['auto']\n",
    "}\n",
    "\n",
    "# Create standard KNN model for grid search\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "print(\"Starting grid search for standard metrics...\")\n",
    "grid_search1_2 = GridSearchCV(knn, param_grid8, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search1_2.fit(X1_2_train_scaled, y1_2_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "standard_best_params1_2 = grid_search1_2.best_params_\n",
    "standard_best_score1_2 = grid_search1_2.best_score_\n",
    "print(f\"Best parameters (standard metrics): {standard_best_params1_2}\")\n",
    "print(f\"Best cross-validation accuracy: {standard_best_score1_2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model with best parameters\n",
    "final_model1_2 = grid_search1_2.best_estimator_\n",
    "\n",
    "# predictions on test set\n",
    "y1_2_pred = final_model1_2.predict(X1_2_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy1_2 = accuracy_score(y1_2_test, y1_2_pred)\n",
    "\n",
    "print(f\"Best accuracy: {accuracy1_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-Nearest Neighbors | Max Rank Change - No Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for standard metrics\n",
    "param_grid8 = {\n",
    "    'n_neighbors': list(range(1, 31, 2)),  # Odd values to avoid ties\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
    "    'algorithm': ['auto']\n",
    "}\n",
    "\n",
    "# Create standard KNN model for grid search\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "print(\"Starting grid search for standard metrics...\")\n",
    "grid_search2_1 = GridSearchCV(knn, param_grid8, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search2_1.fit(X2_1_train_scaled, y2_1_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "standard_best_params2_1 = grid_search2_1.best_params_\n",
    "standard_best_score2_1 = grid_search2_1.best_score_\n",
    "print(f\"Best parameters (standard metrics): {standard_best_params2_1}\")\n",
    "print(f\"Best cross-validation accuracy: {standard_best_score2_1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model with best parameters\n",
    "final_model2_1 = grid_search2_1.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions on test set\n",
    "y2_1_pred = final_model2_1.predict(X2_1_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy2_1 = accuracy_score(y2_1_test, y2_1_pred)\n",
    "\n",
    "print(f\"Best accuracy: {accuracy2_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-Nearest Neighbors | Max Rank Change - With Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for standard metrics\n",
    "param_grid8 = {\n",
    "    'n_neighbors': list(range(1, 31, 2)),  # Odd values to avoid ties\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
    "    'algorithm': ['auto']\n",
    "}\n",
    "\n",
    "# Create standard KNN model for grid search\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "print(\"Starting grid search for standard metrics...\")\n",
    "grid_search2_2 = GridSearchCV(knn, param_grid8, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search2_2.fit(X2_2_train_scaled, y2_2_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "standard_best_params2_2 = grid_search2_2.best_params_\n",
    "standard_best_score2_2 = grid_search2_2.best_score_\n",
    "print(f\"Best parameters (standard metrics): {standard_best_params2_2}\")\n",
    "print(f\"Best cross-validation accuracy: {standard_best_score2_2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model with best parameters\n",
    "final_model2_2 = grid_search2_2.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions on test set\n",
    "y2_2_pred = final_model2_2.predict(X2_2_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy2_2 = accuracy_score(y2_2_test, y2_2_pred)\n",
    "\n",
    "print(f\"Best accuracy: {accuracy2_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN Summary\n",
    "\n",
    "The k-NN models performed poorly on the Max Peak Position data, with a maximum accuracy of 0.052. The performance on the Max Rank Change was better, but the maximum accuracy was still just 0.217.\n",
    "\n",
    "I will not explore k-NN further and instead focus on the deep learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "\n",
    "**Deep Learning | Max Peak Position - No Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model, no regularization or dropout\n",
    "\n",
    "baseline_model3_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X3_1_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "baseline_model3_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_baseline3_1 = baseline_model3_1.fit(\n",
    "    X3_1_train_scaled, y3_1_train_final,\n",
    "    validation_data=(X3_1_val_scaled, y3_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model with batch normalization\n",
    "\n",
    "bnorm_model3_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(X3_1_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "bnorm_model3_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_bnorm_model3_1 = bnorm_model3_1.fit(\n",
    "    X3_1_train_scaled, y3_1_train_final,\n",
    "    validation_data=(X3_1_val_scaled, y3_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model regularization (L2 and dropout)\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model3_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X3_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model3_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model3_1 = reg_model3_1.fit(\n",
    "    X3_1_train_scaled, y3_1_train_final,\n",
    "    validation_data=(X3_1_val_scaled, y3_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "print(\"MODEL EVALUATION: MAX PEAK POSITION, NO GENRE\")\n",
    "\n",
    "print(\"\\n=== Baseline Model ===\")\n",
    "train_scores3_1 = baseline_model3_1.evaluate(X3_1_train_scaled, y3_1_train_final, verbose=0)\n",
    "val_scores3_1   = baseline_model3_1.evaluate(X3_1_val_scaled, y3_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores3_1[1]:.4f}, Train MSE: {train_scores3_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores3_1[1]:.4f}, Val   MSE: {val_scores3_1[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== BatchNorm Model ===\")\n",
    "train_scores_bn3_1 = bnorm_model3_1.evaluate(X3_1_train_scaled, y3_1_train_final, verbose=0)\n",
    "val_scores_bn3_1   = bnorm_model3_1.evaluate(X3_1_val_scaled, y3_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_bn3_1[1]:.4f}, Train MSE: {train_scores_bn3_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_bn3_1[1]:.4f}, Val   MSE: {val_scores_bn3_1[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "train_scores_reg3_1 = reg_model3_1.evaluate(X3_1_train_scaled, y3_1_train_final, verbose=0)\n",
    "val_scores_reg3_1   = reg_model3_1.evaluate(X3_1_val_scaled, y3_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg3_1[1]:.4f}, Train MSE: {train_scores_reg3_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg3_1[1]:.4f}, Val   MSE: {val_scores_reg3_1[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Learning | Max Peak Position - With Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model, no regularization or dropout\n",
    "\n",
    "baseline_model3_2 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X3_2_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "baseline_model3_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_baseline3_2 = baseline_model3_2.fit(\n",
    "    X3_2_train_scaled, y3_2_train_final,\n",
    "    validation_data=(X3_2_val_scaled, y3_2_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model with batch normalization\n",
    "\n",
    "bnorm_model3_2 = keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(X3_2_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "bnorm_model3_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_bnorm_model3_2 = bnorm_model3_2.fit(\n",
    "    X3_2_train_scaled, y3_2_train_final,\n",
    "    validation_data=(X3_2_val_scaled, y3_2_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model with regularization (L2 and dropout)\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model3_2 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X3_2_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model3_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model3_2 = reg_model3_2.fit(\n",
    "    X3_2_train_scaled, y3_2_train_final,\n",
    "    validation_data=(X3_2_val_scaled, y3_2_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "print(\"MODEL EVALUATION: MAX PEAK POSITION, WITH GENRE\")\n",
    "\n",
    "print(\"\\n=== Baseline Model ===\")\n",
    "train_scores3_2 = baseline_model3_2.evaluate(X3_2_train_scaled, y3_2_train_final, verbose=0)\n",
    "val_scores3_2   = baseline_model3_2.evaluate(X3_2_val_scaled, y3_2_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores3_2[1]:.4f}, Train MSE: {train_scores3_2[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores3_2[1]:.4f}, Val   MSE: {val_scores3_2[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== BatchNorm Model ===\")\n",
    "train_scores_bn3_2 = bnorm_model3_2.evaluate(X3_2_train_scaled, y3_2_train_final, verbose=0)\n",
    "val_scores_bn3_2   = bnorm_model3_2.evaluate(X3_2_val_scaled, y3_2_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_bn3_2[1]:.4f}, Train MSE: {train_scores_bn3_2[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_bn3_2[1]:.4f}, Val   MSE: {val_scores_bn3_2[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "train_scores_reg3_2 = reg_model3_2.evaluate(X3_2_train_scaled, y3_2_train_final, verbose=0)\n",
    "val_scores_reg3_2   = reg_model3_2.evaluate(X3_2_val_scaled, y3_2_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg3_2[1]:.4f}, Train MSE: {train_scores_reg3_2[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg3_2[1]:.4f}, Val   MSE: {val_scores_reg3_2[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Learning | Max Rank Change - No Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model, no regularization or dropout\n",
    "\n",
    "baseline_model4_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X4_1_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "baseline_model4_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_baseline4_1 = baseline_model4_1.fit(\n",
    "    X4_1_train_scaled, y4_1_train_final,\n",
    "    validation_data=(X4_1_val_scaled, y4_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model with batch normalization\n",
    "\n",
    "bnorm_model4_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(X4_1_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "bnorm_model4_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_bnorm_model4_1 = bnorm_model4_1.fit(\n",
    "    X4_1_train_scaled, y4_1_train_final,\n",
    "    validation_data=(X4_1_val_scaled, y4_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model with regularization (L2 and dropout)\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model4_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X4_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model4_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model4_1 = reg_model4_1.fit(\n",
    "    X4_1_train_scaled, y4_1_train_final,\n",
    "    validation_data=(X4_1_val_scaled, y4_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "print(\"MODEL EVALUATION: MAX RANK CHANGE, NO GENRE\")\n",
    "\n",
    "print(\"\\n=== Baseline Model ===\")\n",
    "train_scores4_1 = baseline_model4_1.evaluate(X4_1_train_scaled, y4_1_train_final, verbose=0)\n",
    "val_scores4_1   = baseline_model4_1.evaluate(X4_1_val_scaled, y4_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores4_1[1]:.4f}, Train MSE: {train_scores4_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores4_1[1]:.4f}, Val   MSE: {val_scores4_1[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== BatchNorm Model ===\")\n",
    "train_scores_bn4_1 = bnorm_model4_1.evaluate(X4_1_train_scaled, y4_1_train_final, verbose=0)\n",
    "val_scores_bn4_1   = bnorm_model4_1.evaluate(X4_1_val_scaled, y4_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_bn4_1[1]:.4f}, Train MSE: {train_scores_bn4_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_bn4_1[1]:.4f}, Val   MSE: {val_scores_bn4_1[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "train_scores_reg4_1 = reg_model4_1.evaluate(X4_1_train_scaled, y4_1_train_final, verbose=0)\n",
    "val_scores_reg4_1   = reg_model4_1.evaluate(X4_1_val_scaled, y4_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg4_1[1]:.4f}, Train MSE: {train_scores_reg4_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg4_1[1]:.4f}, Val   MSE: {val_scores_reg4_1[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Learning | Max Rank Change - With Genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model, no regularization or dropout\n",
    "\n",
    "baseline_model4_2 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X4_2_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "baseline_model4_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_baseline4_2 = baseline_model4_2.fit(\n",
    "    X4_2_train_scaled, y4_2_train_final,\n",
    "    validation_data=(X4_2_val_scaled, y4_2_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model with batch normalization\n",
    "\n",
    "bnorm_model4_2 = keras.Sequential([\n",
    "    layers.Dense(64, activation='linear', input_shape=(X4_2_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.Dense(64, activation='linear'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "bnorm_model4_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_bnorm_model4_2 = bnorm_model4_2.fit(\n",
    "    X4_2_train_scaled, y4_2_train_final,\n",
    "    validation_data=(X4_2_val_scaled, y4_2_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning model with regularization (L2 and dropout)\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model4_2 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X4_2_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model4_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model4_2 = reg_model4_2.fit(\n",
    "    X4_2_train_scaled, y4_2_train_final,\n",
    "    validation_data=(X4_2_val_scaled, y4_2_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "print(\"MODEL EVALUATION: MAX RANK CHANGE, WITH GENRE\")\n",
    "\n",
    "print(\"\\n=== Baseline Model ===\")\n",
    "train_scores4_2 = baseline_model4_2.evaluate(X4_2_train_scaled, y4_2_train_final, verbose=0)\n",
    "val_scores4_2   = baseline_model4_2.evaluate(X4_2_val_scaled, y4_2_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores4_2[1]:.4f}, Train MSE: {train_scores4_2[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores4_2[1]:.4f}, Val   MSE: {val_scores4_2[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== BatchNorm Model ===\")\n",
    "train_scores_bn4_2 = bnorm_model4_2.evaluate(X4_2_train_scaled, y4_2_train_final, verbose=0)\n",
    "val_scores_bn4_2   = bnorm_model4_2.evaluate(X4_2_val_scaled, y4_2_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_bn4_1[1]:.4f}, Train MSE: {train_scores_bn4_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_bn4_1[1]:.4f}, Val   MSE: {val_scores_bn4_1[2]:.4f}\")\n",
    "\n",
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "train_scores_reg4_2 = reg_model4_2.evaluate(X4_2_train_scaled, y4_2_train_final, verbose=0)\n",
    "val_scores_reg4_2   = reg_model4_2.evaluate(X4_2_val_scaled, y4_2_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg4_2[1]:.4f}, Train MSE: {train_scores_reg4_2[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg4_2[1]:.4f}, Val   MSE: {val_scores_reg4_2[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Learning | Optimizing Regularized Models**\n",
    "\n",
    "Max Peak Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a layer\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model3_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X3_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model3_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model3_1 = reg_model3_1.fit(\n",
    "    X3_1_train_scaled, y3_1_train_final,\n",
    "    validation_data=(X3_1_val_scaled, y3_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "print(\"    Adding an additional deep layer\")\n",
    "train_scores_reg3_1 = reg_model3_1.evaluate(X3_1_train_scaled, y3_1_train_final, verbose=0)\n",
    "val_scores_reg3_1   = reg_model3_1.evaluate(X3_1_val_scaled, y3_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg3_1[1]:.4f}, Train MSE: {train_scores_reg3_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg3_1[1]:.4f}, Val   MSE: {val_scores_reg3_1[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a layer resulted in a larger MAE for both training and validation. Removing the additional layer and adding kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a layer\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model3_1 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X3_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model3_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model3_1 = reg_model3_1.fit(\n",
    "    X3_1_train_scaled, y3_1_train_final,\n",
    "    validation_data=(X3_1_val_scaled, y3_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "print(\"Reverting to 2 deep layers, increasing to 128 kernels per layer\")\n",
    "train_scores_reg3_1 = reg_model3_1.evaluate(X3_1_train_scaled, y3_1_train_final, verbose=0)\n",
    "val_scores_reg3_1   = reg_model3_1.evaluate(X3_1_val_scaled, y3_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg3_1[1]:.4f}, Train MSE: {train_scores_reg3_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg3_1[1]:.4f}, Val   MSE: {val_scores_reg3_1[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing kernels per layer gave a result very similar to the original model but increased overfitting a little bit. Leaving 128 kernels per layer and increasing the dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing dropout rate\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.6\n",
    "\n",
    "reg_model3_1 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X3_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model3_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model3_1 = reg_model3_1.fit(\n",
    "    X3_1_train_scaled, y3_1_train_final,\n",
    "    validation_data=(X3_1_val_scaled, y3_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "print(\"2 deep layers,  kernels per layer, increased dropout from 0.4 to 0.6\")\n",
    "train_scores_reg3_1 = reg_model3_1.evaluate(X3_1_train_scaled, y3_1_train_final, verbose=0)\n",
    "val_scores_reg3_1   = reg_model3_1.evaluate(X3_1_val_scaled, y3_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg3_1[1]:.4f}, Train MSE: {train_scores_reg3_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg3_1[1]:.4f}, Val   MSE: {val_scores_reg3_1[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a layer\n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.6\n",
    "\n",
    "reg_model3_1 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X3_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model3_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model3_1 = reg_model3_1.fit(\n",
    "    X3_1_train_scaled, y3_1_train_final,\n",
    "    validation_data=(X3_1_val_scaled, y3_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Regularized Model (L2 + Dropout) ===\")\n",
    "print(\"3 deep layers, 128 kernels per layer, 0.6 dropout rate\")\n",
    "train_scores_reg3_1 = reg_model3_1.evaluate(X3_1_train_scaled, y3_1_train_final, verbose=0)\n",
    "val_scores_reg3_1   = reg_model3_1.evaluate(X3_1_val_scaled, y3_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg3_1[1]:.4f}, Train MSE: {train_scores_reg3_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg3_1[1]:.4f}, Val   MSE: {val_scores_reg3_1[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original regularized model continues to have the best MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Rank Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a layer \n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model4_1 = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X4_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(64, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model4_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model4_1 = reg_model4_1.fit(\n",
    "    X4_1_train_scaled, y4_1_train_final,\n",
    "    validation_data=(X4_1_val_scaled, y4_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Regularized Model (L2 + Dropout) ===\")\n",
    "print(\"    Adding a layer\")\n",
    "train_scores_reg4_1 = reg_model4_1.evaluate(X4_1_train_scaled, y4_1_train_final, verbose=0)\n",
    "val_scores_reg4_1   = reg_model4_1.evaluate(X4_1_val_scaled, y4_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg4_1[1]:.4f}, Train MSE: {train_scores_reg4_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg4_1[1]:.4f}, Val   MSE: {val_scores_reg4_1[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are very nearly identical to the initial configurations. Doubling the kernels in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a layer \n",
    "\n",
    "l2_reg = 1e-4\n",
    "dropout_rate = 0.4\n",
    "\n",
    "reg_model4_1 = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                 input_shape=(X4_1_train.shape[1],)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "        \n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "reg_model4_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae','mse']\n",
    ")\n",
    "\n",
    "history_reg_model4_1 = reg_model4_1.fit(\n",
    "    X4_1_train_scaled, y4_1_train_final,\n",
    "    validation_data=(X4_1_val_scaled, y4_1_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Regularized Model (L2 + Dropout) ===\")\n",
    "print(\"    Adding a layer\")\n",
    "train_scores_reg4_1 = reg_model4_1.evaluate(X4_1_train_scaled, y4_1_train_final, verbose=0)\n",
    "val_scores_reg4_1   = reg_model4_1.evaluate(X4_1_val_scaled, y4_1_val, verbose=0)\n",
    "print(f\"Train MAE: {train_scores_reg4_1[1]:.4f}, Train MSE: {train_scores_reg4_1[2]:.4f}\")\n",
    "print(f\"Val   MAE: {val_scores_reg4_1[1]:.4f}, Val   MSE: {val_scores_reg4_1[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original regularized model has the best MAE scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Summary of Model Performance\n",
    "\n",
    "**XGBoost**\n",
    "The XGBoost model did not return meaningful results for this dataset. The best metrics for XGBoost were:\n",
    "\n",
    "_Maximum Peak Position_\n",
    "\n",
    "- RMSE: 22.35\n",
    "- r<sup>2</sup>: 0.138\n",
    "\n",
    "_Maximum Rank Increase_\n",
    "\n",
    "- RMSE: 11.73\n",
    "- - r<sup>2</sup>: 0.002\n",
    "\n",
    "**k-Nearest Neighbors**\n",
    "This model also did not perform well on this data set. Its best metrics were:\n",
    "\n",
    "_Maximum Peak Position_\n",
    "\n",
    "- Accuracy: 0.052\n",
    "\n",
    "_Maximum Rank Increase_\n",
    "\n",
    "- Accuracy: 0.217\n",
    "\n",
    "**Deep Learning**\n",
    "\n",
    "The deep learning model returned the most promising results and are described in the next section.\n",
    "\n",
    "### Final Models\n",
    "\n",
    "The final models are both based on a deep learning architecture. \n",
    "\n",
    "_Maximum Peak Position_\n",
    "\n",
    "The best model for the Maximum Peak Position is named reg_model3_1. It is a 3-layer, regularized model trained on the song dataset that does not contain genre information.Its final metrics were:\n",
    "\n",
    "- Training mean absolute error: 16.99\n",
    "- Validation mean absolute error: 17.67\n",
    "\n",
    "_Maximum Rank Increase_\n",
    "\n",
    "The best model for the Maximum Rank Increase is named reg_model4_2. It is also a 3-layer, regularized model trained on the song dataset without genre.\n",
    "Its final metrics:\n",
    "\n",
    "- Training mean absolute error: 7.75\n",
    "- Validation mean absolute error: 8.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genre of a song, at least how it is captured on Spotify, has very little influence on its movement on the Billboard Hot 100 list. This gives FutureProduct Advisors consultants and their customers significant leeway when they are selecting music for their social and advertising campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The characteristics of a given song appear to be the most important factors in its performance on the Hot 100 list. Features such as tempo, danceability, etc. have the most predictive power for the Hot 100 list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digital music has a large number of characteristics that can be pulled into machine learning models. The factors that have the largest influence on popularity are often unexpected, and modeling and analysis of songs requires methodical and careful selection and vetting of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "reg_model3_1 (predicting highest ranking on the Billboard Hot 100) and reg_model4_2 (predicting largest week over week ranking increase) are ready for initial deployment to FutureProduct Advisors. \n",
    "\n",
    "Detailed training will be provided, but at a high level here is how users will engage:\n",
    "\n",
    "1. Consultants will identify a list of songs they'd like to explore.\n",
    "    - We recommend using the songs in places 90-100 of the Billboard Hot 100 at a minimum\n",
    "2. Consultants download those songs' metadata from Spotify as a CSV file (detailed instructions to come)\n",
    "3. Consultants load the CSV file into these models, and the models will return predicted activity for each song.\n",
    "\n",
    "There is also an additional opportunity to built on and refine these models by indluding additional data and experimenting with other modeling approaches. If the FutureProduct Advisors consultants have positive feedback on these prototype tools, we will be happy to partner on future enhancements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
